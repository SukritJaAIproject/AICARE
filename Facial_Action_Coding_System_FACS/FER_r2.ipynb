{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjs5Xoj58KJl",
        "outputId": "04537772-b2a0-491c-e2ec-4c1eddaf7229"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXu2Mffr165-"
      },
      "source": [
        "# Download Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yirmGjXE3igL"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from tqdm import tqdm\n",
        "import collections"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0TejqJ89xaO",
        "outputId": "a3735003-7778-4f2e-c067-c1605439c482"
      },
      "source": [
        "%cd drive/MyDrive/AIHealthcare/FER"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/AIHealthcare/FER'\n",
            "/content/drive/MyDrive/AIHealthcare/FER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_CphqOi7rFb"
      },
      "source": [
        "# def download_dataset_to_collab(dataset):\n",
        "\n",
        "#   !pip install -U -q PyDrive\n",
        "\n",
        "#   from pydrive.auth import GoogleAuth\n",
        "#   from pydrive.drive import GoogleDrive\n",
        "#   from google.colab import auth\n",
        "#   from oauth2client.client import GoogleCredentials\n",
        "#   import time\n",
        "\n",
        "#   # 1. Authenticate and create the PyDrive client.\n",
        "#   auth.authenticate_user()\n",
        "#   gauth = GoogleAuth()\n",
        "#   gauth.credentials = GoogleCredentials.get_application_default()\n",
        "#   drive = GoogleDrive(gauth)\n",
        "\n",
        "#   # Auto-iterate through all files in the folder ID.\n",
        "#   start = time.time()\n",
        "#   for key, value in dataset.items():\n",
        "#     print(\"Initiating files copy from {} ...\".format(key))\n",
        "#     file_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format(value)}).GetList()      #file_list = drive.ListFile({'q': \"'1czmCOb4w0LiWetvQyhIxi6gGvJuAYb5F' in parents and trashed=false\"}).GetList()\n",
        "#     for file1 in file_list:      \n",
        "#       file6 = drive.CreateFile({'id': file1['id']}) # Initialize GoogleDriveFile instance with file id.\n",
        "#       file6.GetContentFile(file1['title'])          # Download file as file1['title']\n",
        "#     !mkdir 'datalab/'$key                           # move the data to folder in dictionary\n",
        "#     !ls -l datalab/\n",
        "#     !mv *.png 'datalab/'$key\n",
        "#     !ls -l datalab/\n",
        "#     print(\"Completed files copy from {}.\".format(key))\n",
        "\n",
        "#   end = time.time()                                                                \n",
        "#   return 'time taken:'+ str(end-start) +'seconds'\n",
        "\n",
        "# dataset = {\n",
        "#           #'<folder_name>':'<gdrive_folder_id>'\n",
        "#           # 'mask_images_emotion':'1p7acuIviEzK5D1-udAdConjhmF7hFJIm', \n",
        "#           # 'test':'1czmCOb4w0LiWetvQyhIxi6gGvJuAYb5F',\n",
        "#           'train_cleaned':'1T4uCpfZueGsSUCu145FuEcPY_he6A2fQ'\n",
        "#           }\n",
        "# download_dataset_to_collab(dataset)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3EHcbFABJzX",
        "outputId": "41d7c265-984d-454f-98b3-f58ac7a42d65"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "\n",
        "for f in os.listdir('mask_images_emotion'):\n",
        "  opath='mask_images_emotion/'+str(f)\n",
        "  img = np.asarray(imread(opath))/255.0\n",
        "print(img.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(382, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyqmEB7Y7yv3"
      },
      "source": [
        "# import os\n",
        "# import numpy as np\n",
        "# #http://scikit-image.org/docs/dev/api/skimage.io.html\n",
        "# from skimage.io import imread\n",
        "# for f in os.listdir('./datalab/img'):\n",
        "#   opath='./datalab/img/'+str(f)\n",
        "#   img = np.asarray(imread(opath))/255.0\n",
        "# print(img.shape)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH6UjAwc_WJ-"
      },
      "source": [
        "from skimage.transform import resize, pyramid_reduce\n",
        "from skimage.io import imread\n",
        "import numpy as np\n",
        "\n",
        "def scale_img_to_sqaure(image, square_size):\n",
        "\n",
        "    height, width = image.shape    \n",
        "    if(height > width):\n",
        "      differ = height\n",
        "    else:\n",
        "      differ = width\n",
        "    differ += 4\n",
        "\n",
        "    # square filler\n",
        "    mask = np.zeros((differ, differ), dtype = \"uint8\")\n",
        "\n",
        "    x_pos = int((differ - width) / 2)\n",
        "    y_pos = int((differ - height) / 2)\n",
        "\n",
        "    # center image inside the square\n",
        "    mask[y_pos: y_pos + height, x_pos: x_pos + width] = image[0: height, 0: width]\n",
        "\n",
        "    # downscale if needed\n",
        "    if differ / square_size > 1:\n",
        "      mask = pyramid_reduce(mask, differ / square_size)\n",
        "    else:\n",
        "      mask = cv2.resize(mask, (square_size, square_size), interpolation = cv2.INTER_AREA)\n",
        "    return mask\n",
        "\n",
        "i=np.asarray(imread('datalab/img/S097_001_00000021.png'))/255.0\n",
        "sq = scale_img_to_sqaure(i,128)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWyfxUuV_WMc",
        "outputId": "925e5722-0ddf-4876-9b14-9c7b86d9d80f"
      },
      "source": [
        "i.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(382, 500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXOP_GjTCh9B",
        "outputId": "201b82b6-66a0-42cb-e740-412ca4f93124"
      },
      "source": [
        "ls 'datalab/img/S052_004_00000033.png'"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab/img/S052_004_00000033.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "3adaz_B632m4",
        "outputId": "9fa0383d-da5c-417c-eb25-d91115f22c60"
      },
      "source": [
        "import cv2 \n",
        "a = cv2.imread('datalab/img/S052_004_00000033.png',0)\n",
        "print(a.shape)\n",
        "cv2_imshow(a)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(382, 500)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=500x382 at 0x7F6F9A55E590>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3jba7fLjqfR",
        "outputId": "620b1519-c087-4ad2-f9e6-4cc5d847df71"
      },
      "source": [
        "ls 'drive/MyDrive/AIHealthcare/FER/datalab/img/'"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'drive/MyDrive/AIHealthcare/FER/datalab/img/': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-qDTzbqCwnF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "64bf524e-039f-419c-a7f5-3dad1edb28b5"
      },
      "source": [
        "from skimage import data\n",
        "image1 = data.load('/content/drive/MyDrive/AIHealthcare/FER/datalab/img/S037_006_00000021.png',0)\n",
        "print(image1.shape)\n",
        "cv2_imshow(image1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(382, 500)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: This function is deprecated and will be removed in 0.18. Use `skimage.io.load` or `imageio.imread` directly.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=500x382 at 0x7F6F9D9F00D0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HslwYTVk_cUh"
      },
      "source": [
        "# ls 'datalab/img/S055_006_00000008.png'"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ynwrnSmTfMA"
      },
      "source": [
        "# ls '/content/drive/MyDrive/AIHealthcare/FER/datalab/img/S037_006_00000021.png'"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "F4Kfl7cg_WOW",
        "outputId": "9e2f2f27-cf1d-4d37-f6e4-51f330839cb8"
      },
      "source": [
        "from skimage.transform import rotate\n",
        "from skimage.feature import local_binary_pattern\n",
        "from skimage import data\n",
        "from skimage.color import label2rgb\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "METHOD = 'uniform'\n",
        "plt.rcParams['font.size'] = 9\n",
        "\n",
        "# settings for LBP\n",
        "radius = 3\n",
        "n_points = 8 * radius\n",
        "\n",
        "def overlay_labels(image, lbp, labels):\n",
        "    mask = np.logical_or.reduce([lbp == each for each in labels])\n",
        "    return label2rgb(mask, image=image, bg_label=0, alpha=0.5)\n",
        "\n",
        "def highlight_bars(bars, indexes):\n",
        "    for i in indexes:\n",
        "        bars[i].set_facecolor('r')\n",
        "\n",
        "image = data.load('/content/drive/MyDrive/AIHealthcare/FER/datalab/img/S037_006_00000021.png')\n",
        "# print(image.shape)\n",
        "\n",
        "lbp = local_binary_pattern(image, n_points, radius, METHOD)\n",
        "\n",
        "def hist(ax, lbp):\n",
        "    n_bins = int(lbp.max() + 1)\n",
        "    return ax.hist(lbp.ravel(),bins=n_bins, range=(0, n_bins),facecolor='0.5')\n",
        "    # return ax.hist(lbp.ravel(), normed=True, bins=n_bins, range=(0, n_bins),facecolor='0.5')\n",
        "\n",
        "\n",
        "# plot histograms of LBP of textures\n",
        "fig, (ax_img, ax_hist) = plt.subplots(nrows=2, ncols=3, figsize=(9, 6))\n",
        "plt.gray()\n",
        "\n",
        "titles = ('edge', 'flat', 'corner')\n",
        "w = width = radius - 1\n",
        "edge_labels = range(n_points // 2 - w, n_points // 2 + w + 1)\n",
        "flat_labels = list(range(0, w + 1)) + list(range(n_points - w, n_points + 2))\n",
        "i_14 = n_points // 4            # 1/4th of the histogram\n",
        "i_34 = 3 * (n_points // 4)      # 3/4th of the histogram\n",
        "corner_labels = (list(range(i_14 - w, i_14 + w + 1)) + list(range(i_34 - w, i_34 + w + 1)))\n",
        "label_sets = (edge_labels, flat_labels, corner_labels)\n",
        "\n",
        "for ax, labels in zip(ax_img, label_sets):\n",
        "    ax.imshow(overlay_labels(image, lbp, labels))\n",
        "\n",
        "for ax, labels, name in zip(ax_hist, label_sets, titles):\n",
        "    counts, _, bars = hist(ax, lbp)\n",
        "    highlight_bars(bars, labels)\n",
        "    ax.set_ylim(ymax=np.max(counts[:-1]))\n",
        "    ax.set_xlim(xmax=n_points + 2)\n",
        "    ax.set_title(name)\n",
        "\n",
        "ax_hist[0].set_ylabel('Percentage')\n",
        "for ax in ax_img:\n",
        "    ax.axis('off')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(382, 500)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: UserWarning: This function is deprecated and will be removed in 0.18. Use `skimage.io.load` or `imageio.imread` directly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x432 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mDlujhHGGY1",
        "outputId": "83a52614-e374-43b3-9f27-fb22ad9d95cb"
      },
      "source": [
        "label_sets"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(range(10, 15), [0, 1, 2, 22, 23, 24, 25], [4, 5, 6, 7, 8, 16, 17, 18, 19, 20])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KOwlbqDT0nu"
      },
      "source": [
        "# ls '/content/drive/MyDrive/AIHealthcare/FER/'\n",
        "# ls '/content/Probabilities.xlsx'"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KYhEu01_WQU"
      },
      "source": [
        "import os\n",
        "import csv \n",
        "from skimage import data\n",
        "from skimage.io import imsave, imshow\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import svm, metrics, linear_model\n",
        "\n",
        "def get_au_label(csvfile, imgfile):\n",
        "  \n",
        "  with open(csvfile, 'r') as f:\n",
        "    r = csv.reader(f, delimiter=' ', quotechar='|')\n",
        "    for row in r:\n",
        "      if imgfile in row[0]:\n",
        "        name,value=row[0].split(',')\n",
        "        return int(value)\n",
        "\n",
        "def get_au_label1(img,au):\n",
        "  dataset = pd.ExcelFile('/content/Probabilities.xlsx')\n",
        "  probabilities = dataset.parse(0)\n",
        "  temp = probabilities.iloc[:,[0,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]]\n",
        "  return int(temp[(temp['File']==img)][au].values[0])\n",
        "\n",
        "def get_expr_label(img):\n",
        "  dataset = pd.ExcelFile('/content/Probabilities.xlsx')\n",
        "  probabilities = dataset.parse(0)\n",
        "  temp = probabilities.iloc[:,[0,3]]\n",
        "  return str(temp[(temp['File']==img)]['Expressions'].values[0])\n",
        "\n",
        "def get_lbp(img_path):\n",
        "  # print('############ get_lbp ##############')\n",
        "\n",
        "  # settings for LBP\n",
        "  radius = 3\n",
        "  n_points = 8 * radius\n",
        "  METHOD = 'uniform'\n",
        "\n",
        "  # image = data.load(img_path)\n",
        "  # print('image.shape', img_path.shape)\n",
        "  # print('local_binary_pattern(image, n_points, radius, METHOD)', local_binary_pattern(img_path, n_points, radius, METHOD).shape)\n",
        "  return local_binary_pattern(img_path, n_points, radius, METHOD)\n",
        "\n",
        "def img_to_vector(path,au):\n",
        "  # print('path = ', path) #path =  /content/drive/MyDrive/AIHealthcare/FER/datalab/img/\n",
        "  # print('au = ', au) #au =  1\n",
        "  \n",
        "  # X_train = np.ndarray(shape=(len(os.listdir(path)), 101, 101), dtype=np.float64)\n",
        "  X_train = np.ndarray(shape=(len(os.listdir(path)), 96, 96), dtype=np.float64)\n",
        "  # print('X_train', X_train.shape)\n",
        "\n",
        "  Y_train = np.ndarray(shape=len(os.listdir(path)),dtype=np.float16)\n",
        "  # print('Y_train', Y_train.shape)\n",
        "\n",
        "  X_expr = []\n",
        "  i=0\n",
        "  for img in os.listdir(path):\n",
        "    # print('img', type(img))\n",
        "    # /content/drive/MyDrive/AIHealthcare/FER/datalab/img/S037_003_00000022.png\n",
        "\n",
        "    s,t = img.split('.')  \n",
        "    # print('s = ',s) #s =  S037_003_00000022\n",
        "    # print('t = ',t) #t =  png\n",
        "\n",
        "    Y_train[i] = get_au_label1(s,au)\n",
        "    # print('Y_train[i] = ', Y_train[i])\n",
        "\n",
        "    X_expr.append(get_expr_label(s))\n",
        "    # print('type(X_expr) = ', type(X_expr))\n",
        "    # print('X_expr = ', X_expr)\n",
        "\n",
        "    # print('path+str(img) = ', path+str(img)) #path+str(img) =  /content/drive/MyDrive/AIHealthcare/FER/datalab/img/S037_003_00000022.png\n",
        "    b = data.load(path+str(img),0)\n",
        "    # print('b.shape', b.shape) #(382, 500)\n",
        "    sq_img = scale_img_to_sqaure(b, 96)\n",
        "    # print('sq_img', sq_img.shape) #(96, 96)\n",
        "\n",
        "\n",
        "    X_train[i] = get_lbp(sq_img)\n",
        "    i += 1\n",
        "  return X_train,Y_train, X_expr\n",
        "\n",
        "def train_svc(X, y, x_test):  \n",
        "  clf = svm.LinearSVC(random_state=0)\n",
        "  clf.fit(X, y)  \n",
        "  svm.LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True, intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr', penalty='l2', random_state=0, tol=0.0001, verbose=1)\n",
        "  return clf"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H67pJVv3UmOs"
      },
      "source": [
        "# ls '/content/drive/MyDrive/AIHealthcare/FER/datalab/img/'"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chMUaYGlDbhb"
      },
      "source": [
        "def eq21_training(y_new, au_list):\n",
        "  # print('############### start eq21_training ###############')\n",
        "  # print('y_new', y_new.shape)\n",
        "  # print('au_list', len(au_list))\n",
        "  i=0\n",
        "  W = np.ndarray(shape=(269, 9216), dtype=np.float64)\n",
        "\n",
        "  for au in tqdm(au_list):\n",
        "    tick = time.time()\n",
        "\n",
        "    X_train, Y_train, X_expr = img_to_vector(\"/content/drive/MyDrive/AIHealthcare/FER/datalab/img/\",au)\n",
        "    # print('X_train', X_train.shape)\n",
        "    # print('Y_train', Y_train.shape)\n",
        "\n",
        "    Y_train = np.transpose(y_new[:,i])\n",
        "    # print('Y_train', Y_train)\n",
        "\n",
        "    X = X_train[0:269,:,:].reshape(269,-1)\n",
        "    y = Y_train[0:269,]\n",
        "    x_expr = X_expr[0:269]\n",
        "    x_test = X_train[270:,:,:].reshape(39,-1)\n",
        "    y_test = Y_train[270:,]\n",
        "\n",
        "    classifier = train_svc(X, y, x_test)\n",
        "    y_pred = classifier.predict(x_test)\n",
        "    confidence = classifier.decision_function(x_test)\n",
        "    #Coeeficients: (1, 10201)\n",
        "    W[i,:]=classifier.coef_\n",
        "    print(classifier.coef_)\n",
        "    print(W[i])\n",
        "    i += 1\n",
        "\n",
        "    print('*************AU{} Classifier*************'.format(au))\n",
        "    print('Pred: {}'.format(y_pred))\n",
        "    print('Test: {}'.format(y_test))\n",
        "    print('AU{} classifier co-eficients: {}'.format(au,classifier.coef_.shape))\n",
        "    print(\"Classification report for classifier {}, {}\".format(classifier, metrics.classification_report(y_test, y_pred)))\n",
        "    print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, y_pred))\n",
        "    tock = time.time()\n",
        "    print(tock-tick)\n",
        "  return W, X, x_expr"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSwwfJ7lDdg8"
      },
      "source": [
        "#Express independent joint AU probability loss\n",
        "def eq8_loss(test_au_labels, positive_au_pairs, negative_au_pairs):\n",
        "  pt_loss = nt_loss = 0\n",
        "  \n",
        "  ## Determine the positive pairs not occurring together\n",
        "  positive_au_pairs_not_present = list()\n",
        "  for i in test_au_labels:\n",
        "    for j in positive_au_pairs:\n",
        "      if i in j:\n",
        "        if not ((j[0] in test_au_labels) and (j[1] in test_au_labels)):\n",
        "          positive_au_pairs_not_present.append(j)\n",
        "  ######################################################\n",
        "  \n",
        "  for pt_pair in positive_au_pairs_not_present:\n",
        "    prob_i = get_prob_i(pt_pair[0])\n",
        "    prob_j = get_prob_i(pt_pair[1])\n",
        "    prob_ij = get_prob_ij(pt_pair)\n",
        "    pt_loss += max(0,(prob_i*prob_j - prob_ij)) + max(0,((1-prob_i)*prob_j - prob_ij)) + max(0,(prob_i*(1-prob_j) - prob_ij))\n",
        "    \n",
        "  negative_au_pairs = [i for i in negative_au_pairs if set(i)<=set(test_au_labels)]\n",
        "  for nt_pair in negative_au_pairs:\n",
        "      prob_i = get_prob_i(nt_pair[0])\n",
        "      prob_j = get_prob_i(nt_pair[1])\n",
        "      prob_ij = get_prob_ij(nt_pair)\n",
        "      nt_loss += max(0,(prob_ij - prob_i*prob_j)) + max(0,(prob_ij - (1-prob_i)*prob_j)) + max(0,(prob_ij - prob_i*(1-prob_j)))\n",
        "  return (pt_loss+nt_loss)\n",
        "\n",
        "#Expression dependent single AU probability loss - considering only 'primary'/'others' AU - SUMMATE over K\n",
        "def eq11_loss(test_au_labels, x_expr_label, primary_au, others_au):\n",
        "  loss=0\n",
        "  for pr_au in primary_au[x_expr_label]:\n",
        "    if pr_au not in test_au_labels:\n",
        "      prob_i_k = get_prob_i_under_k(pr_au, x_expr_label)\n",
        "      loss += max(0,(0.5 - prob_i_k))\n",
        "  for ot_au in others_au[x_expr_label]:\n",
        "    if ot_au in test_au_labels:\n",
        "      prob_i_k = get_prob_i_under_k(ot_au, x_expr_label)\n",
        "      loss += max(0,(prob_i_k - 0.5))    \n",
        "  return loss\n",
        "\n",
        "#Expression dependent single AU probability loss - calculating differences wrt table3\n",
        "def eq13_loss():\n",
        "  return loss\n",
        "\n",
        "#Expression dependent joint AU probability loss - (prob_primary > prob_secondary) & (prob_secondary > prob-others)\n",
        "def eq15_loss(test_au_labels, emotion_list, primary_secondary_au_pairs, secondary_others_au_pairs):\n",
        "  loss = 0\n",
        "  #Filter primary_secondary_au_pairs \n",
        "  for e in emotion_list:\n",
        "    primary_secondary_au_pairs[e] = [i for i in primary_secondary_au_pairs[e] if i[1] in test_au_labels and i[0] not in test_au_labels]\n",
        "    secondary_others_au_pairs[e] = [i for i in secondary_others_au_pairs[e] if i[1] in test_au_labels and i[0] not in test_au_labels]\n",
        "  for e in emotion_list:\n",
        "    for ps in primary_secondary_au_pairs[e]:\n",
        "      prob_prim = get_prob_i_under_k(ps[0], e)\n",
        "      prob_sec = get_prob_i_under_k(ps[1], e)\n",
        "      loss += max(0,(prob_sec - prob_prim))\n",
        "    for ps in secondary_others_au_pairs[e]:\n",
        "      prob_sec = get_prob_i_under_k(ps[0], e)\n",
        "      prob_oth = get_prob_i_under_k(ps[1], e)        \n",
        "      loss += max(0,(prob_oth - prob_sec))\n",
        "  return loss\n",
        "\n",
        "#Expression dependent joint AU probability loss - positive correlation per table4 - SUMMATE over K\n",
        "def eq19_loss(test_au_labels, emotion_list, emfacs):\n",
        "  loss = 0\n",
        "  #Filter emfacs\n",
        "  '''for e in emotion_list:\n",
        "    emfacs[e] = [i for i in emfacs[e] if set(i)<=set(test_au_labels)]'''\n",
        "  #Filter emfacs\n",
        "  emfacs_pairs_not_present = collections.defaultdict(list)\n",
        "  for e in emotion_list:\n",
        "    for i in test_au_labels:\n",
        "      for j in emfacs[e]:\n",
        "        if i in j:\n",
        "          if not ((j[0] in test_au_labels) and (j[1] in test_au_labels)):\n",
        "            emfacs_pairs_not_present[e].append(j)\n",
        "  \n",
        "  emfacs_pairs_not_present = dict(emfacs_pairs_not_present)\n",
        "  for e in emotion_list:\n",
        "    if e in emfacs_pairs_not_present:\n",
        "      for ps in emfacs_pairs_not_present[e]:\n",
        "        prob_i_k = get_prob_i_under_k(ps[0], e)\n",
        "        prob_j_k = get_prob_i_under_k(ps[1], e)\n",
        "        prob_ij_k = get_prob_ij_under_k(ps, e)\n",
        "        loss += max(0,(prob_i_k*prob_j_k - prob_ij_k)) + max(0,((1-prob_i_k)*prob_j_k - prob_ij_k)) + max(0,(prob_i_k*(1-prob_j_k) - prob_ij_k))\n",
        "    else:\n",
        "      pass\n",
        "  return loss\n",
        "\n",
        "#plan to use code to estimate optimum value for each lambda but for getting ahead assuming all to be 10 from range {10, 10^2, 10^3, 10^4}  \n",
        "def lambda_optimization():  \n",
        "  lambd_eq8=lambd_eq13=lambd_eq19=lambd_eq15 = 10\n",
        "  lambda_eq11 = 100\n",
        "  return lambd_eq8, lambda_eq11, lambd_eq13, lambd_eq19, lambd_eq15\n",
        "\n",
        "#Calculate hinge loss\n",
        "def hinge_loss(y, x, w):\n",
        "  return max(0,(1 - (y*(np.dot(np.transpose(w),x)))))\n",
        "\n",
        "#Calculate classification loss\n",
        "def classification_loss(au_config, x, W):\n",
        "  clf_loss = 0\n",
        "  for m in range(len(au_config)):\n",
        "    w = W[m,:]\n",
        "    y = au_config[m]\n",
        "    clf_loss += hinge_loss(y, w, x)\n",
        "  return clf_loss\n",
        "\n",
        "def eq22_loss(test_au_config, x, W, x_expr_label, au_list, primary_au, secondary_au, others_au, positive_au_pairs, negative_au_pairs, emotion_list):  \n",
        "\n",
        "  M = len(au_list)\n",
        "  au_test_config_arr = np.array(list(itertools.product([0, 1], repeat=M)))\n",
        "  lambd_eq8, lambda_eq11, lambd_eq13, lambd_eq19, lambd_eq15 = lambda_optimization()\n",
        "  primary_secondary_au_pairs = pairs_from_dictionaries(primary_au, secondary_au, emotion_list)\n",
        "  secondary_others_au_pairs = pairs_from_dictionaries(secondary_au, others_au, emotion_list)\n",
        "  test_au_labels = au_label_list(au_list, test_au_config)\n",
        "  \n",
        "  total_loss = Loss_eq8 = Loss_eq11 = Loss_eq13 = Loss_eq15 = Loss_eq19 = 0\n",
        "\n",
        "  #Classification loss calculations\n",
        "  clf_loss = classification_loss(test_au_config, x, W)\n",
        "\n",
        "  \n",
        "  #Loss_eq8\n",
        "  Loss_eq8 = lambd_eq8 * eq8_loss(test_au_labels, positive_au_pairs, negative_au_pairs)\n",
        "\n",
        "  #Loss_eq11      \n",
        "  Loss_eq11 = lambda_eq11 * eq11_loss(test_au_labels, x_expr_label, primary_au, others_au)\n",
        "\n",
        "  #Loss_eq15\n",
        "  Loss_eq15 = lambd_eq15 * eq15_loss(test_au_labels, emotion_list, primary_secondary_au_pairs, secondary_others_au_pairs)\n",
        "\n",
        "  #Loss_eq19\n",
        "  Loss_eq19 = lambd_eq19 * eq19_loss(test_au_labels, emotion_list, emfacs_pairs)\n",
        "\n",
        "  print('clf_loss:{} eq8_loss:{} eq11_loss:{} eq13_loss:{} eq15_loss:{} eq19_loss:{}'.format(clf_loss,Loss_eq8,Loss_eq11,Loss_eq13,Loss_eq15,Loss_eq19))\n",
        "  total_loss = (clf_loss + Loss_eq8 + Loss_eq11 + Loss_eq13 + Loss_eq15 + Loss_eq19)/M\n",
        "  return total_loss\n",
        "\n",
        "def get_eq22_best_AU_config(au_test_config_arr, x, sample_no, x_expr_label, W, au_list, primary_au, secondary_au, others_au, positive_au_pairs, negative_au_pairs, emotion_list):\n",
        "  min_loss = None\n",
        "  y_eq22_best = au_test_config_arr[0]\n",
        "  for test_au_config in au_test_config_arr:\n",
        "    tick=time.time()\n",
        "    x_loss = eq22_loss(test_au_config, x, W, x_expr_label, au_list, primary_au, secondary_au, others_au, positive_au_pairs, negative_au_pairs, emotion_list)\n",
        "    if min_loss == None:\n",
        "      min_loss = x_loss  \n",
        "    if x_loss < min_loss:\n",
        "      min_loss = x_loss\n",
        "      y_eq22_best = test_au_config\n",
        "    tock=time.time()\n",
        "    print('sample: {} x_loss: {} for {} min_loss: {} for {} under {}s'.format(sample_no, x_loss,test_au_config,min_loss,y_eq22_best,(tock-tick)))\n",
        "  return y_eq22_best\n",
        "\n",
        "def compute_eq20_obj(best_au_config, X, W, x_expr_label, y_new, au_list, primary_au, secondary_au, others_au, positive_au_pairs, negative_au_pairs, emotion_list):\n",
        "\n",
        "  M = len(au_list)\n",
        "  lambd_eq8, lambda_eq11, lambd_eq13, lambd_eq19, lambd_eq15 = lambda_optimization()\n",
        "  primary_secondary_au_pairs = pairs_from_dictionaries(primary_au, secondary_au, emotion_list)\n",
        "  secondary_others_au_pairs = pairs_from_dictionaries(secondary_au, others_au, emotion_list)\n",
        "  test_au_labels = au_label_list(au_list, best_au_config)\n",
        "  \n",
        "  main_obj = Loss_eq8 = Loss_eq11 = Loss_eq13 = Loss_eq15 = Loss_eq19 = 0\n",
        "\n",
        "  #Classification loss calculations\n",
        "  for sample in range(y_new.shape[0]):\n",
        "    x=X[sample]\n",
        "    clf_loss = classification_loss(np.transpose(y_new[sample,:]), x, W)\n",
        " \n",
        "  #Loss_eq8\n",
        "  Loss_eq8 = lambd_eq8 * eq8_loss(test_au_labels, positive_au_pairs, negative_au_pairs)\n",
        "\n",
        "  #Loss_eq11      \n",
        "  Loss_eq11 = lambda_eq11 * eq11_loss(test_au_labels, x_expr_label, primary_au, others_au)\n",
        "\n",
        "  #Loss_eq15\n",
        "  Loss_eq15 = lambd_eq15 * eq15_loss(test_au_labels, emotion_list, primary_secondary_au_pairs, secondary_others_au_pairs)\n",
        "\n",
        "  #Loss_eq19\n",
        "  Loss_eq19 = lambd_eq19 * eq19_loss(test_au_labels, emotion_list, emfacs_pairs)\n",
        "\n",
        "  main_obj = (clf_loss + Loss_eq8 + Loss_eq11 + Loss_eq13 + Loss_eq15 + Loss_eq19)/M\n",
        "  return main_obj"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9nBe1KkDmWb"
      },
      "source": [
        "#Convert binary AU config array to AU label array\n",
        "def au_label_list(au_list, au_config):\n",
        "  M = len(au_list)\n",
        "  au_labels=[]\n",
        "  for m in range(M):\n",
        "    if au_config[m] == 1:\n",
        "      au_labels.append(au_list[m])\n",
        "  return au_labels\n",
        "\n",
        "#Get all pairs of items from dictionaries in specified order\n",
        "def pairs_from_dictionaries(dict1, dict2, emotion_list):\n",
        "  pairs_dict1_dict2 = {}\n",
        "  for e in emotion_list:\n",
        "    list_of_pairs = []\n",
        "    for x in dict1[e]:\n",
        "      for y in dict2[e]:\n",
        "        list_of_pairs.append([x,y])\n",
        "    pairs_dict1_dict2[e] = list_of_pairs\n",
        "  return pairs_dict1_dict2\n",
        "  \n",
        "#Get expression independent marginal AU probability that is calculated from dataset\n",
        "def get_prob_i(au):\n",
        "  dataset = pd.ExcelFile('/content/Probabilities.xlsx')\n",
        "  probabilities = dataset.parse(0)\n",
        "  probabilities = probabilities.iloc[:,4:]\n",
        "  n_array = probabilities.values\n",
        "\n",
        "  indi_prob_dict = collections.defaultdict()\n",
        "  columns = list(probabilities.columns)\n",
        "  individualProbabilities = np.sum(n_array,axis=0)/309.0\n",
        "  for index,value in enumerate(columns):\n",
        "      indi_prob_dict[value] = individualProbabilities[index]\n",
        "\n",
        "  return indi_prob_dict[au]\n",
        "\n",
        "#Get expression independent marginal AU probability that is calculated from dataset\n",
        "def get_prob_ij(au_pair):\n",
        "  dataset = pd.ExcelFile('/content/Probabilities.xlsx')\n",
        "  probabilities = dataset.parse(0)\n",
        "  probabilities = probabilities.iloc[:,4:]\n",
        "  n_array = probabilities.values\n",
        "  \n",
        "  joint_prob_dict_11 = collections.defaultdict()\n",
        "  columns = list(probabilities.columns)\n",
        "  for cols in itertools.combinations(range(18),2):\n",
        "      temp = n_array[:,cols]\n",
        "      (x,y) = columns[cols[0]],columns[cols[1]]\n",
        "      #print(temp),.\n",
        "      temp_11 = temp[ (temp[:,0]==1) & (temp[:,1]==1)]\n",
        "      joint_prob_dict_11[(x,y)] = temp_11.shape[0]/309.0\n",
        "  return joint_prob_dict_11[au_pair]\n",
        "\n",
        "#Get expression dependent marginal AU probability that is calculated from dataset\n",
        "def get_prob_i_under_k(au, emotion):\n",
        "  dataset = pd.ExcelFile('/content/Probabilities.xlsx')\n",
        "  probabilities = dataset.parse(0)\n",
        "  probabilities = probabilities.iloc[:,3:]\n",
        "  n_array = probabilities.values\n",
        "  columns = list(probabilities.columns)[1:]\n",
        "\n",
        "  expressions = ['disgust','surprise','anger','happiness','sadness','fear']\n",
        "  primary_aus = {'disgust':[9,10],'surprise':[1,2,5,25,26],'anger':[4,5,23,24],'happiness':[6,12],'sadness':[1,7,15],'fear':[1,2,4,5,7,20]}\n",
        "  secondary_aus = {'disgust':[17,25],'surprise':[16],'anger':[7,17],'happiness':[7,25],'sadness':[4,6,17],'fear':[23,25]}\n",
        "  nested_dict = lambda: collections.defaultdict(nested_dict)\n",
        "  master_aus_prob = nested_dict()\n",
        "  for i in expressions:\n",
        "      temp_expr = probabilities[(probabilities['Expressions']==i)]\n",
        "      temp_aus = temp_expr.iloc[:,1:].values\n",
        "      for j in columns:\n",
        "          index_au = columns.index(j)\n",
        "          master_aus_prob[i][j] = np.sum(temp_aus[:,index_au],axis=0)/float(temp_aus.shape[0])\n",
        "  return master_aus_prob[emotion][au]\n",
        "\n",
        "#Get expression dependent joint AU probability that is calculated from dataset\n",
        "def get_prob_ij_under_k(au_pair, emotion):\n",
        "  dataset = pd.ExcelFile('/content/Probabilities.xlsx')\n",
        "  probabilities = dataset.parse(0)\n",
        "  probabilities_expressions = probabilities.iloc[:,3:]\n",
        "  n_array = probabilities.values\n",
        "  n_array_expr = probabilities_expressions.values\n",
        "  columns = list(probabilities.columns)[4:]\n",
        "\n",
        "  #dependent_aus = {'anger':[(4,5),(4,7),(4,5,7),(17,24),(23,)],'disgust':[(9,),(10,)],'fear':[(1,2,4),(20,)],'happiness':[(12,),(6,12),(7,12)],'sadness':[(1,),(1,4),(15,),(6,15)],'surprise':[(1,2,5),(1,2,26),(1,2,5,26)]}\n",
        "  dependent_aus = {'anger':[(4,5),(4,7),(17,24)],'disgust':[],'fear':[(1,2), (1,4), (2,4)],'happiness':[(6,12),(7,12)],'sadness':[(1,4), (6,15)],'surprise':[(1,2), (1,5), (2,5), (2,26), (1,26), (1,5), (5,26)]}\n",
        "  nested_dict = lambda: collections.defaultdict(nested_dict)\n",
        "  dependent_aus_prob = nested_dict()\n",
        "  for i in dependent_aus:\n",
        "      temp_expr = probabilities_expressions[(probabilities_expressions['Expressions']==i)]\n",
        "      temp_aus = temp_expr.iloc[:,1:].values\n",
        "      for j in dependent_aus[i]:\n",
        "          j1 = [columns.index(x) for x in j]\n",
        "          temp = temp_aus[:,j1]\n",
        "          dependent_aus_prob[i][j] = temp.tolist().count([1]*temp.shape[1])/float(temp_aus.shape[0])\n",
        "  return dependent_aus_prob[emotion][au_pair]"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stzOxvZlVwOr"
      },
      "source": [
        "import itertools"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVdXH1AqEJV0",
        "outputId": "e9dbdc1f-aa7b-4ecd-e32f-0f19f755a722"
      },
      "source": [
        "#AU list considered in our solution derived from table2 - 17 AUs\n",
        "au_list = [1,2,4,5,6,7,9,10,12,15,16,17,20,23,24,25,26,27]\n",
        "#au_list = [1,2,4,5,6,7,9,12,15,17,20,23,24,26]\n",
        "#au_list = [1,2,4,6,7,9,12,15,17,23,24]\n",
        "# au_list = [1,2,4,6,7]\n",
        "emotion_list = [\"anger\",\"disgust\",\"fear\",\"happiness\",\"sadness\",\"surprise\"]\n",
        "primary_au = {\n",
        "              \"anger\": [4,5,23,24],\n",
        "              \"disgust\": [9,10],\n",
        "              \"fear\": [1,2,4,5,7,20],\n",
        "              \"happiness\": [6,12],\n",
        "              \"sadness\": [1,7,15],\n",
        "              \"surprise\": [1,2,5,25,26]\n",
        "              }\n",
        "secondary_au = {\n",
        "              \"anger\": [7,17],\n",
        "              \"disgust\": [17,25],\n",
        "              \"fear\": [23,25],\n",
        "              \"happiness\": [7,25],\n",
        "              \"sadness\": [4,6,17],\n",
        "              \"surprise\": [16]\n",
        "}\n",
        "others_au = {\n",
        "              \"anger\": [1, 2, 6, 9, 10, 12, 15, 16, 20, 25, 26],\n",
        "              \"disgust\": [1, 2, 4, 5, 6, 7, 12, 15, 16, 20, 23, 24, 26],\n",
        "              \"fear\": [6, 9, 10, 12, 15, 16, 17, 24, 26],\n",
        "              \"happiness\": [1, 2, 4, 5, 9, 10, 15, 16, 17, 20, 23, 24, 26],\n",
        "              \"sadness\": [2, 5, 9, 10, 12, 16, 20, 23, 24, 25, 26],\n",
        "              \"surprise\": [4, 6, 7, 9, 10, 12, 15, 17, 20, 23, 24]\n",
        "}\n",
        "\n",
        "#Expression independent FACS encoded AU pairs\n",
        "positive_au_pairs = [(1,2), (4,7) , (4,9), (7,9), (6,12), (9,17), (15,17), (15,24), (17,24), (23,24)]\n",
        "negative_au_pairs = [(2,6), (2,7), (12,15), (12,17)]\n",
        "\n",
        "#derived from emfacs table4 - pairing two-wise\n",
        "emfacs_pairs = {\n",
        "          \"anger\": [(4,5), (4,7), (17,24)],\n",
        "          \"disgust\": [],\n",
        "          \"fear\": [(1,2), (1,4), (2,4)],\n",
        "          \"happiness\": [(6,12), (7,12)],\n",
        "          \"sadness\": [(1,4), (6,15)],\n",
        "          \"surprise\": [(1,2), (1,5), (2,5), (2,26), (1,26), (1,5), (5,26)]\n",
        "}\n",
        "\n",
        "#generate list of test AU configs\n",
        "au_test_config_arr = np.array(list(itertools.product([0, 1], repeat=len(au_list))))\n",
        "print(au_test_config_arr.shape)\n",
        "s = np.sum(au_test_config_arr,1)\n",
        "del_list=[]\n",
        "for x in range(s.shape[0]):\n",
        "  if s[x] <= 1:\n",
        "    del_list.append(x)\n",
        "print(del_list)\n",
        "au_test_config_arr = np.delete(au_test_config_arr, del_list, 0)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(262144, 18)\n",
            "[0, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536, 131072]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVY6GwM-WNKd"
      },
      "source": [
        "import pandas as pd\n",
        "import time"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH2HsBaGENOT"
      },
      "source": [
        "#Complete code - run from here\n",
        "main_obj = min_obj = 100000\n",
        "au_list = [1,2,4,5,6,7,9,10,12,15,16,17,20,23,24,25,26,27]\n",
        "# au_list = [1,2,4]\n",
        "\n",
        "def init_y():\n",
        "  #Initialize y from table2\n",
        "  y_new = np.ndarray(shape=(269, len(au_list)), dtype=np.int)\n",
        "  dataset = pd.ExcelFile('/content/Probabilities.xlsx')\n",
        "  probabilities = dataset.parse(0)\n",
        "  temp = probabilities.iloc[:,[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]]\n",
        "  #temp = probabilities.iloc[:,[4,5,6]]\n",
        "  y_new = temp.values\n",
        "  return y_new\n",
        "\n",
        "def core_algo(y_new, au_list, min_obj):\n",
        "  \n",
        "  #step1 train linear SVM: fix Y, optimize W\n",
        "  # print('######core_algo############')\n",
        "  W, X, x_expr = eq21_training(y_new, au_list)\n",
        "  # print('###########eq21_training################')\n",
        "  \n",
        "  #step2 greedy algo: fix W, optimize Y\n",
        "  for i in range(X.shape[0]):\n",
        "    x=X[i]\n",
        "    x_expr_label = x_expr[i]\n",
        "    #step4 find best AU config for a sample (tried parallelize but causing issue in numpy array)\n",
        "    y_temp = get_eq22_best_AU_config(au_test_config_arr, x, i, x_expr_label, W, au_list, primary_au, secondary_au, others_au, positive_au_pairs, negative_au_pairs, emotion_list)\n",
        "    print('eq22_config for sample{} is {}'.format(i,y_temp))\n",
        "    #compute eq20_obj for above sample\n",
        "    x_obj = compute_eq20_obj(y_temp, X, W, x_expr_label, y_new[0:269,:], au_list, primary_au, secondary_au, others_au, positive_au_pairs, negative_au_pairs, emotion_list)\n",
        "    print('min_eq20_obj before sample{} is {}'.format(i,min_obj))\n",
        "    print('eq20_obj for sample{} is {}'.format(i,x_obj))\n",
        "    if x_obj < min_obj:\n",
        "      min_obj = x_obj\n",
        "      y_new[i] = y_temp          #replace y[i]\n",
        "\n",
        "  return y_new, min_obj"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AcAqIHIPdTYJ",
        "outputId": "5db64f84-1a62-493c-eea2-c6eb098ba32c"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  y_new = init_y()\n",
        "  # print('##')\n",
        "  # print('y_new.shape=', y_new.shape)\n",
        "  # print('au_list', au_list)\n",
        "  # print('au_list.shape', len(au_list))\n",
        "  # print('main_obj', main_obj)\n",
        "\n",
        "  y_new, main_obj = core_algo(y_new, au_list, main_obj)\n",
        "\n",
        "  while (main_obj - min_obj) > 0.001:\n",
        "      y_new, min_obj = core_algo(y_new, au_list, min_obj)\n",
        "      print(main_obj, min_obj)\n",
        "      if min_obj < main_obj:\n",
        "        main_obj = min_obj\n",
        "        min_obj = 0"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/18 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: UserWarning: This function is deprecated and will be removed in 0.18. Use `skimage.io.load` or `imageio.imread` directly.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "  6%|▌         | 1/18 [01:58<33:35, 118.55s/it]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: UserWarning: This function is deprecated and will be removed in 0.18. Use `skimage.io.load` or `imageio.imread` directly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[-1.6641248e-05 -1.6641248e-05 -1.6641248e-05 ... -1.6641248e-05\n",
            "  -1.6641248e-05 -1.6641248e-05]]\n",
            "[-1.6641248e-05 -1.6641248e-05 -1.6641248e-05 ... -1.6641248e-05\n",
            " -1.6641248e-05 -1.6641248e-05]\n",
            "*************AU1 Classifier*************\n",
            "Pred: [0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 0 1\n",
            " 1 0]\n",
            "Test: [1 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 0 1 1\n",
            " 0 1]\n",
            "AU1 classifier co-eficients: (1, 9216)\n",
            "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
            "          verbose=0),               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.56      0.45        18\n",
            "           1       0.38      0.24      0.29        21\n",
            "\n",
            "    accuracy                           0.38        39\n",
            "   macro avg       0.38      0.40      0.37        39\n",
            "weighted avg       0.38      0.38      0.37        39\n",
            "\n",
            "Confusion matrix:\n",
            "[[10  8]\n",
            " [16  5]]\n",
            "118.54928851127625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "\r 11%|█         | 2/18 [02:56<26:43, 100.23s/it]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: UserWarning: This function is deprecated and will be removed in 0.18. Use `skimage.io.load` or `imageio.imread` directly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[-1.71343004e-05 -1.71343004e-05 -1.71343004e-05 ... -1.71343004e-05\n",
            "  -1.71343004e-05 -1.71343004e-05]]\n",
            "[-1.71343004e-05 -1.71343004e-05 -1.71343004e-05 ... -1.71343004e-05\n",
            " -1.71343004e-05 -1.71343004e-05]\n",
            "*************AU2 Classifier*************\n",
            "Pred: [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1\n",
            " 0 0]\n",
            "Test: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0\n",
            " 0 1]\n",
            "AU2 classifier co-eficients: (1, 9216)\n",
            "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
            "          verbose=0),               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83        32\n",
            "           1       0.17      0.14      0.15         7\n",
            "\n",
            "    accuracy                           0.72        39\n",
            "   macro avg       0.49      0.49      0.49        39\n",
            "weighted avg       0.70      0.72      0.71        39\n",
            "\n",
            "Confusion matrix:\n",
            "[[27  5]\n",
            " [ 6  1]]\n",
            "57.492533922195435\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "\r 17%|█▋        | 3/18 [03:54<21:56, 87.79s/it] /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: UserWarning: This function is deprecated and will be removed in 0.18. Use `skimage.io.load` or `imageio.imread` directly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[1.2647862e-05 1.2647862e-05 1.2647862e-05 ... 1.2647862e-05\n",
            "  1.2647862e-05 1.2647862e-05]]\n",
            "[1.2647862e-05 1.2647862e-05 1.2647862e-05 ... 1.2647862e-05 1.2647862e-05\n",
            " 1.2647862e-05]\n",
            "*************AU4 Classifier*************\n",
            "Pred: [0 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0\n",
            " 1 0]\n",
            "Test: [1 0 0 1 1 1 0 1 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1]\n",
            "AU4 classifier co-eficients: (1, 9216)\n",
            "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
            "          verbose=0),               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.14      0.33      0.19         9\n",
            "           1       0.65      0.37      0.47        30\n",
            "\n",
            "    accuracy                           0.36        39\n",
            "   macro avg       0.39      0.35      0.33        39\n",
            "weighted avg       0.53      0.36      0.40        39\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 3  6]\n",
            " [19 11]]\n",
            "58.739195585250854\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "\r 22%|██▏       | 4/18 [04:53<18:25, 78.97s/it]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: UserWarning: This function is deprecated and will be removed in 0.18. Use `skimage.io.load` or `imageio.imread` directly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[-5.89996218e-06 -5.89996218e-06 -5.89996218e-06 ... -5.89996218e-06\n",
            "  -5.89996218e-06 -5.89996218e-06]]\n",
            "[-5.89996218e-06 -5.89996218e-06 -5.89996218e-06 ... -5.89996218e-06\n",
            " -5.89996218e-06 -5.89996218e-06]\n",
            "*************AU5 Classifier*************\n",
            "Pred: [0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1\n",
            " 0 0]\n",
            "Test: [1 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0\n",
            " 1 1]\n",
            "AU5 classifier co-eficients: (1, 9216)\n",
            "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
            "          verbose=0),               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.65      0.52        17\n",
            "           1       0.57      0.36      0.44        22\n",
            "\n",
            "    accuracy                           0.49        39\n",
            "   macro avg       0.51      0.51      0.48        39\n",
            "weighted avg       0.51      0.49      0.48        39\n",
            "\n",
            "Confusion matrix:\n",
            "[[11  6]\n",
            " [14  8]]\n",
            "58.39708876609802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "\r 28%|██▊       | 5/18 [05:51<15:46, 72.79s/it]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: UserWarning: This function is deprecated and will be removed in 0.18. Use `skimage.io.load` or `imageio.imread` directly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[3.4862286e-06 3.4862286e-06 3.4862286e-06 ... 3.4862286e-06\n",
            "  3.4862286e-06 3.4862286e-06]]\n",
            "[3.4862286e-06 3.4862286e-06 3.4862286e-06 ... 3.4862286e-06 3.4862286e-06\n",
            " 3.4862286e-06]\n",
            "*************AU6 Classifier*************\n",
            "Pred: [1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
            " 0 0]\n",
            "Test: [0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 1\n",
            " 0 0]\n",
            "AU6 classifier co-eficients: (1, 9216)\n",
            "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
            "          verbose=0),               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.79      0.69        24\n",
            "           1       0.38      0.20      0.26        15\n",
            "\n",
            "    accuracy                           0.56        39\n",
            "   macro avg       0.49      0.50      0.48        39\n",
            "weighted avg       0.52      0.56      0.53        39\n",
            "\n",
            "Confusion matrix:\n",
            "[[19  5]\n",
            " [12  3]]\n",
            "58.36734104156494\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "\r 33%|███▎      | 6/18 [06:50<13:42, 68.54s/it]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: UserWarning: This function is deprecated and will be removed in 0.18. Use `skimage.io.load` or `imageio.imread` directly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[2.19672848e-05 2.19672848e-05 2.19672848e-05 ... 2.19672848e-05\n",
            "  2.19672848e-05 2.19672848e-05]]\n",
            "[2.19672848e-05 2.19672848e-05 2.19672848e-05 ... 2.19672848e-05\n",
            " 2.19672848e-05 2.19672848e-05]\n",
            "*************AU7 Classifier*************\n",
            "Pred: [1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
            " 0 1]\n",
            "Test: [1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1]\n",
            "AU7 classifier co-eficients: (1, 9216)\n",
            "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
            "          verbose=0),               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.12      0.38      0.18         8\n",
            "           1       0.64      0.29      0.40        31\n",
            "\n",
            "    accuracy                           0.31        39\n",
            "   macro avg       0.38      0.33      0.29        39\n",
            "weighted avg       0.54      0.31      0.36        39\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 3  5]\n",
            " [22  9]]\n",
            "58.620938539505005\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "\r 39%|███▉      | 7/18 [07:48<11:59, 65.39s/it]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: UserWarning: This function is deprecated and will be removed in 0.18. Use `skimage.io.load` or `imageio.imread` directly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[-8.98578664e-06 -8.98578664e-06 -8.98578664e-06 ... -8.98578664e-06\n",
            "  -8.98578664e-06 -8.98578664e-06]]\n",
            "[-8.98578664e-06 -8.98578664e-06 -8.98578664e-06 ... -8.98578664e-06\n",
            " -8.98578664e-06 -8.98578664e-06]\n",
            "*************AU9 Classifier*************\n",
            "Pred: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
            " 0 0]\n",
            "Test: [0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0]\n",
            "AU9 classifier co-eficients: (1, 9216)\n",
            "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
            "          verbose=0),               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.86      0.90        37\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.82        39\n",
            "   macro avg       0.47      0.43      0.45        39\n",
            "weighted avg       0.89      0.82      0.86        39\n",
            "\n",
            "Confusion matrix:\n",
            "[[32  5]\n",
            " [ 2  0]]\n",
            "58.03705310821533\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "\r 44%|████▍     | 8/18 [08:45<10:29, 62.93s/it]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: UserWarning: This function is deprecated and will be removed in 0.18. Use `skimage.io.load` or `imageio.imread` directly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[-2.0519852e-05 -2.0519852e-05 -2.0519852e-05 ... -2.0519852e-05\n",
            "  -2.0519852e-05 -2.0519852e-05]]\n",
            "[-2.0519852e-05 -2.0519852e-05 -2.0519852e-05 ... -2.0519852e-05\n",
            " -2.0519852e-05 -2.0519852e-05]\n",
            "*************AU10 Classifier*************\n",
            "Pred: [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
            " 0 0]\n",
            "Test: [0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0]\n",
            "AU10 classifier co-eficients: (1, 9216)\n",
            "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
            "          verbose=0),               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95        37\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.90        39\n",
            "   macro avg       0.47      0.47      0.47        39\n",
            "weighted avg       0.90      0.90      0.90        39\n",
            "\n",
            "Confusion matrix:\n",
            "[[35  2]\n",
            " [ 2  0]]\n",
            "57.19796323776245\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "\r 50%|█████     | 9/18 [09:43<09:12, 61.39s/it]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: UserWarning: This function is deprecated and will be removed in 0.18. Use `skimage.io.load` or `imageio.imread` directly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[1.81886401e-06 1.81886401e-06 1.81886401e-06 ... 1.81886401e-06\n",
            "  1.81886401e-06 1.81886401e-06]]\n",
            "[1.81886401e-06 1.81886401e-06 1.81886401e-06 ... 1.81886401e-06\n",
            " 1.81886401e-06 1.81886401e-06]\n",
            "*************AU12 Classifier*************\n",
            "Pred: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0]\n",
            "Test: [0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0]\n",
            "AU12 classifier co-eficients: (1, 9216)\n",
            "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
            "          verbose=0),               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.94      0.87        32\n",
            "           1       0.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.77        39\n",
            "   macro avg       0.41      0.47      0.43        39\n",
            "weighted avg       0.67      0.77      0.71        39\n",
            "\n",
            "Confusion matrix:\n",
            "[[30  2]\n",
            " [ 7  0]]\n",
            "57.780927658081055\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "\r 56%|█████▌    | 10/18 [10:39<07:57, 59.73s/it]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: UserWarning: This function is deprecated and will be removed in 0.18. Use `skimage.io.load` or `imageio.imread` directly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[-1.17364035e-05 -1.17364035e-05 -1.17364035e-05 ... -1.17364035e-05\n",
            "  -1.17364035e-05 -1.17364035e-05]]\n",
            "[-1.17364035e-05 -1.17364035e-05 -1.17364035e-05 ... -1.17364035e-05\n",
            " -1.17364035e-05 -1.17364035e-05]\n",
            "*************AU15 Classifier*************\n",
            "Pred: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0]\n",
            "Test: [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 1\n",
            " 0 0]\n",
            "AU15 classifier co-eficients: (1, 9216)\n",
            "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
            "          verbose=0),               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.97      0.87        31\n",
            "           1       0.00      0.00      0.00         8\n",
            "\n",
            "    accuracy                           0.77        39\n",
            "   macro avg       0.39      0.48      0.43        39\n",
            "weighted avg       0.63      0.77      0.69        39\n",
            "\n",
            "Confusion matrix:\n",
            "[[30  1]\n",
            " [ 8  0]]\n",
            "55.87518620491028\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "\r 61%|██████    | 11/18 [11:36<06:53, 59.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[-1.69955842e-05 -1.69955842e-05 -1.69955842e-05 ... -1.69955842e-05\n",
            "  -1.69955842e-05 -1.69955842e-05]]\n",
            "[-1.69955842e-05 -1.69955842e-05 -1.69955842e-05 ... -1.69955842e-05\n",
            " -1.69955842e-05 -1.69955842e-05]\n",
            "*************AU16 Classifier*************\n",
            "Pred: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
            " 0 0]\n",
            "Test: [0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0]\n",
            "AU16 classifier co-eficients: (1, 9216)\n",
            "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
            "          verbose=0),               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.94      0.89        33\n",
            "           1       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.79        39\n",
            "   macro avg       0.42      0.47      0.44        39\n",
            "weighted avg       0.71      0.79      0.75        39\n",
            "\n",
            "Confusion matrix:\n",
            "[[31  2]\n",
            " [ 6  0]]\n",
            "57.34925580024719\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: UserWarning: This function is deprecated and will be removed in 0.18. Use `skimage.io.load` or `imageio.imread` directly.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            " 67%|██████▋   | 12/18 [12:34<05:52, 58.81s/it]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: UserWarning: This function is deprecated and will be removed in 0.18. Use `skimage.io.load` or `imageio.imread` directly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[1.41320587e-06 1.41320587e-06 1.41320587e-06 ... 1.41320587e-06\n",
            "  1.41320587e-06 1.41320587e-06]]\n",
            "[1.41320587e-06 1.41320587e-06 1.41320587e-06 ... 1.41320587e-06\n",
            " 1.41320587e-06 1.41320587e-06]\n",
            "*************AU17 Classifier*************\n",
            "Pred: [0 0 1 1 0 1 1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 0 0 0 0 0\n",
            " 0 0]\n",
            "Test: [0 1 0 0 1 0 0 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1\n",
            " 1 0]\n",
            "AU17 classifier co-eficients: (1, 9216)\n",
            "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
            "          verbose=0),               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.70      0.62        20\n",
            "           1       0.57      0.42      0.48        19\n",
            "\n",
            "    accuracy                           0.56        39\n",
            "   macro avg       0.57      0.56      0.55        39\n",
            "weighted avg       0.57      0.56      0.56        39\n",
            "\n",
            "Confusion matrix:\n",
            "[[14  6]\n",
            " [11  8]]\n",
            "58.32215762138367\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "\r 72%|███████▏  | 13/18 [13:30<04:50, 58.02s/it]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: UserWarning: This function is deprecated and will be removed in 0.18. Use `skimage.io.load` or `imageio.imread` directly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[-2.24985681e-06 -2.24985681e-06 -2.24985681e-06 ... -2.24985681e-06\n",
            "  -2.24985681e-06 -2.24985681e-06]]\n",
            "[-2.24985681e-06 -2.24985681e-06 -2.24985681e-06 ... -2.24985681e-06\n",
            " -2.24985681e-06 -2.24985681e-06]\n",
            "*************AU20 Classifier*************\n",
            "Pred: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0]\n",
            "Test: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0\n",
            " 0 1]\n",
            "AU20 classifier co-eficients: (1, 9216)\n",
            "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
            "          verbose=0),               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90        32\n",
            "           1       0.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.82        39\n",
            "   macro avg       0.41      0.50      0.45        39\n",
            "weighted avg       0.67      0.82      0.74        39\n",
            "\n",
            "Confusion matrix:\n",
            "[[32  0]\n",
            " [ 7  0]]\n",
            "56.163867473602295\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "\r 78%|███████▊  | 14/18 [14:28<03:51, 57.78s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[1.17673336e-06 1.17673336e-06 1.17673336e-06 ... 1.17673336e-06\n",
            "  1.17673336e-06 1.17673336e-06]]\n",
            "[1.17673336e-06 1.17673336e-06 1.17673336e-06 ... 1.17673336e-06\n",
            " 1.17673336e-06 1.17673336e-06]\n",
            "*************AU23 Classifier*************\n",
            "Pred: [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0]\n",
            "Test: [1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0\n",
            " 1 1]\n",
            "AU23 classifier co-eficients: (1, 9216)\n",
            "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
            "          verbose=0),               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.91      0.70        23\n",
            "           1       0.00      0.00      0.00        16\n",
            "\n",
            "    accuracy                           0.54        39\n",
            "   macro avg       0.28      0.46      0.35        39\n",
            "weighted avg       0.33      0.54      0.41        39\n",
            "\n",
            "Confusion matrix:\n",
            "[[21  2]\n",
            " [16  0]]\n",
            "57.22667622566223\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: UserWarning: This function is deprecated and will be removed in 0.18. Use `skimage.io.load` or `imageio.imread` directly.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 83%|████████▎ | 15/18 [15:25<02:52, 57.62s/it]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: UserWarning: This function is deprecated and will be removed in 0.18. Use `skimage.io.load` or `imageio.imread` directly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[8.5943275e-06 8.5943275e-06 8.5943275e-06 ... 8.5943275e-06\n",
            "  8.5943275e-06 8.5943275e-06]]\n",
            "[8.5943275e-06 8.5943275e-06 8.5943275e-06 ... 8.5943275e-06 8.5943275e-06\n",
            " 8.5943275e-06]\n",
            "*************AU24 Classifier*************\n",
            "Pred: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0]\n",
            "Test: [0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0\n",
            " 1 0]\n",
            "AU24 classifier co-eficients: (1, 9216)\n",
            "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
            "          verbose=0),               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      1.00      0.87        30\n",
            "           1       0.00      0.00      0.00         9\n",
            "\n",
            "    accuracy                           0.77        39\n",
            "   macro avg       0.38      0.50      0.43        39\n",
            "weighted avg       0.59      0.77      0.67        39\n",
            "\n",
            "Confusion matrix:\n",
            "[[30  0]\n",
            " [ 9  0]]\n",
            "57.248656272888184\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "\r 89%|████████▉ | 16/18 [16:23<01:55, 57.71s/it]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: UserWarning: This function is deprecated and will be removed in 0.18. Use `skimage.io.load` or `imageio.imread` directly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[2.1869379e-06 2.1869379e-06 2.1869379e-06 ... 2.1869379e-06\n",
            "  2.1869379e-06 2.1869379e-06]]\n",
            "[2.1869379e-06 2.1869379e-06 2.1869379e-06 ... 2.1869379e-06 2.1869379e-06\n",
            " 2.1869379e-06]\n",
            "*************AU25 Classifier*************\n",
            "Pred: [1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1\n",
            " 1 1]\n",
            "Test: [1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0\n",
            " 0 1]\n",
            "AU25 classifier co-eficients: (1, 9216)\n",
            "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
            "          verbose=0),               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.24      0.35        17\n",
            "           1       0.61      0.91      0.73        22\n",
            "\n",
            "    accuracy                           0.62        39\n",
            "   macro avg       0.64      0.57      0.54        39\n",
            "weighted avg       0.63      0.62      0.56        39\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 4 13]\n",
            " [ 2 20]]\n",
            "57.928117752075195\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "\r 94%|█████████▍| 17/18 [17:20<00:57, 57.60s/it]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: UserWarning: This function is deprecated and will be removed in 0.18. Use `skimage.io.load` or `imageio.imread` directly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[-9.29197747e-06 -9.29197747e-06 -9.29197747e-06 ... -9.29197747e-06\n",
            "  -9.29197747e-06 -9.29197747e-06]]\n",
            "[-9.29197747e-06 -9.29197747e-06 -9.29197747e-06 ... -9.29197747e-06\n",
            " -9.29197747e-06 -9.29197747e-06]\n",
            "*************AU26 Classifier*************\n",
            "Pred: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
            " 0 0]\n",
            "Test: [0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0]\n",
            "AU26 classifier co-eficients: (1, 9216)\n",
            "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
            "          verbose=0),               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87        33\n",
            "           1       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.77        39\n",
            "   macro avg       0.42      0.45      0.43        39\n",
            "weighted avg       0.71      0.77      0.74        39\n",
            "\n",
            "Confusion matrix:\n",
            "[[30  3]\n",
            " [ 6  0]]\n",
            "57.34686017036438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100%|██████████| 18/18 [18:17<00:00, 60.96s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[-1.59656043e-05 -1.59656043e-05 -1.59656043e-05 ... -1.59656043e-05\n",
            "  -1.59656043e-05 -1.59656043e-05]]\n",
            "[-1.59656043e-05 -1.59656043e-05 -1.59656043e-05 ... -1.59656043e-05\n",
            " -1.59656043e-05 -1.59656043e-05]\n",
            "*************AU27 Classifier*************\n",
            "Pred: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1\n",
            " 0 0]\n",
            "Test: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0]\n",
            "AU27 classifier co-eficients: (1, 9216)\n",
            "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
            "          verbose=0),               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95        39\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.90        39\n",
            "   macro avg       0.50      0.45      0.47        39\n",
            "weighted avg       1.00      0.90      0.95        39\n",
            "\n",
            "Confusion matrix:\n",
            "[[35  4]\n",
            " [ 0  0]]\n",
            "56.56250309944153\n",
            "clf_loss:20.56616457627021 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 1.8754740245169248 for [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1] min_loss: 1.8754740245169248 for [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1] under 2.6303727626800537s\n",
            "clf_loss:20.55800025129345 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.0635482094173185 for [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1] min_loss: 1.8754740245169248 for [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1] under 2.610985040664673s\n",
            "clf_loss:19.981901224547137 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.4558100584580167 for [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0] min_loss: 1.8754740245169248 for [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1] under 4.07843542098999s\n",
            "clf_loss:21.5530330260554 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.5430951585418087 for [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1] min_loss: 1.8754740245169248 for [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1] under 4.009232044219971s\n",
            "clf_loss:20.27517311486142 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.6841650893779236 for [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1] min_loss: 1.6841650893779236 for [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1] under 2.446159601211548s\n",
            "clf_loss:19.699074088115108 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.076426938418622 for [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0] min_loss: 1.6841650893779236 for [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1] under 4.400674343109131s\n",
            "clf_loss:21.27020588962337 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.163712038502414 for [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1] min_loss: 1.6841650893779236 for [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1] under 4.334668874740601s\n",
            "clf_loss:19.690909763138343 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.2645011233190155 for [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0] min_loss: 1.6841650893779236 for [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1] under 3.9928135871887207s\n",
            "clf_loss:21.262041564646605 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.3517862234028075 for [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1] min_loss: 1.6841650893779236 for [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1] under 3.9384207725524902s\n",
            "clf_loss:20.685942537900292 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.7440480724435066 for [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0] min_loss: 1.6841650893779236 for [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1] under 5.2429656982421875s\n",
            "clf_loss:22.257074339408554 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.8313331725272985 for [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1] min_loss: 1.6841650893779236 for [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1] under 5.4407665729522705s\n",
            "clf_loss:20.570017549773155 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.4688587523927916 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1] min_loss: 1.4688587523927916 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1] under 2.4938912391662598s\n",
            "clf_loss:19.993918523026842 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 1.86112060143349 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0] min_loss: 1.4688587523927916 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1] under 4.252885341644287s\n",
            "clf_loss:21.565050324535104 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 1.948405701517282 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1] min_loss: 1.4688587523927916 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1] under 4.203505754470825s\n",
            "clf_loss:19.98575419805008 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.0491947863338833 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0] min_loss: 1.4688587523927916 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1] under 4.077990770339966s\n",
            "clf_loss:21.556885999558343 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.136479886417676 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1] min_loss: 1.4688587523927916 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1] under 4.029267311096191s\n",
            "clf_loss:20.98078697281203 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.528741735458374 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0] min_loss: 1.4688587523927916 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1] under 5.460686445236206s\n",
            "clf_loss:22.551918774320292 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.6160268355421668 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1] min_loss: 1.4688587523927916 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1] under 5.459424734115601s\n",
            "clf_loss:19.70292706161805 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.6349356176565395 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0] min_loss: 1.4688587523927916 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1] under 3.8222804069519043s\n",
            "clf_loss:21.27405886312631 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.722220717740332 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1] min_loss: 1.4688587523927916 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1] under 3.8348371982574463s\n",
            "clf_loss:20.697959836379997 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.11448256678103 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0] min_loss: 1.4688587523927916 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1] under 5.3524010181427s\n",
            "clf_loss:22.26909163788826 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.2017676668648223 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1] min_loss: 1.4688587523927916 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1] under 5.49989914894104s\n",
            "clf_loss:20.689795511403236 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.302556751681424 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0] min_loss: 1.4688587523927916 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1] under 4.9654412269592285s\n",
            "clf_loss:22.260927312911498 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.3898418517652162 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1] min_loss: 1.4688587523927916 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1] under 5.011459827423096s\n",
            "clf_loss:21.684828286165185 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.7821037008059144 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0] min_loss: 1.4688587523927916 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1] under 6.3466575145721436s\n",
            "clf_loss:23.255960087673447 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.869388800889707 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1] min_loss: 1.4688587523927916 for [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1] under 6.302422523498535s\n",
            "clf_loss:20.790396999802724 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.4636640308532378 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1] min_loss: 1.4636640308532378 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1] under 2.0129706859588623s\n",
            "clf_loss:20.21429797305641 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 1.8559258798939358 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0] min_loss: 1.4636640308532378 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1] under 3.782606601715088s\n",
            "clf_loss:21.785429774564673 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 1.9432109799777284 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1] min_loss: 1.4636640308532378 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1] under 3.895301580429077s\n",
            "clf_loss:20.20613364807965 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 2.9106667314609966 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0] min_loss: 1.4636640308532378 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1] under 3.4134762287139893s\n",
            "clf_loss:21.77726544958791 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 2.997951831544789 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1] min_loss: 1.4636640308532378 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1] under 3.4826300144195557s\n",
            "clf_loss:21.2011664228416 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.3902136805854868 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0] min_loss: 1.4636640308532378 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1] under 4.930962085723877s\n",
            "clf_loss:22.77229822434986 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.477498780669279 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1] min_loss: 1.4636640308532378 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1] under 4.709436655044556s\n",
            "clf_loss:19.923306511647617 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.6646169447549346 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0] min_loss: 1.4636640308532378 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1] under 3.762059450149536s\n",
            "clf_loss:21.49443831315588 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.7519020448387268 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1] min_loss: 1.4636640308532378 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1] under 3.698716163635254s\n",
            "clf_loss:20.918339286409566 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.144163893879425 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0] min_loss: 1.4636640308532378 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1] under 5.580211877822876s\n",
            "clf_loss:22.489471087917828 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.2314489939632174 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1] min_loss: 1.4636640308532378 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1] under 5.635113716125488s\n",
            "clf_loss:20.910174961432805 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.1989047454464856 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0] min_loss: 1.4636640308532378 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1] under 4.835050821304321s\n",
            "clf_loss:22.481306762941067 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.286189845530278 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1] min_loss: 1.4636640308532378 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1] under 4.628914833068848s\n",
            "clf_loss:21.905207736194754 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.678451694570976 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0] min_loss: 1.4636640308532378 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1] under 6.334609746932983s\n",
            "clf_loss:23.476339537703016 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.7657367946547686 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1] min_loss: 1.4636640308532378 for [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1] under 6.275404214859009s\n",
            "clf_loss:20.218150946559355 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 3.608673095703125s\n",
            "clf_loss:21.789282748067617 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.5365957078535952 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 3.5335774421691895s\n",
            "clf_loss:21.213183721321304 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 1.9288575568942932 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.342759370803833s\n",
            "clf_loss:22.784315522829566 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.0161426569780856 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.2966413497924805s\n",
            "clf_loss:21.205019396344543 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 2.983598408461354 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.609400272369385s\n",
            "clf_loss:22.776151197852805 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.0708835085451462 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.735265016555786s\n",
            "clf_loss:22.200052171106492 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.463145357585844 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.227325201034546s\n",
            "clf_loss:23.771183972614754 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.5504304576696364 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.189276456832886s\n",
            "clf_loss:20.92219225991251 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.7026725731173429 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.889564514160156s\n",
            "clf_loss:22.493324061420772 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.7899576732011353 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.828166723251343s\n",
            "clf_loss:21.91722503467446 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.1822195222418332 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.446372985839844s\n",
            "clf_loss:23.48835683618272 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.2695046223256257 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.649233818054199s\n",
            "clf_loss:21.909060709697698 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.236960373808894 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.701282024383545s\n",
            "clf_loss:23.48019251120596 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.3242454738926863 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.736742258071899s\n",
            "clf_loss:22.904093484459647 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.7165073229333845 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 7.135733127593994s\n",
            "clf_loss:24.47522528596791 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.8037924230171765 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 7.081872940063477s\n",
            "clf_loss:18.571131801508262 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.257240422545713 eq19_loss:0\n",
            "sample: 0 x_loss: 2.480624887746659 for [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 3.068798303604126s\n",
            "clf_loss:17.99503277476195 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.257240422545713 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.872886736787357 for [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.536057710647583s\n",
            "clf_loss:19.56616457627021 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.257240422545713 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.960171836871149 for [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.535215616226196s\n",
            "clf_loss:17.986868449785188 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:43.28755238520845 eq19_loss:0\n",
            "sample: 0 x_loss: 4.060960921687752 for [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.438302516937256s\n",
            "clf_loss:19.55800025129345 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:43.28755238520845 eq19_loss:0\n",
            "sample: 0 x_loss: 4.148246021771544 for [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.443522930145264s\n",
            "clf_loss:18.981901224547137 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:43.28755238520845 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.540507870812243 for [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.497251987457275s\n",
            "clf_loss:20.5530330260554 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:43.28755238520845 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.627792970896035 for [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.4027183055877686s\n",
            "clf_loss:17.70404131335316 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.923907089212381 eq19_loss:0\n",
            "sample: 0 x_loss: 2.3842481409479723 for [0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 3.828972101211548s\n",
            "clf_loss:19.27517311486142 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.923907089212381 eq19_loss:0\n",
            "sample: 0 x_loss: 2.471533241031765 for [0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 3.906071901321411s\n",
            "clf_loss:18.699074088115104 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.923907089212381 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.863795090072463 for [0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.358901500701904s\n",
            "clf_loss:20.270205889623366 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.923907089212381 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.951080190156255 for [0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.425976753234863s\n",
            "clf_loss:18.690909763138343 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:41.954219051875114 eq19_loss:0\n",
            "sample: 0 x_loss: 4.051869274972857 for [0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.75859522819519s\n",
            "clf_loss:20.262041564646605 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:41.954219051875114 eq19_loss:0\n",
            "sample: 0 x_loss: 4.139154375056649 for [0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.696300983428955s\n",
            "clf_loss:19.685942537900292 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:41.954219051875114 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.531416224097347 for [0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.023643732070923s\n",
            "clf_loss:21.257074339408554 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:41.954219051875114 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.61870132418114 for [0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.037240743637085s\n",
            "clf_loss:17.998885748264893 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.479462644767938 eq19_loss:0\n",
            "sample: 0 x_loss: 2.367506032564459 for [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.37222695350647s\n",
            "clf_loss:19.570017549773155 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.479462644767938 eq19_loss:0\n",
            "sample: 0 x_loss: 2.454791132648251 for [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.327124357223511s\n",
            "clf_loss:18.993918523026842 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.479462644767938 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.8470529816889494 for [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.725099325180054s\n",
            "clf_loss:20.565050324535104 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.479462644767938 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.934338081772742 for [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.466885805130005s\n",
            "clf_loss:18.98575419805008 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:41.50977460743067 eq19_loss:0\n",
            "sample: 0 x_loss: 4.035127166589343 for [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.46108603477478s\n",
            "clf_loss:20.556885999558343 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:41.50977460743067 eq19_loss:0\n",
            "sample: 0 x_loss: 4.122412266673136 for [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.408064365386963s\n",
            "clf_loss:19.98078697281203 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:41.50977460743067 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.514674115713834 for [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.376530170440674s\n",
            "clf_loss:21.551918774320292 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:41.50977460743067 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.601959215797626 for [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.5013556480407715s\n",
            "clf_loss:18.70292706161805 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.146129311434601 eq19_loss:0\n",
            "sample: 0 x_loss: 2.323538337211615 for [0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.670468091964722s\n",
            "clf_loss:20.27405886312631 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.146129311434601 eq19_loss:0\n",
            "sample: 0 x_loss: 2.4108234372954076 for [0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.601221799850464s\n",
            "clf_loss:19.697959836379997 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.146129311434601 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.8030852863361053 for [0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.791499137878418s\n",
            "clf_loss:21.26909163788826 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.146129311434601 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.8903703864198977 for [0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.0095601081848145s\n",
            "clf_loss:19.689795511403236 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:40.17644127409733 eq19_loss:0\n",
            "sample: 0 x_loss: 3.9911594712364993 for [0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.332517623901367s\n",
            "clf_loss:21.260927312911498 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:40.17644127409733 eq19_loss:0\n",
            "sample: 0 x_loss: 4.078444571320292 for [0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.349300384521484s\n",
            "clf_loss:20.684828286165185 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:40.17644127409733 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.47070642036099 for [0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.38212251663208s\n",
            "clf_loss:22.255960087673447 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:40.17644127409733 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.557991520444783 for [0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.431894540786743s\n",
            "clf_loss:18.219265198294462 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.257240422545713 eq19_loss:0\n",
            "sample: 0 x_loss: 2.4610767431236704 for [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 3.8206303119659424s\n",
            "clf_loss:19.790396999802724 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.257240422545713 eq19_loss:0\n",
            "sample: 0 x_loss: 2.5483618432074624 for [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 3.914137601852417s\n",
            "clf_loss:19.21429797305641 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.257240422545713 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.940623692248161 for [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.404352426528931s\n",
            "clf_loss:20.785429774564673 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.257240422545713 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.027908792331953 for [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.38212251663208s\n",
            "clf_loss:19.20613364807965 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:40.88755238520845 eq19_loss:0\n",
            "sample: 0 x_loss: 3.9953645438152217 for [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.853024244308472s\n",
            "clf_loss:20.77726544958791 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:40.88755238520845 eq19_loss:0\n",
            "sample: 0 x_loss: 4.082649643899014 for [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.793825626373291s\n",
            "clf_loss:20.2011664228416 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:40.88755238520845 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.474911492939713 for [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.9343581199646s\n",
            "clf_loss:21.77229822434986 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:40.88755238520845 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.562196593023504 for [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.026476860046387s\n",
            "clf_loss:18.923306511647617 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.923907089212381 eq19_loss:0\n",
            "sample: 0 x_loss: 2.4519850964087757 for [0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.677964448928833s\n",
            "clf_loss:20.49443831315588 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.923907089212381 eq19_loss:0\n",
            "sample: 0 x_loss: 2.539270196492568 for [0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.684217214584351s\n",
            "clf_loss:19.918339286409566 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.923907089212381 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.9315320455332663 for [0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.184506416320801s\n",
            "clf_loss:21.489471087917828 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.923907089212381 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.0188171456170583 for [0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.124269723892212s\n",
            "clf_loss:19.910174961432805 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.55421905187511 eq19_loss:0\n",
            "sample: 0 x_loss: 3.986272897100327 for [0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.121951580047607s\n",
            "clf_loss:21.481306762941067 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.55421905187511 eq19_loss:0\n",
            "sample: 0 x_loss: 4.0735579971841185 for [0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.216953277587891s\n",
            "clf_loss:20.905207736194754 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.55421905187511 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.465819846224817 for [0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.4341161251068115s\n",
            "clf_loss:22.476339537703016 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.55421905187511 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.55310494630861 for [0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.391155004501343s\n",
            "clf_loss:19.218150946559355 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.479462644767938 eq19_loss:0\n",
            "sample: 0 x_loss: 2.4352429880252626 for [0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.978150129318237s\n",
            "clf_loss:20.789282748067617 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.479462644767938 eq19_loss:0\n",
            "sample: 0 x_loss: 2.5225280881090546 for [0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.012700080871582s\n",
            "clf_loss:20.213183721321304 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.479462644767938 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.914789937149753 for [0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.177932977676392s\n",
            "clf_loss:21.784315522829566 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.479462644767938 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.002075037233545 for [0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.404553174972534s\n",
            "clf_loss:20.205019396344543 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.109774607430666 eq19_loss:0\n",
            "sample: 0 x_loss: 3.969530788716813 for [0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.853419542312622s\n",
            "clf_loss:21.776151197852805 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.109774607430666 eq19_loss:0\n",
            "sample: 0 x_loss: 4.056815888800606 for [0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.796592712402344s\n",
            "clf_loss:21.200052171106492 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.109774607430666 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.449077737841304 for [0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.898051500320435s\n",
            "clf_loss:22.771183972614754 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.109774607430666 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.536362837925096 for [0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.836664915084839s\n",
            "clf_loss:19.92219225991251 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.146129311434601 eq19_loss:0\n",
            "sample: 0 x_loss: 2.3912752926724186 for [0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.313225269317627s\n",
            "clf_loss:21.493324061420772 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.146129311434601 eq19_loss:0\n",
            "sample: 0 x_loss: 2.478560392756211 for [0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.33025860786438s\n",
            "clf_loss:20.91722503467446 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.146129311434601 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.870822241796909 for [0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.672876596450806s\n",
            "clf_loss:22.48835683618272 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.146129311434601 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.958107341880701 for [0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.8034563064575195s\n",
            "clf_loss:20.909060709697698 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.77644127409733 eq19_loss:0\n",
            "sample: 0 x_loss: 3.9255630933639702 for [0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.799098491668701s\n",
            "clf_loss:22.48019251120596 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.77644127409733 eq19_loss:0\n",
            "sample: 0 x_loss: 4.012848193447762 for [0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.503659009933472s\n",
            "clf_loss:21.904093484459647 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.77644127409733 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.40511004248846 for [0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.702470064163208s\n",
            "clf_loss:23.47522528596791 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.77644127409733 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.492395142572253 for [0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.7096617221832275s\n",
            "clf_loss:20.583427898845603 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.452165747466731 for [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 2.6801979541778564s\n",
            "clf_loss:20.00732887209929 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 1.8444275965074293 for [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.380998134613037s\n",
            "clf_loss:21.57846067360755 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 1.9317126965912215 for [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.365195274353027s\n",
            "clf_loss:19.99916454712253 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.032501781407823 for [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 3.923793077468872s\n",
            "clf_loss:21.57029634863079 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.119786881491615 for [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.025268793106079s\n",
            "clf_loss:20.994197321884478 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.5120487305323134 for [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.365593910217285s\n",
            "clf_loss:22.56532912339274 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.599333830616106 for [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.450919151306152s\n",
            "clf_loss:19.716337410690496 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.6531186613684279 for [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.343703508377075s\n",
            "clf_loss:21.287469212198758 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.74040376145222 for [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 4.290971755981445s\n",
            "clf_loss:20.711370185452445 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.1326656104929183 for [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.726979494094849s\n",
            "clf_loss:22.282501986960707 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.2199507105767107 for [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.0569775104522705s\n",
            "clf_loss:20.703205860475684 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.320739795393312 for [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.262553691864014s\n",
            "clf_loss:22.274337661983946 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.4080248954771046 for [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 5.322990417480469s\n",
            "clf_loss:21.698238635237633 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.8002867445178032 for [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.647255897521973s\n",
            "clf_loss:23.269370436745895 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.887571844601595 for [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1] min_loss: 1.4493106077698028 for [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0] under 6.5943543910980225s\n",
            "clf_loss:20.01118184560223 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.4378123243832959 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0] min_loss: 1.4378123243832959 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0] under 3.9844279289245605s\n",
            "clf_loss:21.582313647110492 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.5250974244670883 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1] min_loss: 1.4378123243832959 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0] under 4.133978843688965s\n",
            "clf_loss:21.00621462036418 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 1.9173592735077862 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0] min_loss: 1.4378123243832959 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0] under 5.725042343139648s\n",
            "clf_loss:22.57734642187244 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.004644373591579 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1] min_loss: 1.4378123243832959 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0] under 5.840384244918823s\n",
            "clf_loss:20.99805029538742 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.1054334584081804 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0] min_loss: 1.4378123243832959 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0] under 5.210907697677612s\n",
            "clf_loss:22.56918209689568 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.1927185584919724 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1] min_loss: 1.4378123243832959 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0] under 5.217418432235718s\n",
            "clf_loss:21.993083070149368 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.584980407532671 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0] min_loss: 1.4378123243832959 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0] under 6.3531813621521s\n",
            "clf_loss:23.56421487165763 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.6722655076164634 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1] min_loss: 1.4378123243832959 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0] under 6.486636638641357s\n",
            "clf_loss:20.715223158955386 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.691174289730836 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0] min_loss: 1.4378123243832959 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0] under 5.347832679748535s\n",
            "clf_loss:22.286354960463648 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.7784593898146284 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1] min_loss: 1.4378123243832959 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0] under 5.371111154556274s\n",
            "clf_loss:21.710255933717335 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.1707212388553265 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0] min_loss: 1.4378123243832959 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0] under 6.965151309967041s\n",
            "clf_loss:23.281387735225596 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.258006338939119 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1] min_loss: 1.4378123243832959 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0] under 6.866214275360107s\n",
            "clf_loss:21.702091608740574 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.3587954237557205 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0] min_loss: 1.4378123243832959 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0] under 5.82171893119812s\n",
            "clf_loss:23.273223410248836 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.446080523839513 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1] min_loss: 1.4378123243832959 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0] under 6.034964561462402s\n",
            "clf_loss:22.697124383502523 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.838342372880211 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 0] min_loss: 1.4378123243832959 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0] under 7.309203147888184s\n",
            "clf_loss:24.268256185010785 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.9256274729640035 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1] min_loss: 1.4378123243832959 for [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0] under 7.254947662353516s\n",
            "clf_loss:20.2315612956318 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 3.7594127655029297s\n",
            "clf_loss:21.80269309714006 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.5199027029275343 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 3.82450008392334s\n",
            "clf_loss:21.226594070393748 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 1.9121645519682327 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.29524040222168s\n",
            "clf_loss:22.79772587190201 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 1.9994496520520246 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.47503662109375s\n",
            "clf_loss:21.218429745416987 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 2.966905403535293 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.755523681640625s\n",
            "clf_loss:22.78956154692525 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.0541905036190853 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.828376054763794s\n",
            "clf_loss:22.213462520178936 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.4464523526597834 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.030416965484619s\n",
            "clf_loss:23.784594321687198 eq8_loss:0 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.5337374527435754 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.049123048782349s\n",
            "clf_loss:20.935602608984954 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.720855616829231 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.149797201156616s\n",
            "clf_loss:22.506734410493216 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.8081407169130235 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.399542331695557s\n",
            "clf_loss:21.930635383746903 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.2004025659537216 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.134671449661255s\n",
            "clf_loss:23.501767185255165 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.287687666037514 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.069415092468262s\n",
            "clf_loss:21.922471058770142 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.2551434175207823 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.01690673828125s\n",
            "clf_loss:23.493602860278404 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.3424285176045747 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.012535572052002s\n",
            "clf_loss:22.91750383353209 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.734690366645273 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.108593702316284s\n",
            "clf_loss:24.488635635040353 eq8_loss:4.4842429383856475 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.8219754667290653 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.457710027694702s\n",
            "clf_loss:21.230447043896696 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.5055492798440995 for [0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.037693023681641s\n",
            "clf_loss:22.801578845404958 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.592834379927892 for [0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.187084913253784s\n",
            "clf_loss:22.225479818658645 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 1.9850962289685898 for [0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.747020483016968s\n",
            "clf_loss:23.796611620166907 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.0723813290523823 for [0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.74803900718689s\n",
            "clf_loss:22.217315493681884 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.0398370805356505 for [0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.74990177154541s\n",
            "clf_loss:23.788447295190146 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.127122180619443 for [0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.8665549755096436s\n",
            "clf_loss:23.212348268443833 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.5193840296601406 for [0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.100018262863159s\n",
            "clf_loss:24.783480069952095 eq8_loss:0.31388443774154035 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.606669129743933 for [0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.161943197250366s\n",
            "clf_loss:21.93448835724985 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.7589112451916398 for [0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.303230285644531s\n",
            "clf_loss:23.505620158758113 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.846196345275432 for [0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.317042350769043s\n",
            "clf_loss:22.9295211320118 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.23845819431613 for [0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.637593746185303s\n",
            "clf_loss:24.500652933520062 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.3257432943999223 for [0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.959305763244629s\n",
            "clf_loss:22.92135680703504 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.2931990458831906 for [0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.746219158172607s\n",
            "clf_loss:24.4924886085433 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.3804841459669834 for [0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.7260212898254395s\n",
            "clf_loss:23.916389581796988 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.772745995007681 for [0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.028247594833374s\n",
            "clf_loss:25.48752138330525 eq8_loss:4.170358500644107 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.8600310950914736 for [0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.9284422397613525s\n",
            "clf_loss:18.01229609733734 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.016276567124027 eq19_loss:0\n",
            "sample: 0 x_loss: 2.436191578880403 for [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.308844566345215s\n",
            "clf_loss:19.583427898845603 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.016276567124027 eq19_loss:0\n",
            "sample: 0 x_loss: 2.5234766789641956 for [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.547566175460815s\n",
            "clf_loss:19.00732887209929 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.016276567124027 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.9157385280048937 for [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.842315912246704s\n",
            "clf_loss:20.57846067360755 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.016276567124027 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.0030236280886857 for [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.772668361663818s\n",
            "clf_loss:18.999164547122525 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:43.04658852978676 eq19_loss:0\n",
            "sample: 0 x_loss: 4.103812712905287 for [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.355526447296143s\n",
            "clf_loss:20.570296348630787 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:43.04658852978676 eq19_loss:0\n",
            "sample: 0 x_loss: 4.191097812989081 for [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.338718891143799s\n",
            "clf_loss:19.994197321884474 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:43.04658852978676 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.583359662029778 for [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.125813245773315s\n",
            "clf_loss:21.565329123392736 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:43.04658852978676 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.670644762113571 for [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.350951910018921s\n",
            "clf_loss:18.716337410690496 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.682943233790693 eq19_loss:0\n",
            "sample: 0 x_loss: 2.427099932165509 for [0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.112096786499023s\n",
            "clf_loss:20.287469212198758 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.682943233790693 eq19_loss:0\n",
            "sample: 0 x_loss: 2.514385032249301 for [0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.199988842010498s\n",
            "clf_loss:19.711370185452445 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.682943233790693 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.906646881289999 for [0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.470949172973633s\n",
            "clf_loss:21.282501986960707 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.682943233790693 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.9939319813737915 for [0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.541984796524048s\n",
            "clf_loss:19.703205860475684 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:41.713255196453424 eq19_loss:0\n",
            "sample: 0 x_loss: 4.0947210661903926 for [0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.421449184417725s\n",
            "clf_loss:21.274337661983946 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:41.713255196453424 eq19_loss:0\n",
            "sample: 0 x_loss: 4.182006166274186 for [0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.64599347114563s\n",
            "clf_loss:20.698238635237633 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:41.713255196453424 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.574268015314884 for [0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.690282583236694s\n",
            "clf_loss:22.269370436745895 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:41.713255196453424 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.661553115398676 for [0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.680420398712158s\n",
            "clf_loss:19.01118184560223 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.23849878934625 eq19_loss:0\n",
            "sample: 0 x_loss: 2.410357823781995 for [0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.489633321762085s\n",
            "clf_loss:20.582313647110492 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.23849878934625 eq19_loss:0\n",
            "sample: 0 x_loss: 2.497642923865788 for [0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.434866905212402s\n",
            "clf_loss:20.00621462036418 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.23849878934625 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.8899047729064855 for [0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.514453649520874s\n",
            "clf_loss:21.57734642187244 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.23849878934625 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.977189872990278 for [0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.808437347412109s\n",
            "clf_loss:19.99805029538742 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:41.26881075200898 eq19_loss:0\n",
            "sample: 0 x_loss: 4.07797895780688 for [0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.05571436882019s\n",
            "clf_loss:21.56918209689568 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:41.26881075200898 eq19_loss:0\n",
            "sample: 0 x_loss: 4.1652640578906714 for [0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.154548406600952s\n",
            "clf_loss:20.993083070149368 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:41.26881075200898 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.557525906931371 for [0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.074724435806274s\n",
            "clf_loss:22.56421487165763 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:41.26881075200898 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.6448110070151625 for [0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.958415746688843s\n",
            "clf_loss:19.71522315895539 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.905165456012913 eq19_loss:0\n",
            "sample: 0 x_loss: 2.3663901284291513 for [0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.74423360824585s\n",
            "clf_loss:21.28635496046365 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.905165456012913 eq19_loss:0\n",
            "sample: 0 x_loss: 2.453675228512944 for [0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.749557971954346s\n",
            "clf_loss:20.710255933717338 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.905165456012913 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.8459370775536414 for [0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.866797924041748s\n",
            "clf_loss:22.2813877352256 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.905165456012913 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.9332221776374343 for [0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.917163610458374s\n",
            "clf_loss:20.702091608740577 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.935477418675646 eq19_loss:0\n",
            "sample: 0 x_loss: 4.034011262454036 for [0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.00442099571228s\n",
            "clf_loss:22.27322341024884 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.935477418675646 eq19_loss:0\n",
            "sample: 0 x_loss: 4.121296362537829 for [0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.987898826599121s\n",
            "clf_loss:21.697124383502526 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.935477418675646 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.513558211578527 for [0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.587953329086304s\n",
            "clf_loss:23.268256185010788 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.935477418675646 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.600843311662319 for [0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.898334980010986s\n",
            "clf_loss:19.2315612956318 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.016276567124027 eq19_loss:0\n",
            "sample: 0 x_loss: 2.5039285343412065 for [0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.209384918212891s\n",
            "clf_loss:20.80269309714006 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.016276567124027 eq19_loss:0\n",
            "sample: 0 x_loss: 2.591213634424999 for [0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.233710289001465s\n",
            "clf_loss:20.226594070393748 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.016276567124027 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.9834754834656967 for [0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.562545299530029s\n",
            "clf_loss:21.79772587190201 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.016276567124027 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.0707605835494896 for [0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.650967836380005s\n",
            "clf_loss:20.218429745416987 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:40.646588529786754 eq19_loss:0\n",
            "sample: 0 x_loss: 4.038216335032757 for [0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.626360893249512s\n",
            "clf_loss:21.78956154692525 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:40.646588529786754 eq19_loss:0\n",
            "sample: 0 x_loss: 4.125501435116551 for [0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.801160097122192s\n",
            "clf_loss:21.213462520178936 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:40.646588529786754 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.517763284157248 for [0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.905372381210327s\n",
            "clf_loss:22.784594321687198 eq8_loss:6.267320199830333 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:40.646588529786754 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.605048384241041 for [0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.711059093475342s\n",
            "clf_loss:19.935602608984958 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.682943233790693 eq19_loss:0\n",
            "sample: 0 x_loss: 2.494836887626312 for [0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.8536131381988525s\n",
            "clf_loss:21.50673441049322 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.682943233790693 eq19_loss:0\n",
            "sample: 0 x_loss: 2.5821219877101047 for [0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.628122806549072s\n",
            "clf_loss:20.930635383746907 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.682943233790693 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.9743838367508024 for [0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.215035438537598s\n",
            "clf_loss:22.50176718525517 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.682943233790693 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.061668936834595 for [0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.182116985321045s\n",
            "clf_loss:20.922471058770146 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.313255196453426 eq19_loss:0\n",
            "sample: 0 x_loss: 4.029124688317863 for [0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.012239694595337s\n",
            "clf_loss:22.493602860278408 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.313255196453426 eq19_loss:0\n",
            "sample: 0 x_loss: 4.116409788401656 for [0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.9787468910217285s\n",
            "clf_loss:21.917503833532095 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.313255196453426 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.508671637442354 for [0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.984440803527832s\n",
            "clf_loss:23.488635635040357 eq8_loss:6.7329625789424075 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.313255196453426 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.595956737526146 for [0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.857095956802368s\n",
            "clf_loss:20.230447043896696 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.23849878934625 eq19_loss:0\n",
            "sample: 0 x_loss: 2.4780947792427988 for [0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.1032679080963135s\n",
            "clf_loss:21.801578845404958 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.23849878934625 eq19_loss:0\n",
            "sample: 0 x_loss: 2.565379879326591 for [0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.1875903606414795s\n",
            "clf_loss:21.225479818658645 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.23849878934625 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.9576417283672893 for [0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.38461446762085s\n",
            "clf_loss:22.796611620166907 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.23849878934625 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.0449268284510813 for [0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.365876913070679s\n",
            "clf_loss:21.217315493681884 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:38.86881075200898 eq19_loss:0\n",
            "sample: 0 x_loss: 4.01238257993435 for [0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.38518500328064s\n",
            "clf_loss:22.788447295190146 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:38.86881075200898 eq19_loss:0\n",
            "sample: 0 x_loss: 4.0996676800181415 for [0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.190889835357666s\n",
            "clf_loss:22.212348268443833 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:38.86881075200898 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.49192952905884 for [0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.385116100311279s\n",
            "clf_loss:23.783480069952095 eq8_loss:6.581204637571874 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:38.86881075200898 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.579214629142633 for [0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.320155382156372s\n",
            "clf_loss:20.93448835724985 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.905165456012913 eq19_loss:0\n",
            "sample: 0 x_loss: 2.4341270838899547 for [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.304614305496216s\n",
            "clf_loss:22.505620158758113 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.905165456012913 eq19_loss:0\n",
            "sample: 0 x_loss: 2.5214121839737476 for [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.341296195983887s\n",
            "clf_loss:21.9295211320118 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.905165456012913 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.9136740330144453 for [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.554251194000244s\n",
            "clf_loss:23.500652933520062 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.905165456012913 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.0009591330982373 for [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.492977142333984s\n",
            "clf_loss:21.92135680703504 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.53547741867565 eq19_loss:0\n",
            "sample: 0 x_loss: 3.968414884581506 for [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.142725229263306s\n",
            "clf_loss:23.4924886085433 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.53547741867565 eq19_loss:0\n",
            "sample: 0 x_loss: 4.055699984665299 for [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.325720310211182s\n",
            "clf_loss:22.916389581796988 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.53547741867565 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.447961833705997 for [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.173081874847412s\n",
            "clf_loss:24.48752138330525 eq8_loss:6.419078141200867 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.53547741867565 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.535246933789789 for [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.158142566680908s\n",
            "clf_loss:20.780669927447804 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.7350276467701216 for [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 2.2954704761505127s\n",
            "clf_loss:20.20457090070149 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.1272894958108197 for [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.175481796264648s\n",
            "clf_loss:21.775702702209752 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.214574595894612 for [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.2134106159210205s\n",
            "clf_loss:20.19640657572473 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.3153636807112132 for [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 3.817357063293457s\n",
            "clf_loss:21.76753837723299 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.402648780795006 for [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 3.8376879692077637s\n",
            "clf_loss:21.19143935048668 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.7949106298357043 for [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.295337677001953s\n",
            "clf_loss:22.76257115199494 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.8821957299194967 for [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.255181074142456s\n",
            "clf_loss:19.913579439292697 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.6958629805598937 for [0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 3.6604483127593994s\n",
            "clf_loss:21.48471124080096 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.7831480806436864 for [0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 3.813488721847534s\n",
            "clf_loss:20.908612214054646 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.1754099296843843 for [0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.572852373123169s\n",
            "clf_loss:22.479744015562908 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.2626950297681763 for [0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.559595108032227s\n",
            "clf_loss:20.900447889077885 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.3634841145847783 for [0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.938522815704346s\n",
            "clf_loss:22.471579690586147 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.4507692146685702 for [0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.820271253585815s\n",
            "clf_loss:21.895480663839834 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.843031063709269 for [0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.195618391036987s\n",
            "clf_loss:23.466612465348096 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.930316163793061 for [0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.4950480461120605s\n",
            "clf_loss:20.208423874204435 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.7206742236866868 for [0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 3.893498182296753s\n",
            "clf_loss:21.779555675712697 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.8079593237704792 for [0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.002428770065308s\n",
            "clf_loss:21.203456648966384 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.2002211728111774 for [0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.62796688079834s\n",
            "clf_loss:22.774588450474646 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.2875062728949698 for [0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.6295857429504395s\n",
            "clf_loss:21.195292323989623 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.3882953577115713 for [0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.924656629562378s\n",
            "clf_loss:22.766424125497885 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.4755804577953637 for [0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.214189767837524s\n",
            "clf_loss:22.190325098751572 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.867842306836062 for [0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.520081520080566s\n",
            "clf_loss:23.761456900259834 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.955127406919854 for [0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.564452648162842s\n",
            "clf_loss:20.91246518755759 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.7339186089223024 for [0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.919386625289917s\n",
            "clf_loss:22.483596989065852 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.8212037090060949 for [0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.891840934753418s\n",
            "clf_loss:21.90749796231954 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.213465558046793 for [0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.366123199462891s\n",
            "clf_loss:23.4786297638278 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.300750658130585 for [0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.770931005477905s\n",
            "clf_loss:21.899333637342778 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.401539742947187 for [0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.861727237701416s\n",
            "clf_loss:23.47046543885104 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.488824843030979 for [0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.84757399559021s\n",
            "clf_loss:22.894366412104727 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.881086692071677 for [0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.294220447540283s\n",
            "clf_loss:24.46549821361299 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.96837179215547 for [0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.071437835693359s\n",
            "clf_loss:20.428803324234003 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.7154795021471327 for [0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 3.4718854427337646s\n",
            "clf_loss:21.999935125742265 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.8027646022309252 for [0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 3.5346858501434326s\n",
            "clf_loss:21.423836098995952 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.195026451271623 for [0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.412694692611694s\n",
            "clf_loss:22.994967900504214 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.2823115513554155 for [0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.343986511230469s\n",
            "clf_loss:21.41567177401919 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.2497673028386838 for [0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.777019262313843s\n",
            "clf_loss:22.986803575527453 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.337052402922476 for [0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.669192314147949s\n",
            "clf_loss:22.41070454878114 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.7293142519631743 for [0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.883431434631348s\n",
            "clf_loss:23.981836350289402 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.8165993520469663 for [0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.131956100463867s\n",
            "clf_loss:21.13284463758716 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.7635999360206975 for [0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.075642347335815s\n",
            "clf_loss:22.70397643909542 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.8508850361044895 for [0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.014282941818237s\n",
            "clf_loss:22.127877412349108 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.2431468851451877 for [0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.804206371307373s\n",
            "clf_loss:23.69900921385737 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.33043198522898 for [0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.749862194061279s\n",
            "clf_loss:22.119713087372347 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.2978877367122483 for [0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.576792001724243s\n",
            "clf_loss:23.69084488888061 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.3851728367960408 for [0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.808824777603149s\n",
            "clf_loss:23.114745862134296 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.777434685836739 for [0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.130032062530518s\n",
            "clf_loss:24.685877663642557 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.864719785920531 for [0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.13889741897583s\n",
            "clf_loss:21.427689072498897 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.7884111791474904 for [0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.075990200042725s\n",
            "clf_loss:22.99882087400716 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.8756962792312828 for [0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.095333099365234s\n",
            "clf_loss:22.422721847260846 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.2679581282719807 for [0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.51702356338501s\n",
            "clf_loss:23.993853648769107 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.355243228355773 for [0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.7754433155059814s\n",
            "clf_loss:22.414557522284085 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.3226989798390414 for [0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.964359998703003s\n",
            "clf_loss:23.985689323792347 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.409984079922834 for [0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.057705640792847s\n",
            "clf_loss:23.409590297046034 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.8022459289635315 for [0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.455039978027344s\n",
            "clf_loss:24.980722098554295 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.8895310290473244 for [0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.238218307495117s\n",
            "clf_loss:22.13173038585205 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.801655564383106 for [0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.986889839172363s\n",
            "clf_loss:23.702862187360314 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.8889406644668982 for [0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.153848171234131s\n",
            "clf_loss:23.126763160614 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.281202513507596 for [0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.882699728012085s\n",
            "clf_loss:24.697894962122263 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.368487613591389 for [0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.862284898757935s\n",
            "clf_loss:23.11859883563724 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.335943365074657 for [0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.567419767379761s\n",
            "clf_loss:24.6897306371455 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.4232284651584495 for [0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.531681299209595s\n",
            "clf_loss:24.11363161039919 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.8154903141991476 for [0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.600848436355591s\n",
            "clf_loss:25.68476341190745 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.90277541428294 for [0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.985505104064941s\n",
            "clf_loss:18.20953812593954 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.11438327968857 eq19_loss:0\n",
            "sample: 0 x_loss: 2.3097023024538785 for [0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.000909805297852s\n",
            "clf_loss:19.780669927447804 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.11438327968857 eq19_loss:0\n",
            "sample: 0 x_loss: 2.3969874025376705 for [0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.004793643951416s\n",
            "clf_loss:19.20457090070149 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.11438327968857 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.7892492515783687 for [0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.45724630355835s\n",
            "clf_loss:20.775702702209752 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.11438327968857 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.876534351662161 for [0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.4055914878845215s\n",
            "clf_loss:19.19640657572473 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:41.144695242351304 eq19_loss:0\n",
            "sample: 0 x_loss: 3.9773234364787635 for [0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.796149969100952s\n",
            "clf_loss:20.76753837723299 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:41.144695242351304 eq19_loss:0\n",
            "sample: 0 x_loss: 4.064608536562556 for [0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.98111367225647s\n",
            "clf_loss:20.19143935048668 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:41.144695242351304 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.456870385603254 for [0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.304847240447998s\n",
            "clf_loss:21.76257115199494 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:41.144695242351304 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.544155485687046 for [0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.192821741104126s\n",
            "clf_loss:18.913579439292697 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.781049946355237 eq19_loss:0\n",
            "sample: 0 x_loss: 2.0604930756270594 for [0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.429625749588013s\n",
            "clf_loss:20.48471124080096 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.781049946355237 eq19_loss:0\n",
            "sample: 0 x_loss: 2.147778175710852 for [0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.418654203414917s\n",
            "clf_loss:19.908612214054646 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.781049946355237 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.5400400247515496 for [0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.690134525299072s\n",
            "clf_loss:21.479744015562908 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.781049946355237 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.627325124835342 for [0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.897159099578857s\n",
            "clf_loss:19.900447889077885 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.81136190901797 eq19_loss:0\n",
            "sample: 0 x_loss: 3.728114209651944 for [0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.029574632644653s\n",
            "clf_loss:21.471579690586147 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.81136190901797 eq19_loss:0\n",
            "sample: 0 x_loss: 3.8153993097357364 for [0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.039051294326782s\n",
            "clf_loss:20.895480663839834 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.81136190901797 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.2076611587764345 for [0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.177753925323486s\n",
            "clf_loss:22.466612465348096 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.81136190901797 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.294946258860227 for [0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.147014141082764s\n",
            "clf_loss:19.208423874204435 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.336605501910794 eq19_loss:0\n",
            "sample: 0 x_loss: 2.2838685473554707 for [0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.175121784210205s\n",
            "clf_loss:20.779555675712697 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.336605501910794 eq19_loss:0\n",
            "sample: 0 x_loss: 2.3711536474392627 for [0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.178791761398315s\n",
            "clf_loss:20.203456648966384 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.336605501910794 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.763415496479961 for [0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.554712533950806s\n",
            "clf_loss:21.774588450474646 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.336605501910794 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.8507005965637533 for [0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.495298624038696s\n",
            "clf_loss:20.195292323989623 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.366917464573525 eq19_loss:0\n",
            "sample: 0 x_loss: 3.951489681380355 for [0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.8590247631073s\n",
            "clf_loss:21.766424125497885 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.366917464573525 eq19_loss:0\n",
            "sample: 0 x_loss: 4.038774781464148 for [0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.7361767292022705s\n",
            "clf_loss:21.190325098751572 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.366917464573525 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.431036630504845 for [0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.895438194274902s\n",
            "clf_loss:22.761456900259834 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.366917464573525 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.518321730588638 for [0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.927547454833984s\n",
            "clf_loss:19.91246518755759 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:9.003272168577459 eq19_loss:0\n",
            "sample: 0 x_loss: 1.9997832718907023 for [0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.0924177169799805s\n",
            "clf_loss:21.483596989065852 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:9.003272168577459 eq19_loss:0\n",
            "sample: 0 x_loss: 2.0870683719744947 for [0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.088629484176636s\n",
            "clf_loss:20.90749796231954 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:9.003272168577459 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.479330221015193 for [0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.407294511795044s\n",
            "clf_loss:22.4786297638278 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:9.003272168577459 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.566615321098985 for [0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.230036973953247s\n",
            "clf_loss:20.899333637342778 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:38.03358413124019 eq19_loss:0\n",
            "sample: 0 x_loss: 3.6674044059155873 for [0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.457879304885864s\n",
            "clf_loss:22.47046543885104 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:38.03358413124019 eq19_loss:0\n",
            "sample: 0 x_loss: 3.7546895059993792 for [0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.454408645629883s\n",
            "clf_loss:21.894366412104727 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:38.03358413124019 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.146951355040077 for [0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.533653497695923s\n",
            "clf_loss:23.46549821361299 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:38.03358413124019 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.23423645512387 for [0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.552333831787109s\n",
            "clf_loss:19.428803324234003 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.11438327968857 eq19_loss:0\n",
            "sample: 0 x_loss: 2.377439257914682 for [0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.850711107254028s\n",
            "clf_loss:20.999935125742265 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.11438327968857 eq19_loss:0\n",
            "sample: 0 x_loss: 2.4647243579984743 for [0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.767982006072998s\n",
            "clf_loss:20.423836098995952 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.11438327968857 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.8569862070391725 for [0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.128666400909424s\n",
            "clf_loss:21.994967900504214 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.11438327968857 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.9442713071229645 for [0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.416547536849976s\n",
            "clf_loss:20.41567177401919 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:38.744695242351305 eq19_loss:0\n",
            "sample: 0 x_loss: 3.9117270586062336 for [0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.498481512069702s\n",
            "clf_loss:21.986803575527453 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:38.744695242351305 eq19_loss:0\n",
            "sample: 0 x_loss: 3.9990121586900256 for [0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.504029273986816s\n",
            "clf_loss:21.41070454878114 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:38.744695242351305 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.391274007730724 for [0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.5520079135894775s\n",
            "clf_loss:22.981836350289402 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:38.744695242351305 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.478559107814516 for [0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.701866626739502s\n",
            "clf_loss:20.13284463758716 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.781049946355237 eq19_loss:0\n",
            "sample: 0 x_loss: 2.128230031087863 for [0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.124454498291016s\n",
            "clf_loss:21.70397643909542 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.781049946355237 eq19_loss:0\n",
            "sample: 0 x_loss: 2.2155151311716548 for [0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.211090564727783s\n",
            "clf_loss:21.127877412349108 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.781049946355237 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.607776980212353 for [0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.792302370071411s\n",
            "clf_loss:22.69900921385737 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.781049946355237 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.6950620802961454 for [0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.712241172790527s\n",
            "clf_loss:21.119713087372347 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.41136190901797 eq19_loss:0\n",
            "sample: 0 x_loss: 3.662517831779414 for [0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.558830499649048s\n",
            "clf_loss:22.69084488888061 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.41136190901797 eq19_loss:0\n",
            "sample: 0 x_loss: 3.749802931863206 for [0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.555395126342773s\n",
            "clf_loss:22.114745862134296 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.41136190901797 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.142064780903905 for [0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.476975679397583s\n",
            "clf_loss:23.685877663642557 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.41136190901797 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.229349880987697 for [0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.7176337242126465s\n",
            "clf_loss:20.427689072498897 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.336605501910794 eq19_loss:0\n",
            "sample: 0 x_loss: 2.351605502816274 for [0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.92398476600647s\n",
            "clf_loss:21.99882087400716 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.336605501910794 eq19_loss:0\n",
            "sample: 0 x_loss: 2.4388906029000665 for [0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.894536018371582s\n",
            "clf_loss:21.422721847260846 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.336605501910794 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.8311524519407647 for [0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.2355170249938965s\n",
            "clf_loss:22.993853648769107 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.336605501910794 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.9184375520245567 for [0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.267545223236084s\n",
            "clf_loss:21.414557522284085 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.96691746457353 eq19_loss:0\n",
            "sample: 0 x_loss: 3.885893303507825 for [0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.009687662124634s\n",
            "clf_loss:22.985689323792347 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.96691746457353 eq19_loss:0\n",
            "sample: 0 x_loss: 3.973178403591618 for [0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.327009201049805s\n",
            "clf_loss:22.409590297046034 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.96691746457353 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.3654402526323155 for [0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.298968553543091s\n",
            "clf_loss:23.980722098554295 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.96691746457353 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.452725352716108 for [0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.346174716949463s\n",
            "clf_loss:21.13173038585205 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:9.003272168577459 eq19_loss:0\n",
            "sample: 0 x_loss: 2.067520227351506 for [0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.807539939880371s\n",
            "clf_loss:22.702862187360314 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:9.003272168577459 eq19_loss:0\n",
            "sample: 0 x_loss: 2.154805327435298 for [0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.872346878051758s\n",
            "clf_loss:22.126763160614 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:9.003272168577459 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.5470671764759962 for [0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.966773271560669s\n",
            "clf_loss:23.697894962122263 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:9.003272168577459 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.6343522765597887 for [0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.294874429702759s\n",
            "clf_loss:22.11859883563724 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.633584131240184 eq19_loss:0\n",
            "sample: 0 x_loss: 3.6018080280430564 for [0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.969135999679565s\n",
            "clf_loss:23.6897306371455 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.633584131240184 eq19_loss:0\n",
            "sample: 0 x_loss: 3.6890931281268484 for [0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.938761472702026s\n",
            "clf_loss:23.11363161039919 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.633584131240184 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.081354977167547 for [0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.907407999038696s\n",
            "clf_loss:24.68476341190745 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.633584131240184 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.1686400772513394 for [0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.91335654258728s\n",
            "clf_loss:20.22183422327688 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.7039812187606258 for [0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.118105888366699s\n",
            "clf_loss:21.79296602478514 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.7912663188444182 for [0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.142197370529175s\n",
            "clf_loss:21.216866998038828 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.1835281678851164 for [0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.906111717224121s\n",
            "clf_loss:22.78799879954709 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.270813267968909 for [0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.967308282852173s\n",
            "clf_loss:21.208702673062067 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.3716023527855103 for [0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.221289396286011s\n",
            "clf_loss:22.77983447457033 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.4588874528693028 for [0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.198707818984985s\n",
            "clf_loss:22.203735447824016 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.851149301910001 for [0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.291177034378052s\n",
            "clf_loss:23.774867249332278 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.9384344019937934 for [0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.563915014266968s\n",
            "clf_loss:20.925875536630034 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.7521016526341906 for [0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.576232194900513s\n",
            "clf_loss:22.497007338138296 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.8393867527179826 for [0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.459523439407349s\n",
            "clf_loss:21.920908311391983 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.2316486017586805 for [0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.245474338531494s\n",
            "clf_loss:23.492040112900245 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.3189337018424734 for [0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.274699687957764s\n",
            "clf_loss:21.912743986415222 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.4197227866590745 for [0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.831645250320435s\n",
            "clf_loss:23.483875787923484 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.5070078867428673 for [0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.105879545211792s\n",
            "clf_loss:22.90777676117717 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.8992697357835655 for [0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.517042398452759s\n",
            "clf_loss:24.478908562685433 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.9865548358673575 for [0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.520549297332764s\n",
            "clf_loss:21.220719971541776 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.7769128957609837 for [0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.553705215454102s\n",
            "clf_loss:22.791851773050038 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.8641979958447759 for [0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.5576276779174805s\n",
            "clf_loss:22.215752746303725 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.256459844885474 for [0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.825647830963135s\n",
            "clf_loss:23.786884547811987 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.3437449449692664 for [0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.15376353263855s\n",
            "clf_loss:22.207588421326964 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.444534029785868 for [0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.425641775131226s\n",
            "clf_loss:23.778720222835226 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.5318191298696604 for [0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.260212421417236s\n",
            "clf_loss:23.202621196088913 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.9240809789103586 for [0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.6764116287231445s\n",
            "clf_loss:24.773752997597175 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.0113660789941505 for [0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.613461017608643s\n",
            "clf_loss:21.92476128489493 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.790157280996599 for [0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.241151809692383s\n",
            "clf_loss:23.495893086403193 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.8774423810803915 for [0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.487237453460693s\n",
            "clf_loss:22.91979405965688 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.2697042301210897 for [0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.9921064376831055s\n",
            "clf_loss:24.49092586116514 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.3569893302048817 for [0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.061776161193848s\n",
            "clf_loss:22.91162973468012 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.4577784150214836 for [0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.860934734344482s\n",
            "clf_loss:24.48276153618838 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.5450635151052756 for [0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.898281097412109s\n",
            "clf_loss:23.906662509442068 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.937325364145974 for [0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.940439939498901s\n",
            "clf_loss:25.47779431095033 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:29.03031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.024610464229767 for [0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.796238422393799s\n",
            "clf_loss:21.441099421571344 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.7717181742214294 for [0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.266181468963623s\n",
            "clf_loss:23.012231223079606 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.8590032743052218 for [0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.2627668380737305s\n",
            "clf_loss:22.436132196333293 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.2512651233459198 for [0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.1207990646362305s\n",
            "clf_loss:24.007263997841555 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.338550223429712 for [0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.999119281768799s\n",
            "clf_loss:22.427967871356532 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.3060059749129804 for [0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.692527532577515s\n",
            "clf_loss:23.999099672864794 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.393291074996773 for [0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.907088994979858s\n",
            "clf_loss:23.42300064611848 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.785552924037471 for [0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.264167308807373s\n",
            "clf_loss:24.994132447626743 eq8_loss:4.89427215885883 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.872838024121263 for [0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.3482561111450195s\n",
            "clf_loss:22.1451407349245 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.8198386080949942 for [0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.558927059173584s\n",
            "clf_loss:23.71627253643276 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.9071237081787862 for [0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.585586071014404s\n",
            "clf_loss:23.14017350968645 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.2993855572194843 for [0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.129018545150757s\n",
            "clf_loss:24.71130531119471 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.3866706573032768 for [0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.364354133605957s\n",
            "clf_loss:23.132009184709688 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.354126408786545 for [0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.895576477050781s\n",
            "clf_loss:24.70314098621795 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.4414115088703374 for [0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.987899541854858s\n",
            "clf_loss:24.127041959471637 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.8336733579110356 for [0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.291441440582275s\n",
            "clf_loss:25.6981737609799 eq8_loss:5.056398655229836 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.9209584579948276 for [0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.189752340316772s\n",
            "clf_loss:22.439985169836238 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.844649851221787 for [0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.345915079116821s\n",
            "clf_loss:24.0111169713445 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.9319349513055795 for [0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.6135313510894775s\n",
            "clf_loss:23.435017944598187 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.3241968003462774 for [0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.267930507659912s\n",
            "clf_loss:25.00614974610645 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.41148190043007 for [0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.15903639793396s\n",
            "clf_loss:23.426853619621426 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.378937651913338 for [0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.871525526046753s\n",
            "clf_loss:24.997985421129687 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.4662227519971305 for [0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.730281829833984s\n",
            "clf_loss:24.421886394383375 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.858484601037828 for [0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.288982391357422s\n",
            "clf_loss:25.993018195891636 eq8_loss:5.208156596600371 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.9457697011216215 for [0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.169719457626343s\n",
            "clf_loss:23.144026483189393 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.8578942364574027 for [0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.517167806625366s\n",
            "clf_loss:24.715158284697655 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0\n",
            "sample: 0 x_loss: 1.945179336541195 for [0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.453619718551636s\n",
            "clf_loss:24.13905925795134 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.337441185581893 for [0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 9.023008823394775s\n",
            "clf_loss:25.710191059459603 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.4247262856656855 for [0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.631993770599365s\n",
            "clf_loss:24.13089493297458 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.3921820371489537 for [0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.477373361587524s\n",
            "clf_loss:25.702026734482843 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:0\n",
            "sample: 0 x_loss: 3.479467137232746 for [0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.484042406082153s\n",
            "clf_loss:25.12592770773653 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.8717289862734443 for [0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.631197929382324s\n",
            "clf_loss:26.69705950924479 eq8_loss:4.742514217488296 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:26.63031196266273 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 3.9590140863572367 for [0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.65782904624939s\n",
            "clf_loss:19.22183422327688 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.873419424266881 eq19_loss:0\n",
            "sample: 0 x_loss: 2.352554093671414 for [0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.254460096359253s\n",
            "clf_loss:20.79296602478514 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.873419424266881 eq19_loss:0\n",
            "sample: 0 x_loss: 2.439839193755207 for [0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.234989166259766s\n",
            "clf_loss:20.216866998038828 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.873419424266881 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.832101042795905 for [0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.802789211273193s\n",
            "clf_loss:21.78799879954709 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.873419424266881 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.9193861428796968 for [0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.751457214355469s\n",
            "clf_loss:20.208702673062067 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:40.903731386929614 eq19_loss:0\n",
            "sample: 0 x_loss: 4.020175227696299 for [0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.899359226226807s\n",
            "clf_loss:21.77983447457033 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:40.903731386929614 eq19_loss:0\n",
            "sample: 0 x_loss: 4.107460327780092 for [0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.863847017288208s\n",
            "clf_loss:21.203735447824016 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:40.903731386929614 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.499722176820789 for [0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.892508506774902s\n",
            "clf_loss:22.774867249332278 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:40.903731386929614 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.587007276904583 for [0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.6219916343688965s\n",
            "clf_loss:19.925875536630038 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.54008609093355 eq19_loss:0\n",
            "sample: 0 x_loss: 2.103344866844596 for [0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.622280597686768s\n",
            "clf_loss:21.4970073381383 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.54008609093355 eq19_loss:0\n",
            "sample: 0 x_loss: 2.190629966928388 for [0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.660398960113525s\n",
            "clf_loss:20.920908311391987 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.54008609093355 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.582891815969086 for [0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.917205333709717s\n",
            "clf_loss:22.49204011290025 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.54008609093355 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.6701769160528785 for [0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.971894979476929s\n",
            "clf_loss:20.912743986415226 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.570398053596286 eq19_loss:0\n",
            "sample: 0 x_loss: 3.77096600086948 for [0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.892767906188965s\n",
            "clf_loss:22.483875787923488 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.570398053596286 eq19_loss:0\n",
            "sample: 0 x_loss: 3.858251100953273 for [0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.58680534362793s\n",
            "clf_loss:21.907776761177175 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.570398053596286 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.250512949993971 for [0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.84467339515686s\n",
            "clf_loss:23.478908562685437 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.570398053596286 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.337798050077763 for [0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.837628602981567s\n",
            "clf_loss:20.220719971541776 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.095641646489106 eq19_loss:0\n",
            "sample: 0 x_loss: 2.326720338573007 for [0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.37992787361145s\n",
            "clf_loss:21.791851773050038 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.095641646489106 eq19_loss:0\n",
            "sample: 0 x_loss: 2.4140054386567993 for [0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.261764287948608s\n",
            "clf_loss:21.215752746303725 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.095641646489106 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.806267287697497 for [0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.479963541030884s\n",
            "clf_loss:22.786884547811987 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.095641646489106 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.8935523877812894 for [0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.252701759338379s\n",
            "clf_loss:21.207588421326964 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.12595360915184 eq19_loss:0\n",
            "sample: 0 x_loss: 3.9943414725978914 for [0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.605911016464233s\n",
            "clf_loss:22.778720222835226 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.12595360915184 eq19_loss:0\n",
            "sample: 0 x_loss: 4.081626572681683 for [0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.533054351806641s\n",
            "clf_loss:22.202621196088913 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.12595360915184 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.473888421722382 for [0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.488180875778198s\n",
            "clf_loss:23.773752997597175 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.12595360915184 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.561173521806174 for [0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.507813215255737s\n",
            "clf_loss:20.92476128489493 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:8.76230831315577 eq19_loss:0\n",
            "sample: 0 x_loss: 2.042635063108239 for [0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.076733350753784s\n",
            "clf_loss:22.495893086403193 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:8.76230831315577 eq19_loss:0\n",
            "sample: 0 x_loss: 2.129920163192031 for [0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.843036890029907s\n",
            "clf_loss:21.91979405965688 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:8.76230831315577 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.522182012232729 for [0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.4383604526519775s\n",
            "clf_loss:23.49092586116514 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:8.76230831315577 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.6094671123165214 for [0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.384479284286499s\n",
            "clf_loss:21.91162973468012 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.7926202758185 eq19_loss:0\n",
            "sample: 0 x_loss: 3.710256197133123 for [0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.092691659927368s\n",
            "clf_loss:23.48276153618838 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.7926202758185 eq19_loss:0\n",
            "sample: 0 x_loss: 3.797541297216915 for [0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.022248983383179s\n",
            "clf_loss:22.906662509442068 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.7926202758185 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.1898031462576135 for [0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.048527240753174s\n",
            "clf_loss:24.47779431095033 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.7926202758185 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.277088246341406 for [0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.857940196990967s\n",
            "clf_loss:20.441099421571344 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.873419424266881 eq19_loss:0\n",
            "sample: 0 x_loss: 2.420291049132218 for [0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.091383218765259s\n",
            "clf_loss:22.012231223079606 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.873419424266881 eq19_loss:0\n",
            "sample: 0 x_loss: 2.507576149216011 for [0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.11773157119751s\n",
            "clf_loss:21.436132196333293 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.873419424266881 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.8998379982567086 for [0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.443137884140015s\n",
            "clf_loss:23.007263997841555 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.873419424266881 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.9871230983405006 for [0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.400979518890381s\n",
            "clf_loss:21.427967871356532 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:38.503731386929616 eq19_loss:0\n",
            "sample: 0 x_loss: 3.9545788498237693 for [0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.209768533706665s\n",
            "clf_loss:22.999099672864794 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:38.503731386929616 eq19_loss:0\n",
            "sample: 0 x_loss: 4.041863949907562 for [0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.978786945343018s\n",
            "clf_loss:22.42300064611848 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:38.503731386929616 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.43412579894826 for [0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.464996099472046s\n",
            "clf_loss:23.994132447626743 eq8_loss:5.695164482986144 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:38.503731386929616 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.521410899032052 for [0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.3598809242248535s\n",
            "clf_loss:21.1451407349245 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.54008609093355 eq19_loss:0\n",
            "sample: 0 x_loss: 2.171081822305399 for [0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.386944532394409s\n",
            "clf_loss:22.71627253643276 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.54008609093355 eq19_loss:0\n",
            "sample: 0 x_loss: 2.2583669223891913 for [0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.490156173706055s\n",
            "clf_loss:22.14017350968645 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.54008609093355 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.650628771429889 for [0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.767272472381592s\n",
            "clf_loss:23.71130531119471 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.54008609093355 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.7379138715136815 for [0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.4851155281066895s\n",
            "clf_loss:22.132009184709688 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.17039805359628 eq19_loss:0\n",
            "sample: 0 x_loss: 3.7053696229969497 for [0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.212334871292114s\n",
            "clf_loss:23.70314098621795 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.17039805359628 eq19_loss:0\n",
            "sample: 0 x_loss: 3.7926547230807426 for [0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.200163125991821s\n",
            "clf_loss:23.127041959471637 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.17039805359628 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.184916572121441 for [0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.215725660324097s\n",
            "clf_loss:24.6981737609799 eq8_loss:1.8386904200835765 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.17039805359628 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.272201672205233 for [0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.3976731300354s\n",
            "clf_loss:21.439985169836234 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.095641646489106 eq19_loss:0\n",
            "sample: 0 x_loss: 2.3944572940338102 for [0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.917010068893433s\n",
            "clf_loss:23.011116971344496 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.095641646489106 eq19_loss:0\n",
            "sample: 0 x_loss: 2.4817423941176022 for [0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.648355722427368s\n",
            "clf_loss:22.435017944598183 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.095641646489106 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.8740042431583004 for [0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.031656980514526s\n",
            "clf_loss:24.006149746106445 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.095641646489106 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.961289343242093 for [0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.197895765304565s\n",
            "clf_loss:22.426853619621422 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.72595360915184 eq19_loss:0\n",
            "sample: 0 x_loss: 3.9287450947253606 for [0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.832422256469727s\n",
            "clf_loss:23.997985421129684 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.72595360915184 eq19_loss:0\n",
            "sample: 0 x_loss: 4.0160301948091535 for [0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.718837738037109s\n",
            "clf_loss:23.42188639438337 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.72595360915184 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.408292043849852 for [0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.636417865753174s\n",
            "clf_loss:24.993018195891633 eq8_loss:6.009048920727684 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.72595360915184 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.495577143933644 for [0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.40968656539917s\n",
            "clf_loss:22.14402648318939 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:8.76230831315577 eq19_loss:0\n",
            "sample: 0 x_loss: 2.1103720185690418 for [0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.740312814712524s\n",
            "clf_loss:23.71515828469765 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:8.76230831315577 eq19_loss:0\n",
            "sample: 0 x_loss: 2.197657118652834 for [0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.713467121124268s\n",
            "clf_loss:23.139059257951338 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:8.76230831315577 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.5899189676935324 for [0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.918502569198608s\n",
            "clf_loss:24.7101910594596 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:8.76230831315577 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 2.6772040677773243 for [0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.958906888961792s\n",
            "clf_loss:23.130894932974577 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.3926202758185 eq19_loss:0\n",
            "sample: 0 x_loss: 3.644659819260593 for [0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.347877025604248s\n",
            "clf_loss:24.70202673448284 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.3926202758185 eq19_loss:0\n",
            "sample: 0 x_loss: 3.731944919344385 for [0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.094427108764648s\n",
            "clf_loss:24.125927707736526 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.3926202758185 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.124206768385084 for [0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.332386016845703s\n",
            "clf_loss:25.697059509244788 eq8_loss:1.5248059823420363 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.3926202758185 eq19_loss:7.63681230947888\n",
            "sample: 0 x_loss: 4.211491868468876 for [0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.358197927474976s\n",
            "clf_loss:20.572187512425337 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.4758245817170266 for [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 2.504173994064331s\n",
            "clf_loss:19.996088485679024 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 1.8680864307577245 for [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.360931396484375s\n",
            "clf_loss:21.567220287187286 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 1.955371530841517 for [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.351938962936401s\n",
            "clf_loss:19.987924160702264 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.8387693113102923 for [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 3.815188407897949s\n",
            "clf_loss:21.559055962210525 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.926054411394085 for [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 3.8487024307250977s\n",
            "clf_loss:20.982956935464212 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.3183162604347824 for [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.42070746421814s\n",
            "clf_loss:22.554088736972474 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.4056013605185753 for [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.46715784072876s\n",
            "clf_loss:19.70509702427023 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.6767774956187234 for [0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.2638256549835205s\n",
            "clf_loss:21.276228825778492 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.7640625957025153 for [0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.245822906494141s\n",
            "clf_loss:20.70012979903218 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.1563244447432135 for [0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.03283953666687s\n",
            "clf_loss:22.27126160054044 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.243609544827006 for [0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.035121917724609s\n",
            "clf_loss:20.69196547405542 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.1270073252957813 for [0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.330591678619385s\n",
            "clf_loss:22.26309727556368 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.2142924253795737 for [0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.483518838882446s\n",
            "clf_loss:21.686998248817368 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.606554274420272 for [0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.906073570251465s\n",
            "clf_loss:23.25813005032563 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.693839374504064 for [0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.671473026275635s\n",
            "clf_loss:19.99994145918197 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.4614711586335916 for [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.2592995166778564s\n",
            "clf_loss:21.57107326069023 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.5487562587173838 for [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.214771032333374s\n",
            "clf_loss:20.994974233943918 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 1.941018107758082 for [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.915292739868164s\n",
            "clf_loss:22.56610603545218 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.0283032078418746 for [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.794825315475464s\n",
            "clf_loss:20.986809908967157 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.91170098831065 for [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.318800449371338s\n",
            "clf_loss:22.55794171047542 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.9989860883944424 for [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.119704961776733s\n",
            "clf_loss:21.981842683729106 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.39124793743514 for [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.775752305984497s\n",
            "clf_loss:23.552974485237367 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.4785330375189325 for [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.709383487701416s\n",
            "clf_loss:20.703982772535124 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.7148331239811316 for [0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.436057090759277s\n",
            "clf_loss:22.275114574043386 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.802118224064924 for [0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.375170946121216s\n",
            "clf_loss:21.699015547297073 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.1943800731056218 for [0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.020583152770996s\n",
            "clf_loss:23.270147348805335 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.2816651731894146 for [0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.960486173629761s\n",
            "clf_loss:21.690851222320312 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.16506295365819 for [0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.242984771728516s\n",
            "clf_loss:23.261983023828574 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.2523480537419824 for [0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.29745888710022s\n",
            "clf_loss:22.68588399708226 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.644609902782681 for [0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.740406036376953s\n",
            "clf_loss:24.257015798590523 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.731895002866472 for [0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.688756704330444s\n",
            "clf_loss:20.220320909211537 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.4562764370940375 for [0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 3.6437079906463623s\n",
            "clf_loss:21.7914527107198 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.54356153717783 for [0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 3.610483407974243s\n",
            "clf_loss:21.215353683973486 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 1.9358233862185277 for [0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.549233675003052s\n",
            "clf_loss:22.786485485481748 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.0231084863023203 for [0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.616145610809326s\n",
            "clf_loss:21.207189358996725 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.773172933437763 for [0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.873129367828369s\n",
            "clf_loss:22.778321160504987 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.860458033521555 for [0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.822137832641602s\n",
            "clf_loss:22.202222133758674 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.252719882562253 for [0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.2791924476623535s\n",
            "clf_loss:23.773353935266936 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.3400049826460454 for [0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.0818164348602295s\n",
            "clf_loss:20.924362222564692 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.7445144510795265 for [0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.484156370162964s\n",
            "clf_loss:22.495494024072954 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.831799551163319 for [0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.444451570510864s\n",
            "clf_loss:21.91939499732664 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.224061400204017 for [0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.224579095840454s\n",
            "clf_loss:23.490526798834903 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.3113465002878093 for [0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.269824743270874s\n",
            "clf_loss:21.91123067234988 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.061410947423252 for [0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.221208333969116s\n",
            "clf_loss:23.482362473858142 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.148696047507044 for [0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.009530305862427s\n",
            "clf_loss:22.90626344711183 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.540957896547742 for [0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.703914642333984s\n",
            "clf_loss:24.47739524862009 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.628242996631534 for [0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.647322177886963s\n",
            "clf_loss:21.21920665747643 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.529208114094395 for [0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.225186109542847s\n",
            "clf_loss:22.790338458984692 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.6164932141781874 for [0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.181875944137573s\n",
            "clf_loss:22.21423943223838 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.008755063218885 for [0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.858094215393066s\n",
            "clf_loss:23.78537123374664 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.0960401633026775 for [0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.6224353313446045s\n",
            "clf_loss:22.20607510726162 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.84610461043812 for [0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.103527307510376s\n",
            "clf_loss:23.77720690876988 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.9333897105219124 for [0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.031560659408569s\n",
            "clf_loss:23.201107882023567 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.32565155956261 for [0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.41041898727417s\n",
            "clf_loss:24.77223968353183 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.412936659646403 for [0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.443641662597656s\n",
            "clf_loss:21.923247970829586 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.782570079441935 for [0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.46004319190979s\n",
            "clf_loss:23.494379772337847 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.8698551795257277 for [0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.278592109680176s\n",
            "clf_loss:22.918280745591534 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.2621170285664256 for [0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.15801739692688s\n",
            "clf_loss:24.489412547099796 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.3494021286502176 for [0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.156996488571167s\n",
            "clf_loss:22.910116420614774 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.0994665757856605 for [0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.925955057144165s\n",
            "clf_loss:24.481248222123035 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.1867516758694525 for [0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.968734502792358s\n",
            "clf_loss:23.905149195376723 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.5790135249101507 for [0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.258260011672974s\n",
            "clf_loss:25.476280996884984 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.666298624993943 for [0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.012242555618286s\n",
            "clf_loss:18.001055710917075 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.257240422545713 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.473237293987459 for [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.5106940269470215s\n",
            "clf_loss:19.572187512425337 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.257240422545713 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.560522394071251 for [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.55509877204895s\n",
            "clf_loss:18.996088485679024 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.257240422545713 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.952784243111949 for [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.098822832107544s\n",
            "clf_loss:20.567220287187286 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.257240422545713 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.0400693431957415 for [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.026001691818237s\n",
            "clf_loss:18.987924160702264 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.37450890694758 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.9234671236645173 for [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.569997310638428s\n",
            "clf_loss:20.559055962210525 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.37450890694758 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 4.01075222374831 for [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.34140682220459s\n",
            "clf_loss:19.982956935464212 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.37450890694758 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.403014072789008 for [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.605541229248047s\n",
            "clf_loss:21.554088736972474 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.37450890694758 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.4902991728728 for [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.627382755279541s\n",
            "clf_loss:18.70509702427023 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.923907089212381 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.4641456472725647 for [0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.286677837371826s\n",
            "clf_loss:20.276228825778492 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.923907089212381 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.5514307473563567 for [0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.270323038101196s\n",
            "clf_loss:19.70012979903218 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.923907089212381 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.943692596397055 for [0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.694079399108887s\n",
            "clf_loss:21.27126160054044 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.923907089212381 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.0309776964808472 for [0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.469967603683472s\n",
            "clf_loss:19.69196547405542 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:38.04117557361424 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.9143754769496226 for [0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.9470062255859375s\n",
            "clf_loss:21.26309727556368 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:38.04117557361424 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 4.001660577033414 for [0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.851479768753052s\n",
            "clf_loss:20.686998248817368 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:38.04117557361424 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.393922426074113 for [0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.011091470718384s\n",
            "clf_loss:22.25813005032563 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:38.04117557361424 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.481207526157906 for [0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.021951675415039s\n",
            "clf_loss:18.99994145918197 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.479462644767938 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.447403538889051 for [0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.680101633071899s\n",
            "clf_loss:20.57107326069023 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.479462644767938 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.5346886389728436 for [0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.503079175949097s\n",
            "clf_loss:19.994974233943918 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.479462644767938 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.9269504880135417 for [0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.985397577285767s\n",
            "clf_loss:21.56610603545218 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.479462644767938 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.0142355880973337 for [0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.022071838378906s\n",
            "clf_loss:19.986809908967157 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.5967311291698 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.8976333685661086 for [0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.370043754577637s\n",
            "clf_loss:21.55794171047542 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.5967311291698 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.9849184686499015 for [0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.3843443393707275s\n",
            "clf_loss:20.981842683729106 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.5967311291698 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.377180317690599 for [0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.360366106033325s\n",
            "clf_loss:22.552974485237367 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.5967311291698 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.464465417774392 for [0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.101090908050537s\n",
            "clf_loss:19.703982772535124 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.146129311434601 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.403435843536207 for [0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.896000862121582s\n",
            "clf_loss:21.275114574043386 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.146129311434601 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.4907209436199995 for [0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.93771767616272s\n",
            "clf_loss:20.699015547297073 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.146129311434601 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.8829827926606972 for [0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.374576568603516s\n",
            "clf_loss:22.270147348805335 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.146129311434601 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.9702678927444897 for [0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.284326076507568s\n",
            "clf_loss:20.690851222320312 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.26339779583646 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.853665673213265 for [0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.384443044662476s\n",
            "clf_loss:22.261983023828574 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.26339779583646 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.940950773297057 for [0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.08560848236084s\n",
            "clf_loss:21.68588399708226 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.26339779583646 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.333212622337756 for [0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.442526340484619s\n",
            "clf_loss:23.257015798590523 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.26339779583646 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.420497722421548 for [0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.381920337677002s\n",
            "clf_loss:19.220320909211537 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.257240422545713 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.5409742494482623 for [0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.356753587722778s\n",
            "clf_loss:20.7914527107198 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.257240422545713 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.6282593495320548 for [0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.366998195648193s\n",
            "clf_loss:20.215353683973486 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.257240422545713 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.020521198572753 for [0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.757824897766113s\n",
            "clf_loss:21.786485485481748 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.257240422545713 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.107806298656545 for [0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.534412622451782s\n",
            "clf_loss:20.207189358996725 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.97450890694758 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.857870745791987 for [0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.098440408706665s\n",
            "clf_loss:21.778321160504987 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.97450890694758 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.9451558458757794 for [0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.967459678649902s\n",
            "clf_loss:21.202222133758674 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.97450890694758 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.3374176949164776 for [0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.108847379684448s\n",
            "clf_loss:22.773353935266936 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.97450890694758 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.42470279500027 for [0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.139522552490234s\n",
            "clf_loss:19.924362222564692 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.923907089212381 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.531882602733368 for [0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.161048412322998s\n",
            "clf_loss:21.495494024072954 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.923907089212381 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.61916770281716 for [0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.959597826004028s\n",
            "clf_loss:20.91939499732664 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.923907089212381 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.0114295518578578 for [0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.627634525299072s\n",
            "clf_loss:22.490526798834903 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.923907089212381 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.0987146519416506 for [0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.5485193729400635s\n",
            "clf_loss:20.91123067234988 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.64117557361424 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.8487790990770927 for [0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.434487342834473s\n",
            "clf_loss:22.482362473858142 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.64117557361424 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.9360641991608847 for [0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.357741832733154s\n",
            "clf_loss:21.90626344711183 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.64117557361424 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.328326048201583 for [0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.415155410766602s\n",
            "clf_loss:23.47739524862009 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.64117557361424 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.415611148285375 for [0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.277174472808838s\n",
            "clf_loss:20.21920665747643 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.479462644767938 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.515140494349855 for [0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.322158575057983s\n",
            "clf_loss:21.790338458984692 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.479462644767938 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.602425594433647 for [0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.399789094924927s\n",
            "clf_loss:21.21423943223838 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.479462644767938 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.9946874434743447 for [0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.815404891967773s\n",
            "clf_loss:22.78537123374664 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.479462644767938 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.0819725435581375 for [0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.884336471557617s\n",
            "clf_loss:21.20607510726162 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.1967311291698 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.8320369906935787 for [0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.816186904907227s\n",
            "clf_loss:22.77720690876988 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.1967311291698 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.9193220907773716 for [0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.665463447570801s\n",
            "clf_loss:22.201107882023567 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.1967311291698 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.31158393981807 for [0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.891019105911255s\n",
            "clf_loss:23.77223968353183 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.1967311291698 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.398869039901862 for [0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.016855239868164s\n",
            "clf_loss:20.923247970829586 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.146129311434601 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.4711727989970105 for [0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.826491832733154s\n",
            "clf_loss:22.494379772337847 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.146129311434601 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.558457899080803 for [0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.808867692947388s\n",
            "clf_loss:21.918280745591534 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.146129311434601 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.950719748121501 for [0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.214074850082397s\n",
            "clf_loss:23.489412547099796 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:11.146129311434601 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.038004848205293 for [0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.896342992782593s\n",
            "clf_loss:21.910116420614774 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:33.86339779583646 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.7880692953407356 for [0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.834092617034912s\n",
            "clf_loss:23.481248222123035 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:33.86339779583646 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.875354395424527 for [0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.843140363693237s\n",
            "clf_loss:22.905149195376723 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:33.86339779583646 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.267616244465226 for [0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.810126781463623s\n",
            "clf_loss:24.476280996884984 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:33.86339779583646 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.354901344549019 for [0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.882322549819946s\n",
            "clf_loss:20.013351808254413 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.4447781537075306 for [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.34514594078064s\n",
            "clf_loss:21.584483609762675 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.532063253791323 for [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.238208293914795s\n",
            "clf_loss:21.008384583016362 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 1.9243251028320207 for [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.034401893615723s\n",
            "clf_loss:22.579516384524624 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.011610202915813 for [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.938688039779663s\n",
            "clf_loss:21.0002202580396 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.895007983384589 for [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.289337158203125s\n",
            "clf_loss:22.571352059547863 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.9822930834683814 for [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.235087633132935s\n",
            "clf_loss:21.99525303280155 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.3745549325090796 for [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.496995210647583s\n",
            "clf_loss:23.56638483430981 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.4618400325928715 for [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.36577033996582s\n",
            "clf_loss:20.717393121607568 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.7330161676930196 for [0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.918058633804321s\n",
            "clf_loss:22.28852492311583 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.820301267776812 for [0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.923923015594482s\n",
            "clf_loss:21.712425896369517 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.21256311681751 for [0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.5844080448150635s\n",
            "clf_loss:23.28355769787778 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.299848216901302 for [0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.667166471481323s\n",
            "clf_loss:21.704261571392756 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.183245997370078 for [0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.570684194564819s\n",
            "clf_loss:23.275393372901018 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.2705310974538704 for [0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.329592704772949s\n",
            "clf_loss:22.699294346154705 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.6627929464945685 for [0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.948492050170898s\n",
            "clf_loss:24.270426147662967 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.750078046578361 for [0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.902325391769409s\n",
            "clf_loss:21.01223755651931 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.5177098307078882 for [0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.629674434661865s\n",
            "clf_loss:22.58336935802757 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.6049949307916807 for [0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.651358366012573s\n",
            "clf_loss:22.00727033128126 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 1.9972567798323786 for [0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.189456224441528s\n",
            "clf_loss:23.57840213278952 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.0845418799161712 for [0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.969113826751709s\n",
            "clf_loss:21.999106006304498 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.9679396603849466 for [0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.362297534942627s\n",
            "clf_loss:23.57023780781276 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.055224760468739 for [0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.326335906982422s\n",
            "clf_loss:22.994138781066447 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.4474866095094368 for [0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.614643573760986s\n",
            "clf_loss:24.56527058257471 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.534771709593229 for [0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.593151807785034s\n",
            "clf_loss:21.716278869872465 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.7710717960554283 for [0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.785599231719971s\n",
            "clf_loss:23.287410671380727 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.8583568961392207 for [0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.726577281951904s\n",
            "clf_loss:22.711311644634414 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.250618745179919 for [0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.456750392913818s\n",
            "clf_loss:24.282443446142675 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.3379038452637113 for [0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.513267755508423s\n",
            "clf_loss:22.703147319657653 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.2213016257324867 for [0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.133272886276245s\n",
            "clf_loss:24.274279121165915 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.308586725816279 for [0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.182587623596191s\n",
            "clf_loss:23.6981800944196 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.700848574856977 for [0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.4422128200531s\n",
            "clf_loss:25.269311895927864 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.7881336749407697 for [0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.30002212524414s\n",
            "clf_loss:21.232617006548878 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.5125151091683344 for [0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.546644926071167s\n",
            "clf_loss:22.80374880805714 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.5998002092521266 for [0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.370326042175293s\n",
            "clf_loss:22.227649781310827 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 1.9920620582928246 for [0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.088482856750488s\n",
            "clf_loss:23.79878158281909 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.079347158376617 for [0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.046588182449341s\n",
            "clf_loss:22.219485456334066 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.8294116055120595 for [0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.939268350601196s\n",
            "clf_loss:23.790617257842328 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.916696705595852 for [0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.900156021118164s\n",
            "clf_loss:23.214518231096015 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.3089585546365496 for [0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.377443075180054s\n",
            "clf_loss:24.785650032604277 eq8_loss:0.18925231197829934 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.396243654720342 for [0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.471770286560059s\n",
            "clf_loss:21.936658319902033 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.8007531231538232 for [0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.961931228637695s\n",
            "clf_loss:23.507790121410295 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.8880382232376158 for [0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.907313585281372s\n",
            "clf_loss:22.931691094663982 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.2803000722783136 for [0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.775992631912231s\n",
            "clf_loss:24.502822896172244 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.367585172362106 for [0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.335978746414185s\n",
            "clf_loss:22.92352676968722 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.1176496194975485 for [0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.316803216934204s\n",
            "clf_loss:24.494658571195483 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.2049347195813405 for [0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.398861408233643s\n",
            "clf_loss:23.91855954444917 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.5971965686220386 for [0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.724887132644653s\n",
            "clf_loss:25.489691345957432 eq8_loss:4.673495250363947 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.6844816687058315 for [0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.650127172470093s\n",
            "clf_loss:22.23150275481377 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.5854467861686916 for [0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.631781578063965s\n",
            "clf_loss:23.802634556322033 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.672731886252484 for [0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.41982626914978s\n",
            "clf_loss:23.22653552957572 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.0649937352931818 for [0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.238305807113647s\n",
            "clf_loss:24.797667331083982 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.152278835376974 for [0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.323535680770874s\n",
            "clf_loss:23.21837120459896 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.902343282512417 for [0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.932921648025513s\n",
            "clf_loss:24.78950300610722 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.989628382596209 for [0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.059662580490112s\n",
            "clf_loss:24.21340397936091 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.3818902316369073 for [0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.285262823104858s\n",
            "clf_loss:25.78453578086917 eq8_loss:0.5031367497198397 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.4691753317206997 for [0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.944600820541382s\n",
            "clf_loss:22.935544068166926 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.8388087515162317 for [0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.843454122543335s\n",
            "clf_loss:24.50667586967519 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.9260938516000243 for [0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.823362112045288s\n",
            "clf_loss:23.930576842928875 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.3183557006407223 for [0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 9.567688465118408s\n",
            "clf_loss:25.501708644437137 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.4056408007245142 for [0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 9.402069807052612s\n",
            "clf_loss:23.922412517952115 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.155705247859957 for [0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.817802906036377s\n",
            "clf_loss:25.493544319460376 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.242990347943749 for [0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.546088933944702s\n",
            "clf_loss:24.917445292714063 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.635252196984447 for [0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 9.111238956451416s\n",
            "clf_loss:26.488577094222325 eq8_loss:4.359610812622407 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.7225372970682398 for [0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 9.050963640213013s\n",
            "clf_loss:19.013351808254413 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.016276567124027 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.5160890852049946 for [0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.898904800415039s\n",
            "clf_loss:20.584483609762675 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.016276567124027 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.6033741852887875 for [0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.816511392593384s\n",
            "clf_loss:20.008384583016362 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.016276567124027 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.995636034329485 for [0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.273994445800781s\n",
            "clf_loss:21.579516384524624 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.016276567124027 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.0829211344132776 for [0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.976633310317993s\n",
            "clf_loss:20.0002202580396 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.13354505152589 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.966318914882053 for [0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.422148942947388s\n",
            "clf_loss:21.571352059547863 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.13354505152589 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 4.053604014965845 for [0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.482779264450073s\n",
            "clf_loss:20.99525303280155 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.13354505152589 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.445865864006544 for [0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.3551836013793945s\n",
            "clf_loss:22.56638483430981 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:39.13354505152589 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.533150964090336 for [0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.427987813949585s\n",
            "clf_loss:19.71739312160757 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.682943233790693 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.506997438490101 for [0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.453240871429443s\n",
            "clf_loss:21.288524923115833 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.682943233790693 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.5942825385738932 for [0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.389747142791748s\n",
            "clf_loss:20.71242589636952 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.682943233790693 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.9865443876145914 for [0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.024951219558716s\n",
            "clf_loss:22.283557697877782 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.682943233790693 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.0738294876983834 for [0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.996559381484985s\n",
            "clf_loss:20.70426157139276 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.80021171819256 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.9572272681671583 for [0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.7064454555511475s\n",
            "clf_loss:22.27539337290102 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.80021171819256 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 4.044512368250952 for [0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.71178412437439s\n",
            "clf_loss:21.69929434615471 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.80021171819256 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.436774217291649 for [0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.69742488861084s\n",
            "clf_loss:23.27042614766297 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.80021171819256 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.524059317375442 for [0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.434128999710083s\n",
            "clf_loss:20.01223755651931 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.23849878934625 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.4902553301065873 for [0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.893080234527588s\n",
            "clf_loss:21.58336935802757 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.23849878934625 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.57754043019038 for [0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.782488584518433s\n",
            "clf_loss:21.00727033128126 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.23849878934625 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.969802279231078 for [0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.12821888923645s\n",
            "clf_loss:22.57840213278952 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.23849878934625 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.0570873793148703 for [0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.089880466461182s\n",
            "clf_loss:20.999106006304498 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.355767273748114 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.940485159783646 for [0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.050900936126709s\n",
            "clf_loss:22.57023780781276 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.355767273748114 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 4.027770259867437 for [0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.829530954360962s\n",
            "clf_loss:21.994138781066447 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.355767273748114 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.420032108908136 for [0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.026931285858154s\n",
            "clf_loss:23.56527058257471 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.355767273748114 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.507317208991929 for [0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.021883487701416s\n",
            "clf_loss:20.716278869872465 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.905165456012913 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.4462876347537432 for [0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.976253271102905s\n",
            "clf_loss:22.287410671380727 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.905165456012913 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.5335727348375356 for [0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.972716808319092s\n",
            "clf_loss:21.711311644634414 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.905165456012913 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.925834583878234 for [0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.299455642700195s\n",
            "clf_loss:23.282443446142675 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.905165456012913 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.0131196839620262 for [0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.983932256698608s\n",
            "clf_loss:21.703147319657653 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.02243394041478 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.8965174644308016 for [0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.9663987159729s\n",
            "clf_loss:23.274279121165915 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.02243394041478 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.9838025645145945 for [0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.890477418899536s\n",
            "clf_loss:22.6981800944196 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.02243394041478 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.376064413555293 for [0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.867998123168945s\n",
            "clf_loss:24.269311895927864 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.02243394041478 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.463349513639084 for [0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.797208547592163s\n",
            "clf_loss:20.232617006548878 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.016276567124027 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.5838260406657985 for [0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.613471031188965s\n",
            "clf_loss:21.80374880805714 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.016276567124027 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.6711111407495913 for [0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.382007122039795s\n",
            "clf_loss:21.227649781310827 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.016276567124027 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.063372989790289 for [0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.933359146118164s\n",
            "clf_loss:22.79878158281909 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:14.016276567124027 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.150658089874081 for [0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.974422216415405s\n",
            "clf_loss:21.219485456334066 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.733545051525894 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.9007225370095235 for [0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.8258562088012695s\n",
            "clf_loss:22.790617257842328 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.733545051525894 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.988007637093316 for [0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.8758320808410645s\n",
            "clf_loss:22.214518231096015 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.733545051525894 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.380269486134015 for [0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.901505470275879s\n",
            "clf_loss:23.785650032604277 eq8_loss:6.4565725118086315 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:36.733545051525894 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.4675545862178065 for [0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.463660717010498s\n",
            "clf_loss:20.936658319902033 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.682943233790693 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.574734393950904 for [0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.155581712722778s\n",
            "clf_loss:22.507790121410295 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.682943233790693 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.6620194940346966 for [0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.210068225860596s\n",
            "clf_loss:21.931691094663982 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.682943233790693 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.0542813430753943 for [0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.623063087463379s\n",
            "clf_loss:23.502822896172244 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.682943233790693 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.1415664431591868 for [0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.573542356491089s\n",
            "clf_loss:21.92352676968722 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.40021171819256 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.8916308902946284 for [0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.998222589492798s\n",
            "clf_loss:23.494658571195483 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.40021171819256 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.9789159903784213 for [0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.808144569396973s\n",
            "clf_loss:22.91855954444917 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.40021171819256 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.37117783941912 for [0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.165125608444214s\n",
            "clf_loss:24.489691345957432 eq8_loss:6.922214890920706 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.40021171819256 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.458462939502912 for [0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.026197671890259s\n",
            "clf_loss:21.231502754813768 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.23849878934625 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.5579922855673907 for [0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.437596321105957s\n",
            "clf_loss:22.80263455632203 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.23849878934625 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.645277385651183 for [0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.464769601821899s\n",
            "clf_loss:22.226535529575717 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.23849878934625 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.0375392346918813 for [0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.565689086914062s\n",
            "clf_loss:23.79766733108398 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.23849878934625 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.1248243347756732 for [0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.469853401184082s\n",
            "clf_loss:22.218371204598956 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:34.955767273748116 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.8748887819111157 for [0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.308624029159546s\n",
            "clf_loss:23.789503006107218 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:34.955767273748116 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.9621738819949073 for [0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.37451696395874s\n",
            "clf_loss:23.213403979360905 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:34.955767273748116 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.354435731035606 for [0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.189079999923706s\n",
            "clf_loss:24.784535780869167 eq8_loss:6.770456949550172 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:34.955767273748116 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.441720831119399 for [0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.258584022521973s\n",
            "clf_loss:21.935544068166923 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.905165456012913 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.514024590214547 for [0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.445580244064331s\n",
            "clf_loss:23.506675869675185 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.905165456012913 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.601309690298339 for [0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.3487043380737305s\n",
            "clf_loss:22.930576842928872 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.905165456012913 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.9935715393390367 for [0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.889559268951416s\n",
            "clf_loss:24.501708644437134 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.905165456012913 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.0808566394228296 for [0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.888530015945435s\n",
            "clf_loss:22.92241251795211 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:33.62243394041477 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.8309210865582717 for [0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.117877721786499s\n",
            "clf_loss:24.493544319460373 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:33.62243394041477 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.9182061866420637 for [0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.2400360107421875s\n",
            "clf_loss:23.91744529271406 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:33.62243394041477 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.310468035682762 for [0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.128104209899902s\n",
            "clf_loss:25.48857709422232 eq8_loss:6.608330453179166 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:33.62243394041477 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.397753135766554 for [0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.719279050827026s\n",
            "clf_loss:20.210593836856617 eq8_loss:5.08352447083713 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.7276400530109215 for [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.2380523681640625s\n",
            "clf_loss:21.78172563836488 eq8_loss:5.08352447083713 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.8149251530947137 for [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 4.275416135787964s\n",
            "clf_loss:21.205626611618566 eq8_loss:5.08352447083713 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.2071870021354116 for [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.070617437362671s\n",
            "clf_loss:22.776758413126828 eq8_loss:5.08352447083713 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.2944721022192045 for [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.046452760696411s\n",
            "clf_loss:21.197462286641805 eq8_loss:5.08352447083713 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.17786988268798 for [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.349887371063232s\n",
            "clf_loss:22.768594088150067 eq8_loss:5.08352447083713 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.2651549827717723 for [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.124137878417969s\n",
            "clf_loss:22.192495061403754 eq8_loss:5.08352447083713 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.657416831812471 for [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.881625652313232s\n",
            "clf_loss:23.763626862912016 eq8_loss:5.08352447083713 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.744701931896262 for [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.900827884674072s\n",
            "clf_loss:20.914635150209772 eq8_loss:5.245650967208136 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.7757604868844858 for [0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.709907293319702s\n",
            "clf_loss:22.485766951718034 eq8_loss:5.245650967208136 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.8630455869682783 for [0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.624926567077637s\n",
            "clf_loss:21.90966792497172 eq8_loss:5.245650967208136 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.255307436008976 for [0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.44877815246582s\n",
            "clf_loss:23.480799726479983 eq8_loss:5.245650967208136 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.3425925360927686 for [0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.213850021362305s\n",
            "clf_loss:21.90150359999496 eq8_loss:5.245650967208136 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.2259903165615444 for [0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.308663368225098s\n",
            "clf_loss:23.472635401503222 eq8_loss:5.245650967208136 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.313275416645337 for [0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.417739152908325s\n",
            "clf_loss:22.89653637475691 eq8_loss:5.245650967208136 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.7055372656860346 for [0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.948506116867065s\n",
            "clf_loss:24.46766817626517 eq8_loss:5.245650967208136 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.7928223657698275 for [0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.873302698135376s\n",
            "clf_loss:21.20947958512151 eq8_loss:5.3974089085786705 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.800571730011279 for [0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.743185758590698s\n",
            "clf_loss:22.780611386629772 eq8_loss:5.3974089085786705 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.887856830095071 for [0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.565915584564209s\n",
            "clf_loss:22.20451235988346 eq8_loss:5.3974089085786705 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.2801186791357693 for [0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.360098600387573s\n",
            "clf_loss:23.77564416139172 eq8_loss:5.3974089085786705 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.3674037792195617 for [0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.501794099807739s\n",
            "clf_loss:22.1963480349067 eq8_loss:5.3974089085786705 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.250801559688337 for [0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.650925874710083s\n",
            "clf_loss:23.76747983641496 eq8_loss:5.3974089085786705 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.3380866597721295 for [0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.629516124725342s\n",
            "clf_loss:23.191380809668647 eq8_loss:5.3974089085786705 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.730348508812827 for [0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.899840593338013s\n",
            "clf_loss:24.76251261117691 eq8_loss:5.3974089085786705 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.81763360889662 for [0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.5782904624938965s\n",
            "clf_loss:21.913520898474665 eq8_loss:4.9317665294665955 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.8138161152468948 for [0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.677505016326904s\n",
            "clf_loss:23.484652699982927 eq8_loss:4.9317665294665955 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.9011012153306868 for [0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.73689866065979s\n",
            "clf_loss:22.908553673236614 eq8_loss:4.9317665294665955 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.293363064371385 for [0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.32334566116333s\n",
            "clf_loss:24.479685474744876 eq8_loss:4.9317665294665955 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.3806481644551774 for [0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.4876708984375s\n",
            "clf_loss:22.900389348259854 eq8_loss:4.9317665294665955 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.2640459449239527 for [0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.23827338218689s\n",
            "clf_loss:24.471521149768115 eq8_loss:4.9317665294665955 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.351331045007745 for [0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.946359157562256s\n",
            "clf_loss:23.895422123021802 eq8_loss:4.9317665294665955 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.7435928940484433 for [0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.714156150817871s\n",
            "clf_loss:25.466553924530064 eq8_loss:4.9317665294665955 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:25.117268484401862 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.8308779941322353 for [0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.673444509506226s\n",
            "clf_loss:21.42985903515108 eq8_loss:5.08352447083713 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.7953770084717249 for [0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.500755786895752s\n",
            "clf_loss:23.00099083665934 eq8_loss:5.08352447083713 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.8826621085555173 for [0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.439594507217407s\n",
            "clf_loss:22.424891809913028 eq8_loss:5.08352447083713 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.2749239575962155 for [0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.103521108627319s\n",
            "clf_loss:23.99602361142129 eq8_loss:5.08352447083713 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.3622090576800074 for [0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.9496543407440186s\n",
            "clf_loss:22.416727484936267 eq8_loss:5.08352447083713 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.11227350481545 for [0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.251453161239624s\n",
            "clf_loss:23.98785928644453 eq8_loss:5.08352447083713 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.1995586048992424 for [0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.170816659927368s\n",
            "clf_loss:23.411760259698216 eq8_loss:5.08352447083713 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.5918204539399405 for [0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.696563959121704s\n",
            "clf_loss:24.982892061206478 eq8_loss:5.08352447083713 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.679105554023733 for [0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.682382583618164s\n",
            "clf_loss:22.133900348504234 eq8_loss:5.245650967208136 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.8434974423452894 for [0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.785632371902466s\n",
            "clf_loss:23.705032150012496 eq8_loss:5.245650967208136 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.9307825424290819 for [0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.630629301071167s\n",
            "clf_loss:23.128933123266183 eq8_loss:5.245650967208136 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.32304439146978 for [0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.807719230651855s\n",
            "clf_loss:24.700064924774445 eq8_loss:5.245650967208136 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.410329491553572 for [0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.710744619369507s\n",
            "clf_loss:23.120768798289422 eq8_loss:5.245650967208136 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.1603939386890145 for [0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.2281763553619385s\n",
            "clf_loss:24.691900599797684 eq8_loss:5.245650967208136 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.247679038772807 for [0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.340776205062866s\n",
            "clf_loss:24.11580157305137 eq8_loss:5.245650967208136 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.6399408878135042 for [0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.674498558044434s\n",
            "clf_loss:25.686933374559633 eq8_loss:5.245650967208136 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.727225987897297 for [0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.399495363235474s\n",
            "clf_loss:22.428744783415972 eq8_loss:5.3974089085786705 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.8683086854720823 for [0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.905811786651611s\n",
            "clf_loss:23.999876584924234 eq8_loss:5.3974089085786705 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.9555937855558747 for [0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.847306489944458s\n",
            "clf_loss:23.42377755817792 eq8_loss:5.3974089085786705 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.3478556345965726 for [0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.561395645141602s\n",
            "clf_loss:24.994909359686183 eq8_loss:5.3974089085786705 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.435140734680365 for [0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.575640439987183s\n",
            "clf_loss:23.41561323320116 eq8_loss:5.3974089085786705 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.1852051818158076 for [0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.327541351318359s\n",
            "clf_loss:24.986745034709422 eq8_loss:5.3974089085786705 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.2724902818995996 for [0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.063294410705566s\n",
            "clf_loss:24.41064600796311 eq8_loss:5.3974089085786705 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.6647521309402973 for [0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.699292182922363s\n",
            "clf_loss:25.98177780947137 eq8_loss:5.3974089085786705 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.75203723102409 for [0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.686169624328613s\n",
            "clf_loss:23.132786096769127 eq8_loss:4.9317665294665955 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.881553070707698 for [0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.845370769500732s\n",
            "clf_loss:24.70391789827739 eq8_loss:4.9317665294665955 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 1.9688381707914904 for [0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.746230602264404s\n",
            "clf_loss:24.127818871531076 eq8_loss:4.9317665294665955 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.3611000198321883 for [0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 9.472911596298218s\n",
            "clf_loss:25.698950673039338 eq8_loss:4.9317665294665955 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:0 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.4483851199159807 for [0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 9.168113231658936s\n",
            "clf_loss:24.119654546554315 eq8_loss:4.9317665294665955 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.1984495670514232 for [0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.9948954582214355s\n",
            "clf_loss:25.690786348062577 eq8_loss:4.9317665294665955 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.2857346671352152 for [0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.02765417098999s\n",
            "clf_loss:25.114687321316264 eq8_loss:4.9317665294665955 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.6779965161759134 for [0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 9.400729417800903s\n",
            "clf_loss:26.685819122824526 eq8_loss:4.9317665294665955 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:22.717268484401863 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.7652816162597054 for [0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 9.393325090408325s\n",
            "clf_loss:19.210593836856617 eq8_loss:5.884416794964443 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.11438327968857 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.3895998087784704 for [0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.64233660697937s\n",
            "clf_loss:20.78172563836488 eq8_loss:5.884416794964443 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.11438327968857 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.4768849088622624 for [0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 5.591513156890869s\n",
            "clf_loss:20.205626611618566 eq8_loss:5.884416794964443 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.11438327968857 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.8691467579029606 for [0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.132260799407959s\n",
            "clf_loss:21.776758413126828 eq8_loss:5.884416794964443 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.11438327968857 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.956431857986753 for [0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.139331340789795s\n",
            "clf_loss:20.197462286641805 eq8_loss:5.884416794964443 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.23165176409044 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.839829638455529 for [0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.419068098068237s\n",
            "clf_loss:21.768594088150067 eq8_loss:5.884416794964443 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.23165176409044 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.9271147385393212 for [0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.318514347076416s\n",
            "clf_loss:21.192495061403754 eq8_loss:5.884416794964443 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.23165176409044 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.319376587580019 for [0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.379601001739502s\n",
            "clf_loss:22.763626862912016 eq8_loss:5.884416794964443 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:37.23165176409044 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.406661687663812 for [0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.163156986236572s\n",
            "clf_loss:19.914635150209772 eq8_loss:2.027942732061876 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.781049946355237 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.1403905819516513 for [0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.205921173095703s\n",
            "clf_loss:21.485766951718034 eq8_loss:2.027942732061876 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.781049946355237 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.2276756820354437 for [0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.204529523849487s\n",
            "clf_loss:20.90966792497172 eq8_loss:2.027942732061876 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.781049946355237 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.6199375310761415 for [0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.602429389953613s\n",
            "clf_loss:22.480799726479983 eq8_loss:2.027942732061876 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.781049946355237 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.7072226311599343 for [0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.497421741485596s\n",
            "clf_loss:20.90150359999496 eq8_loss:2.027942732061876 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.8983184307571 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.5906204116287097 for [0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.313221216201782s\n",
            "clf_loss:22.472635401503222 eq8_loss:2.027942732061876 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.8983184307571 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.6779055117125017 for [0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.175382137298584s\n",
            "clf_loss:21.89653637475691 eq8_loss:2.027942732061876 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.8983184307571 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.070167360753199 for [0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.562628269195557s\n",
            "clf_loss:23.46766817626517 eq8_loss:2.027942732061876 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.8983184307571 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.157452460836993 for [0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.54804253578186s\n",
            "clf_loss:20.20947958512151 eq8_loss:6.198301232705983 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.336605501910794 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.3637660536800627 for [0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.597462177276611s\n",
            "clf_loss:21.780611386629772 eq8_loss:6.198301232705983 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.336605501910794 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.451051153763855 for [0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.6265764236450195s\n",
            "clf_loss:21.20451235988346 eq8_loss:6.198301232705983 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.336605501910794 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.8433130028045532 for [0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.093208312988281s\n",
            "clf_loss:22.77564416139172 eq8_loss:6.198301232705983 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:10.336605501910794 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.930598102888345 for [0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.806119680404663s\n",
            "clf_loss:21.1963480349067 eq8_loss:6.198301232705983 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.45387398631266 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.8139958833571206 for [0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.094213962554932s\n",
            "clf_loss:22.76747983641496 eq8_loss:6.198301232705983 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.45387398631266 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.9012809834409135 for [0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.173322439193726s\n",
            "clf_loss:22.191380809668647 eq8_loss:6.198301232705983 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.45387398631266 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.293542832481611 for [0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.116210460662842s\n",
            "clf_loss:23.76251261117691 eq8_loss:6.198301232705983 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:35.45387398631266 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.380827932565404 for [0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.080711126327515s\n",
            "clf_loss:20.913520898474665 eq8_loss:1.7140582943203355 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:9.003272168577459 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.079680778215294 for [0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.640589952468872s\n",
            "clf_loss:22.484652699982927 eq8_loss:1.7140582943203355 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:9.003272168577459 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.1669658782990866 for [0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.426697254180908s\n",
            "clf_loss:21.908553673236614 eq8_loss:1.7140582943203355 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:9.003272168577459 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.5592277273397848 for [0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.027406692504883s\n",
            "clf_loss:23.479685474744876 eq8_loss:1.7140582943203355 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:9.003272168577459 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.6465128274235767 for [0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.017460823059082s\n",
            "clf_loss:21.900389348259854 eq8_loss:1.7140582943203355 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:34.120540652979315 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.5299106078923526 for [0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.646323204040527s\n",
            "clf_loss:23.471521149768115 eq8_loss:1.7140582943203355 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:34.120540652979315 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.617195707976144 for [0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.676620244979858s\n",
            "clf_loss:22.895422123021802 eq8_loss:1.7140582943203355 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:34.120540652979315 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.009457557016843 for [0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.733908176422119s\n",
            "clf_loss:24.466553924530064 eq8_loss:1.7140582943203355 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:34.120540652979315 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.096742657100635 for [0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 1 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.5389792919158936s\n",
            "clf_loss:20.42985903515108 eq8_loss:5.884416794964443 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.11438327968857 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.457336764239274 for [0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.57914924621582s\n",
            "clf_loss:22.00099083665934 eq8_loss:5.884416794964443 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.11438327968857 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 2.5446218643230663 for [0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.573108911514282s\n",
            "clf_loss:21.424891809913028 eq8_loss:5.884416794964443 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.11438327968857 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 2.9368837133637644 for [0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 8.032352209091187s\n",
            "clf_loss:22.99602361142129 eq8_loss:5.884416794964443 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:12.11438327968857 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 3.0241688134475564 for [0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 1 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.978374004364014s\n",
            "clf_loss:21.416727484936267 eq8_loss:5.884416794964443 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:34.83165176409044 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.774233260582999 for [0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.768983840942383s\n",
            "clf_loss:22.98785928644453 eq8_loss:5.884416794964443 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:34.83165176409044 eq19_loss:0.2478470909472802\n",
            "sample: 0 x_loss: 3.861518360666791 for [0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 6.515967130661011s\n",
            "clf_loss:22.411760259698216 eq8_loss:5.884416794964443 eq11_loss:5.555555555555558 eq13_loss:0 eq15_loss:34.83165176409044 eq19_loss:7.884659400426159\n",
            "sample: 0 x_loss: 4.2537802097074895 for [0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 1 0] min_loss: 1.432617602843742 for [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0] under 7.96950888633728s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-8d72c8b0d1e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m# print('main_obj', main_obj)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0my_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore_algo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mau_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmain_obj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmin_obj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-9023602a6774>\u001b[0m in \u001b[0;36mcore_algo\u001b[0;34m(y_new, au_list, min_obj)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mx_expr_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_expr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#step4 find best AU config for a sample (tried parallelize but causing issue in numpy array)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0my_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_eq22_best_AU_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mau_test_config_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_expr_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mau_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimary_au\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecondary_au\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mothers_au\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_au_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_au_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotion_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eq22_config for sample{} is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#compute eq20_obj for above sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-a8540fb61073>\u001b[0m in \u001b[0;36mget_eq22_best_AU_config\u001b[0;34m(au_test_config_arr, x, sample_no, x_expr_label, W, au_list, primary_au, secondary_au, others_au, positive_au_pairs, negative_au_pairs, emotion_list)\u001b[0m\n\u001b[1;32m    143\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mtest_au_config\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mau_test_config_arr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mtick\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0mx_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meq22_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_au_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_expr_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mau_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimary_au\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecondary_au\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mothers_au\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_au_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_au_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotion_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmin_loss\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m       \u001b[0mmin_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-a8540fb61073>\u001b[0m in \u001b[0;36meq22_loss\u001b[0;34m(test_au_config, x, W, x_expr_label, au_list, primary_au, secondary_au, others_au, positive_au_pairs, negative_au_pairs, emotion_list)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;31m#Loss_eq8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m   \u001b[0mLoss_eq8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambd_eq8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0meq8_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_au_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_au_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_au_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m   \u001b[0;31m#Loss_eq11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-a8540fb61073>\u001b[0m in \u001b[0;36meq8_loss\u001b[0;34m(test_au_labels, positive_au_pairs, negative_au_pairs)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprob_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prob_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprob_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prob_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mprob_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prob_ij\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mpt_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_i\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprob_j\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprob_ij\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mprob_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprob_j\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprob_ij\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_i\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mprob_j\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprob_ij\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-992a334e015d>\u001b[0m in \u001b[0;36mget_prob_ij\u001b[0;34m(au_pair)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#Get expression independent marginal AU probability that is calculated from dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_prob_ij\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mau_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Probabilities.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m   \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mformatting_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatting_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mon_demand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_demand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 \u001b[0mragged_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mragged_rows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m                 )\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mbk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xlrd/xlsx.py\u001b[0m in \u001b[0;36mopen_workbook_2007_xml\u001b[0;34m(zf, component_names, logfile, verbosity, use_mmap, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0mx12sheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX12Sheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[0mheading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Sheet %r (sheetx=%d) from %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheetx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m         \u001b[0mx12sheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzflo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheading\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    838\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mzflo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xlrd/xlsx.py\u001b[0m in \u001b[0;36mown_process_stream\u001b[0;34m(self, stream, heading)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrow_tag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m                 \u001b[0mself_do_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m                 \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# destroy all child elements (cells)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mU_SSML12\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"dimension\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xlrd/xlsx.py\u001b[0m in \u001b[0;36mdo_row\u001b[0;34m(self, row_elem)\u001b[0m\n\u001b[1;32m    688\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXL_CELL_BLANK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxf_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxf_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mcell_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"s\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;31m# s = index into shared string table. 2nd most frequent type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn6HCIUcaTyO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "3159b74a-38c6-4704-b0cf-d0e8d2b410cd"
      },
      "source": [
        "Classification"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-16caf8a25b64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Classification' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY1Q1bIfNpZn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}