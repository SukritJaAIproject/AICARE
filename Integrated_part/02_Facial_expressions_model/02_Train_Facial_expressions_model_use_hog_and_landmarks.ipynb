{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_Train_Facial_expressions_model_use_hog_and_landmarks.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YdoqV48vd3qN",
        "8NC92MdsQmGF"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnDoSNUFQpjI"
      },
      "source": [
        "# pip install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JN-i942BBfA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db95cea9-ff0a-443f-e5e4-00bae5c8ef14"
      },
      "source": [
        "pip install tflearn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tflearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/3c/0b156d08ef3d4e2a8009ecab2af1ad2e304f6fb99562b6271c68a74a4397/tflearn-0.5.0.tar.gz (107kB)\n",
            "\r\u001b[K     |███                             | 10kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 20kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 30kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40kB 10.0MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 51kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 61kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 71kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 81kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 92kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 102kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tflearn) (7.0.0)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-cp37-none-any.whl size=127301 sha256=cb5a9d267fdd0daae99113a467889fe9117a379096c2c21c237a0aea9cdb517f\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/d2/ed/fb9a0d301dd9586c11e9547120278e624227f22fd5f4baf744\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1g-cNpJdcZa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25fe9a34-58b3-48d8-de77-94a8fb5fad92"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tflearn import DNN\n",
        "import time\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf \n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.merge_ops import merge_outputs, merge\n",
        "from tflearn.layers.normalization import local_response_normalization, batch_normalization\n",
        "from tflearn.layers.estimator import regression \n",
        "from tflearn.optimizers import Momentum, Adam"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tN2ILBzfAFP",
        "outputId": "ace1e46b-a901-440b-ed55-899a88d6206b"
      },
      "source": [
        "ls 'drive/MyDrive/AIHealthcare/Facial_expressions_model_data/LANDMARKS_HOG'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mPrivateTest\u001b[0m/  \u001b[01;34mPublicTest\u001b[0m/  \u001b[01;34mTraining\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8meOIU6FeZjt"
      },
      "source": [
        "# ls 'drive/MyDrive/AIHealthcare/Facial_expressions_model_data/Onlylandmark'\n",
        "# ls 'drive/MyDrive/AIHealthcare/Facial_expressions_model_data/LANDMARKS_HOG'\n",
        "# ls 'drive/MyDrive/AIHealthcare/Facial_expressions_model_data/Facelandmarks_HOG_sliding_window'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6AY5vjIdzlS"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4H9Zzm1dvj1"
      },
      "source": [
        "class Dataset:\n",
        "    name = 'Fer2013'\n",
        "    train_folder = 'drive/MyDrive/AIHealthcare/Facial_expressions_model_data/LANDMARKS_HOG/Training'\n",
        "    validation_folder = 'drive/MyDrive/AIHealthcare/Facial_expressions_model_data/LANDMARKS_HOG/PublicTest'\n",
        "    test_folder = 'drive/MyDrive/AIHealthcare/Facial_expressions_model_data/LANDMARKS_HOG/PrivateTest'\n",
        "    shape_predictor_path='drive/MyDrive/AIHealthcare/facial_expression_recognition_using_cnn/shape_predictor_68_face_landmarks.dat'\n",
        "    trunc_trainset_to = -1  # put the number of train images to use (-1 = all images of the train set)\n",
        "    trunc_validationset_to = -1\n",
        "    trunc_testset_to = -1\n",
        "\n",
        "class Network:\n",
        "    model = 'B'\n",
        "    input_size = 48\n",
        "    output_size = 7\n",
        "    activation = 'relu'\n",
        "    loss = 'categorical_crossentropy'\n",
        "    use_landmarks = True\n",
        "    use_hog_and_landmarks = True\n",
        "    use_hog_sliding_window_and_landmarks = False\n",
        "    use_batchnorm_after_conv_layers = True\n",
        "    use_batchnorm_after_fully_connected_layers = False\n",
        "\n",
        "class Hyperparams:\n",
        "    keep_prob = 0.956   # dropout = 1 - keep_prob\n",
        "    learning_rate = 0.016\n",
        "    learning_rate_decay = 0.864\n",
        "    decay_step = 50\n",
        "    optimizer = 'momentum'  # {'momentum', 'adam', 'rmsprop', 'adagrad', 'adadelta'}\n",
        "    optimizer_param = 0.95   # momentum value for Momentum optimizer, or beta1 value for Adam\n",
        "\n",
        "class Training:\n",
        "    batch_size = 128\n",
        "    epochs = 13\n",
        "    snapshot_step = 500\n",
        "    vizualize = True\n",
        "    logs_dir = \"logs\"\n",
        "    checkpoint_dir = \"checkpoints/chk\"\n",
        "    best_checkpoint_path = \"checkpoints/best/\"\n",
        "    max_checkpoints = 1\n",
        "    checkpoint_frequency = 1.0 # in hours\n",
        "    save_model = True\n",
        "    save_model_path = \"best_model/saved_model.bin\"\n",
        "\n",
        "class VideoPredictor:\n",
        "    emotions = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\n",
        "    print_emotions = False\n",
        "    camera_source = 0\n",
        "    face_detection_classifier = \"lbpcascade_frontalface.xml\"\n",
        "    show_confidence = False\n",
        "    time_to_wait_between_predictions = 0.5\n",
        "\n",
        "class OptimizerSearchSpace:\n",
        "    learning_rate = {'min': 0.00001, 'max': 0.1}\n",
        "    learning_rate_decay = {'min': 0.5, 'max': 0.99}\n",
        "    optimizer = ['momentum']   # ['momentum', 'adam', 'rmsprop', 'adagrad', 'adadelta']\n",
        "    optimizer_param = {'min': 0.5, 'max': 0.99}\n",
        "    keep_prob = {'min': 0.7, 'max': 0.99}\n",
        "\n",
        "def make_dir(folder):\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "\n",
        "DATASET = Dataset()\n",
        "NETWORK = Network()\n",
        "TRAINING = Training()\n",
        "HYPERPARAMS = Hyperparams()\n",
        "VIDEO_PREDICTOR = VideoPredictor()\n",
        "OPTIMIZER = OptimizerSearchSpace()\n",
        "\n",
        "make_dir(TRAINING.logs_dir)\n",
        "make_dir(TRAINING.checkpoint_dir)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdoqV48vd3qN"
      },
      "source": [
        "# data_loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DgoqgHqdiFa"
      },
      "source": [
        "def load_data(validation=False, test=False):\n",
        "    \n",
        "    data_dict = dict()\n",
        "    validation_dict = dict()\n",
        "    test_dict = dict()\n",
        "\n",
        "    if DATASET.name == \"Fer2013\":\n",
        "\n",
        "        # load train set\n",
        "        data_dict['X'] = np.load(DATASET.train_folder + '/images.npy')\n",
        "        data_dict['X'] = data_dict['X'].reshape([-1, NETWORK.input_size, NETWORK.input_size, 1])\n",
        "        if NETWORK.use_landmarks:\n",
        "            data_dict['X2'] = np.load(DATASET.train_folder + '/landmarks.npy')\n",
        "        if NETWORK.use_hog_and_landmarks:\n",
        "            data_dict['X2'] = np.load(DATASET.train_folder + '/landmarks.npy')\n",
        "            data_dict['X2'] = np.array([x.flatten() for x in data_dict['X2']])\n",
        "            data_dict['X2'] = np.concatenate((data_dict['X2'], np.load(DATASET.train_folder + '/hog_features.npy')), axis=1)\n",
        "        data_dict['Y'] = np.load(DATASET.train_folder + '/labels.npy')\n",
        "        if DATASET.trunc_trainset_to > 0:\n",
        "            data_dict['X'] = data_dict['X'][0:DATASET.trunc_trainset_to, :, :]\n",
        "            if NETWORK.use_landmarks and NETWORK.use_hog_and_landmarks:\n",
        "                data_dict['X2'] = data_dict['X2'][0:DATASET.trunc_trainset_to, :]\n",
        "            elif NETWORK.use_landmarks:\n",
        "                data_dict['X2'] = data_dict['X2'][0:DATASET.trunc_trainset_to, :, :]\n",
        "            data_dict['Y'] = data_dict['Y'][0:DATASET.trunc_trainset_to, :]\n",
        "\n",
        "        if validation:\n",
        "            # load validation set\n",
        "            validation_dict['X'] = np.load(DATASET.validation_folder + '/images.npy')\n",
        "            validation_dict['X'] = validation_dict['X'].reshape([-1, NETWORK.input_size, NETWORK.input_size, 1])\n",
        "            if NETWORK.use_landmarks:\n",
        "                validation_dict['X2'] = np.load(DATASET.validation_folder + '/landmarks.npy')\n",
        "            if NETWORK.use_hog_and_landmarks:\n",
        "                validation_dict['X2'] = np.load(DATASET.validation_folder + '/landmarks.npy')\n",
        "                validation_dict['X2'] = np.array([x.flatten() for x in validation_dict['X2']])\n",
        "                validation_dict['X2'] = np.concatenate((validation_dict['X2'], np.load(DATASET.validation_folder + '/hog_features.npy')), axis=1)\n",
        "            validation_dict['Y'] = np.load(DATASET.validation_folder + '/labels.npy')\n",
        "            if DATASET.trunc_validationset_to > 0:\n",
        "                validation_dict['X'] = validation_dict['X'][0:DATASET.trunc_validationset_to, :, :]\n",
        "                if NETWORK.use_landmarks and NETWORK.use_hog_and_landmarks:\n",
        "                    validation_dict['X2'] = validation_dict['X2'][0:DATASET.trunc_validationset_to, :]\n",
        "                elif NETWORK.use_landmarks:\n",
        "                    validation_dict['X2'] = validation_dict['X2'][0:DATASET.trunc_validationset_to, :, :]\n",
        "                validation_dict['Y'] = validation_dict['Y'][0:DATASET.trunc_validationset_to, :]\n",
        "        \n",
        "        if test:\n",
        "            # load test set\n",
        "            test_dict['X'] = np.load(DATASET.test_folder + '/images.npy')\n",
        "            test_dict['X'] = test_dict['X'].reshape([-1, NETWORK.input_size, NETWORK.input_size, 1])\n",
        "            if NETWORK.use_landmarks:\n",
        "                test_dict['X2'] = np.load(DATASET.test_folder + '/landmarks.npy')\n",
        "            if NETWORK.use_hog_and_landmarks:\n",
        "                test_dict['X2'] = np.load(DATASET.test_folder + '/landmarks.npy')\n",
        "                test_dict['X2'] = np.array([x.flatten() for x in test_dict['X2']])\n",
        "                test_dict['X2'] = np.concatenate((test_dict['X2'], np.load(DATASET.test_folder + '/hog_features.npy')), axis=1)\n",
        "            test_dict['Y'] = np.load(DATASET.test_folder + '/labels.npy')\n",
        "            if DATASET.trunc_testset_to > 0:\n",
        "                test_dict['X'] = test_dict['X'][0:DATASET.trunc_testset_to, :, :]\n",
        "                if NETWORK.use_landmarks and NETWORK.use_hog_and_landmarks:\n",
        "                    test_dict['X2'] = test_dict['X2'][0:DATASET.trunc_testset_to, :]\n",
        "                elif NETWORK.use_landmarks:\n",
        "                    test_dict['X2'] = test_dict['X2'][0:DATASET.trunc_testset_to, :, :]\n",
        "                test_dict['Y'] = test_dict['Y'][0:DATASET.trunc_testset_to, :]\n",
        "\n",
        "        if not validation and not test:\n",
        "            return data_dict\n",
        "        elif not test:\n",
        "            return data_dict, validation_dict\n",
        "        else: \n",
        "            return data_dict, validation_dict, test_dict\n",
        "    else:\n",
        "        print( \"Unknown dataset\")\n",
        "        exit()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jbq-NXJSeMXI"
      },
      "source": [
        "## model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdXJQ1j5eLCF"
      },
      "source": [
        "def build_model(optimizer=HYPERPARAMS.optimizer, optimizer_param=HYPERPARAMS.optimizer_param, \n",
        "    learning_rate=HYPERPARAMS.learning_rate, keep_prob=HYPERPARAMS.keep_prob,\n",
        "    learning_rate_decay=HYPERPARAMS.learning_rate_decay, decay_step=HYPERPARAMS.decay_step):\n",
        "\n",
        "    if NETWORK.model == 'A':\n",
        "        return build_modelA(optimizer, optimizer_param, learning_rate, keep_prob, learning_rate_decay, decay_step)\n",
        "    elif NETWORK.model == 'B':\n",
        "        return build_modelB(optimizer, optimizer_param, learning_rate, keep_prob, learning_rate_decay, decay_step)\n",
        "    else:\n",
        "        print( \"ERROR: no model \" + str(NETWORK.model))\n",
        "        exit()\n",
        "\n",
        "def build_modelB(optimizer=HYPERPARAMS.optimizer, optimizer_param=HYPERPARAMS.optimizer_param, \n",
        "    learning_rate=HYPERPARAMS.learning_rate, keep_prob=HYPERPARAMS.keep_prob,\n",
        "    learning_rate_decay=HYPERPARAMS.learning_rate_decay, decay_step=HYPERPARAMS.decay_step):\n",
        "\n",
        "    images_network = input_data(shape=[None, NETWORK.input_size, NETWORK.input_size, 1], name='input1')\n",
        "    images_network = conv_2d(images_network, 64, 3, activation=NETWORK.activation)\n",
        "    #images_network = local_response_normalization(images_network)\n",
        "    if NETWORK.use_batchnorm_after_conv_layers:\n",
        "        images_network = batch_normalization(images_network)\n",
        "    images_network = max_pool_2d(images_network, 3, strides = 2)\n",
        "    images_network = conv_2d(images_network, 128, 3, activation=NETWORK.activation)\n",
        "    if NETWORK.use_batchnorm_after_conv_layers:\n",
        "        images_network = batch_normalization(images_network)\n",
        "    images_network = max_pool_2d(images_network, 3, strides = 2)\n",
        "    images_network = conv_2d(images_network, 256, 3, activation=NETWORK.activation)\n",
        "    if NETWORK.use_batchnorm_after_conv_layers:\n",
        "        images_network = batch_normalization(images_network)\n",
        "    images_network = max_pool_2d(images_network, 3, strides = 2)\n",
        "    images_network = dropout(images_network, keep_prob=keep_prob)\n",
        "    images_network = fully_connected(images_network, 4096, activation=NETWORK.activation)\n",
        "    images_network = dropout(images_network, keep_prob=keep_prob)\n",
        "    images_network = fully_connected(images_network, 1024, activation=NETWORK.activation)\n",
        "    if NETWORK.use_batchnorm_after_fully_connected_layers:\n",
        "        images_network = batch_normalization(images_network)\n",
        "\n",
        "    if NETWORK.use_landmarks or NETWORK.use_hog_and_landmarks:\n",
        "        if NETWORK.use_hog_sliding_window_and_landmarks:\n",
        "            landmarks_network = input_data(shape=[None, 2728], name='input2')\n",
        "        elif NETWORK.use_hog_and_landmarks:\n",
        "            landmarks_network = input_data(shape=[None, 208], name='input2')\n",
        "        else:\n",
        "            landmarks_network = input_data(shape=[None, 68, 2], name='input2')\n",
        "        landmarks_network = fully_connected(landmarks_network, 1024, activation=NETWORK.activation)\n",
        "        if NETWORK.use_batchnorm_after_fully_connected_layers:\n",
        "            landmarks_network = batch_normalization(landmarks_network)\n",
        "        landmarks_network = fully_connected(landmarks_network, 128, activation=NETWORK.activation)\n",
        "        if NETWORK.use_batchnorm_after_fully_connected_layers:\n",
        "            landmarks_network = batch_normalization(landmarks_network)\n",
        "        images_network = fully_connected(images_network, 128, activation=NETWORK.activation)\n",
        "        network = merge([images_network, landmarks_network], 'concat', axis=1)\n",
        "    else:\n",
        "        network = images_network\n",
        "    network = fully_connected(network, NETWORK.output_size, activation='softmax')\n",
        "\n",
        "    if optimizer == 'momentum':\n",
        "        optimizer = Momentum(learning_rate=learning_rate, momentum=optimizer_param, \n",
        "                    lr_decay=learning_rate_decay, decay_step=decay_step)\n",
        "    elif optimizer == 'adam':\n",
        "        optimizer = Adam(learning_rate=learning_rate, beta1=optimizer_param, beta2=learning_rate_decay)\n",
        "    else:\n",
        "        print( \"Unknown optimizer: {}\".format(optimizer))\n",
        "    network = regression(network, optimizer=optimizer, loss=NETWORK.loss, learning_rate=learning_rate, name='output')\n",
        "\n",
        "    return network\n",
        "\n",
        "def build_modelA(optimizer=HYPERPARAMS.optimizer, optimizer_param=HYPERPARAMS.optimizer_param, \n",
        "    learning_rate=HYPERPARAMS.learning_rate, keep_prob=HYPERPARAMS.keep_prob,\n",
        "    learning_rate_decay=HYPERPARAMS.learning_rate_decay, decay_step=HYPERPARAMS.decay_step):\n",
        "\n",
        "    images_network = input_data(shape=[None, NETWORK.input_size, NETWORK.input_size, 1], name='input1')\n",
        "    images_network = conv_2d(images_network, 64, 5, activation=NETWORK.activation)\n",
        "    #images_network = local_response_normalization(images_network)\n",
        "    if NETWORK.use_batchnorm_after_conv_layers:\n",
        "        images_network = batch_normalization(images_network)\n",
        "    images_network = max_pool_2d(images_network, 3, strides = 2)\n",
        "    images_network = conv_2d(images_network, 64, 5, activation=NETWORK.activation)\n",
        "    if NETWORK.use_batchnorm_after_conv_layers:\n",
        "        images_network = batch_normalization(images_network)\n",
        "    images_network = max_pool_2d(images_network, 3, strides = 2)\n",
        "    images_network = conv_2d(images_network, 128, 4, activation=NETWORK.activation)\n",
        "    if NETWORK.use_batchnorm_after_conv_layers:\n",
        "        images_network = batch_normalization(images_network)\n",
        "    images_network = dropout(images_network, keep_prob=keep_prob)\n",
        "    images_network = fully_connected(images_network, 1024, activation=NETWORK.activation)\n",
        "    if NETWORK.use_batchnorm_after_fully_connected_layers:\n",
        "        images_network = batch_normalization(images_network)\n",
        "\n",
        "    if NETWORK.use_landmarks or NETWORK.use_hog_and_landmarks:\n",
        "        if NETWORK.use_hog_sliding_window_and_landmarks:\n",
        "            landmarks_network = input_data(shape=[None, 2728], name='input2')\n",
        "        elif NETWORK.use_hog_and_landmarks:\n",
        "            landmarks_network = input_data(shape=[None, 208], name='input2')\n",
        "        else:\n",
        "            landmarks_network = input_data(shape=[None, 68, 2], name='input2')\n",
        "        landmarks_network = fully_connected(landmarks_network, 1024, activation=NETWORK.activation)\n",
        "        if NETWORK.use_batchnorm_after_fully_connected_layers:\n",
        "            landmarks_network = batch_normalization(landmarks_network)\n",
        "        landmarks_network = fully_connected(landmarks_network, 40, activation=NETWORK.activation)\n",
        "        if NETWORK.use_batchnorm_after_fully_connected_layers:\n",
        "            landmarks_network = batch_normalization(landmarks_network)\n",
        "        images_network = fully_connected(images_network, 40, activation=NETWORK.activation)\n",
        "        network = merge([images_network, landmarks_network], 'concat', axis=1)\n",
        "    else:\n",
        "        network = images_network\n",
        "    network = fully_connected(network, NETWORK.output_size, activation='softmax')\n",
        "\n",
        "    if optimizer == 'momentum':\n",
        "        optimizer = Momentum(learning_rate=learning_rate, momentum=optimizer_param, \n",
        "                    lr_decay=learning_rate_decay, decay_step=decay_step)\n",
        "    elif optimizer == 'adam':\n",
        "        optimizer = Adam(learning_rate=learning_rate, beta1=optimizer_param, beta2=learning_rate_decay)\n",
        "    else:\n",
        "        print( \"Unknown optimizer: {}\".format(optimizer))\n",
        "    network = regression(network, optimizer=optimizer, loss=NETWORK.loss, learning_rate=learning_rate, name='output')\n",
        "\n",
        "    return network"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NC92MdsQmGF"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldNnX25bdFbK"
      },
      "source": [
        "def train(optimizer=HYPERPARAMS.optimizer, optimizer_param=HYPERPARAMS.optimizer_param, \n",
        "        learning_rate=HYPERPARAMS.learning_rate, keep_prob=HYPERPARAMS.keep_prob, \n",
        "        learning_rate_decay=HYPERPARAMS.learning_rate_decay, decay_step=HYPERPARAMS.decay_step,\n",
        "        train_model=True):\n",
        "\n",
        "        print( \"loading dataset \" + DATASET.name + \"...\")\n",
        "        if train_model:\n",
        "                data, validation = load_data(validation=True)\n",
        "        else:\n",
        "                data, validation, test = load_data(validation=True, test=True)\n",
        "\n",
        "        with tf.Graph().as_default():\n",
        "                print( \"building model...\")\n",
        "                network = build_model(optimizer, optimizer_param, learning_rate, \n",
        "                          keep_prob, learning_rate_decay, decay_step)\n",
        "                model = DNN(network, tensorboard_dir=TRAINING.logs_dir, \n",
        "                        tensorboard_verbose=0, checkpoint_path=TRAINING.checkpoint_dir,\n",
        "                        max_checkpoints=TRAINING.max_checkpoints)\n",
        "\n",
        "                #tflearn.config.init_graph(seed=None, log_device=False, num_cores=6)\n",
        "\n",
        "                if train_model:\n",
        "                        # Training phase\n",
        "                        print( \"start training...\")\n",
        "                        print( \"  - emotions = {}\".format(NETWORK.output_size))\n",
        "                        print( \"  - model = {}\".format(NETWORK.model))\n",
        "                        print( \"  - optimizer = '{}'\".format(optimizer))\n",
        "                        print( \"  - learning_rate = {}\".format(learning_rate))\n",
        "                        print( \"  - learning_rate_decay = {}\".format(learning_rate_decay))\n",
        "                        print( \"  - otimizer_param ({}) = {}\".format('beta1' if optimizer == 'adam' else 'momentum', optimizer_param))\n",
        "                        print( \"  - keep_prob = {}\".format(keep_prob))\n",
        "                        print( \"  - epochs = {}\".format(TRAINING.epochs))\n",
        "                        print( \"  - use landmarks = {}\".format(NETWORK.use_landmarks))\n",
        "                        print( \"  - use hog + landmarks = {}\".format(NETWORK.use_hog_and_landmarks))\n",
        "                        print( \"  - use hog sliding window + landmarks = {}\".format(NETWORK.use_hog_sliding_window_and_landmarks))\n",
        "                        print( \"  - use batchnorm after conv = {}\".format(NETWORK.use_batchnorm_after_conv_layers))\n",
        "                        print( \"  - use batchnorm after fc = {}\".format(NETWORK.use_batchnorm_after_fully_connected_layers))\n",
        "\n",
        "                        start_time = time.time()\n",
        "                        if NETWORK.use_landmarks:\n",
        "                                model.fit([data['X'], data['X2']], data['Y'],\n",
        "                                        validation_set=([validation['X'], validation['X2']], validation['Y']),\n",
        "                                        snapshot_step=TRAINING.snapshot_step,\n",
        "                                        show_metric=TRAINING.vizualize,\n",
        "                                        batch_size=TRAINING.batch_size,\n",
        "                                        n_epoch=TRAINING.epochs)\n",
        "                        else:\n",
        "                                model.fit(data['X'], data['Y'],\n",
        "                                        validation_set=(validation['X'], validation['Y']),\n",
        "                                        snapshot_step=TRAINING.snapshot_step,\n",
        "                                        show_metric=TRAINING.vizualize,\n",
        "                                        batch_size=TRAINING.batch_size,\n",
        "                                        n_epoch=TRAINING.epochs)\n",
        "                                validation['X2'] = None\n",
        "                        training_time = time.time() - start_time\n",
        "                        print( \"training time = {0:.1f} sec\".format(training_time))\n",
        "\n",
        "                        if TRAINING.save_model:\n",
        "                                print( \"saving model...\")\n",
        "                                model.save(TRAINING.save_model_path)\n",
        "                                if not(os.path.isfile(TRAINING.save_model_path)) and \\\n",
        "                                        os.path.isfile(TRAINING.save_model_path + \".meta\"):\n",
        "                                        os.rename(TRAINING.save_model_path + \".meta\", TRAINING.save_model_path)\n",
        "\n",
        "                        print( \"evaluating...\")\n",
        "                        validation_accuracy = evaluate(model, validation['X'], validation['X2'], validation['Y'])\n",
        "                        print( \"  - validation accuracy = {0:.1f}\".format(validation_accuracy*100))\n",
        "                        return validation_accuracy\n",
        "                else:\n",
        "                        # Testing phase : load saved model and evaluate on test dataset\n",
        "                        print( \"start evaluation...\")\n",
        "                        print( \"loading pretrained model...\")\n",
        "                        if os.path.isfile(TRAINING.save_model_path):\n",
        "                                model.load(TRAINING.save_model_path)\n",
        "                        else:\n",
        "                                print( \"Error: file '{}' not found\".format(TRAINING.save_model_path))\n",
        "                                exit()\n",
        "                        \n",
        "                        if not NETWORK.use_landmarks:\n",
        "                                validation['X2'] = None\n",
        "                                test['X2'] = None\n",
        "\n",
        "                        print( \"--\")\n",
        "                        print( \"Validation samples: {}\".format(len(validation['Y'])))\n",
        "                        print( \"Test samples: {}\".format(len(test['Y'])))\n",
        "                        print( \"--\")\n",
        "                        print( \"evaluating...\")\n",
        "                        start_time = time.time()\n",
        "                        validation_accuracy = evaluate(model, validation['X'], validation['X2'], validation['Y'])\n",
        "                        print( \"  - validation accuracy = {0:.1f}\".format(validation_accuracy*100))\n",
        "                        test_accuracy = evaluate(model, test['X'], test['X2'], test['Y'])\n",
        "                        print( \"  - test accuracy = {0:.1f}\".format(test_accuracy*100))\n",
        "                        print( \"  - evalution time = {0:.1f} sec\".format(time.time() - start_time))\n",
        "                        return test_accuracy\n",
        "\n",
        "def evaluate(model, X, X2, Y):\n",
        "        if NETWORK.use_landmarks:\n",
        "                accuracy = model.evaluate([X, X2], Y)\n",
        "        else:\n",
        "                accuracy = model.evaluate(X, Y)\n",
        "        return accuracy[0]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z19TVuzJgqLh",
        "outputId": "d3f7dbd4-6849-4cfb-9cfb-7c4757e18f26"
      },
      "source": [
        "# train\n",
        "train()\n",
        "# evaluate\n",
        "# train(train_model=False)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 350  | total loss: \u001b[1m\u001b[32m0.13052\u001b[0m\u001b[0m | time: 1.867s\n",
            "| Momentum | epoch: 013 | loss: 0.13052 - acc: 0.9690 -- iter: 3328/3436\n",
            "Training Step: 351  | total loss: \u001b[1m\u001b[32m0.12323\u001b[0m\u001b[0m | time: 2.937s\n",
            "| Momentum | epoch: 013 | loss: 0.12323 - acc: 0.9713 | val_loss: 1.72887 - val_acc: 0.7143 -- iter: 3436/3436\n",
            "--\n",
            "training time = 230.3 sec\n",
            "saving model...\n",
            "evaluating...\n",
            "  - validation accuracy = 71.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7142857313156128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VA-YAtKjDkm",
        "outputId": "1530dcc5-de4f-4086-a0d2-9b944c47c777"
      },
      "source": [
        "train(train_model=False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading dataset Fer2013...\n",
            "building model...\n",
            "start evaluation...\n",
            "loading pretrained model...\n",
            "INFO:tensorflow:Restoring parameters from /content/best_model/saved_model.bin\n",
            "--\n",
            "Validation samples: 56\n",
            "Test samples: 8\n",
            "--\n",
            "evaluating...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  - validation accuracy = 71.4\n",
            "  - test accuracy = 62.5\n",
            "  - evalution time = 2.0 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1v27cdsjhcX"
      },
      "source": [
        "# ZIP model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mciHGPunjiz2",
        "outputId": "f7efc82a-76e4-4072-eb01-7f751fc4df76"
      },
      "source": [
        "!zip -r \"drive/MyDrive/AIHealthcare/Facial_expressions_model_data/LANDMARKS_HOG_best_model.zip\" \"/content/best_model\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/best_model/ (stored 0%)\n",
            "  adding: content/best_model/checkpoint (deflated 47%)\n",
            "  adding: content/best_model/saved_model.bin.index (deflated 49%)\n",
            "  adding: content/best_model/saved_model.bin.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/best_model/saved_model.bin (deflated 91%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}