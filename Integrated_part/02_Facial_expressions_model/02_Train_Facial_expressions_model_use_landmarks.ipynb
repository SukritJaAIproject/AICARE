{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_Train_Facial_expressions_model_use_landmarks.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mnDoSNUFQpjI",
        "f6AY5vjIdzlS",
        "YdoqV48vd3qN"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnDoSNUFQpjI"
      },
      "source": [
        "# pip install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JN-i942BBfA"
      },
      "source": [
        "pip install tflearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1g-cNpJdcZa"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tflearn import DNN\n",
        "import time\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf \n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.merge_ops import merge_outputs, merge\n",
        "from tflearn.layers.normalization import local_response_normalization, batch_normalization\n",
        "from tflearn.layers.estimator import regression \n",
        "from tflearn.optimizers import Momentum, Adam"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tN2ILBzfAFP",
        "outputId": "2105be05-7c22-4c6d-a8ef-687731f9f392"
      },
      "source": [
        "ls 'drive/MyDrive/AIHealthcare/Facial_expressions_model_data/Onlylandmark'"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mPrivateTest\u001b[0m/  \u001b[01;34mPublicTest\u001b[0m/  \u001b[01;34mTraining\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8meOIU6FeZjt"
      },
      "source": [
        "# ls 'drive/MyDrive/AIHealthcare/Facial_expressions_model_data/Onlylandmark'\n",
        "# ls 'drive/MyDrive/AIHealthcare/Facial_expressions_model_data/LANDMARKS_HOG'\n",
        "# ls 'drive/MyDrive/AIHealthcare/Facial_expressions_model_data/Facelandmarks_HOG_sliding_window'"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6AY5vjIdzlS"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4H9Zzm1dvj1"
      },
      "source": [
        "class Dataset:\n",
        "    name = 'Fer2013'\n",
        "    train_folder = 'drive/MyDrive/AIHealthcare/Facial_expressions_model_data/Onlylandmark/Training'\n",
        "    validation_folder = 'drive/MyDrive/AIHealthcare/Facial_expressions_model_data/Onlylandmark/PublicTest'\n",
        "    test_folder = 'drive/MyDrive/AIHealthcare/Facial_expressions_model_data/Onlylandmark/PrivateTest'\n",
        "    shape_predictor_path='drive/MyDrive/AIHealthcare/facial_expression_recognition_using_cnn/shape_predictor_68_face_landmarks.dat'\n",
        "    trunc_trainset_to = -1  # put the number of train images to use (-1 = all images of the train set)\n",
        "    trunc_validationset_to = -1\n",
        "    trunc_testset_to = -1\n",
        "\n",
        "class Network:\n",
        "    model = 'B'\n",
        "    input_size = 48\n",
        "    output_size = 7\n",
        "    activation = 'relu'\n",
        "    loss = 'categorical_crossentropy'\n",
        "    use_landmarks = True\n",
        "    use_hog_and_landmarks = False\n",
        "    use_hog_sliding_window_and_landmarks = False\n",
        "    use_batchnorm_after_conv_layers = True\n",
        "    use_batchnorm_after_fully_connected_layers = False\n",
        "\n",
        "class Hyperparams:\n",
        "    keep_prob = 0.956   # dropout = 1 - keep_prob\n",
        "    learning_rate = 0.016\n",
        "    learning_rate_decay = 0.864\n",
        "    decay_step = 50\n",
        "    optimizer = 'momentum'  # {'momentum', 'adam', 'rmsprop', 'adagrad', 'adadelta'}\n",
        "    optimizer_param = 0.95   # momentum value for Momentum optimizer, or beta1 value for Adam\n",
        "\n",
        "class Training:\n",
        "    batch_size = 128\n",
        "    epochs = 13\n",
        "    snapshot_step = 500\n",
        "    vizualize = True\n",
        "    logs_dir = \"logs\"\n",
        "    checkpoint_dir = \"checkpoints/chk\"\n",
        "    best_checkpoint_path = \"checkpoints/best/\"\n",
        "    max_checkpoints = 1\n",
        "    checkpoint_frequency = 1.0 # in hours\n",
        "    save_model = True\n",
        "    save_model_path = \"best_model/saved_model.bin\"\n",
        "\n",
        "class VideoPredictor:\n",
        "    emotions = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\n",
        "    print_emotions = False\n",
        "    camera_source = 0\n",
        "    face_detection_classifier = \"lbpcascade_frontalface.xml\"\n",
        "    show_confidence = False\n",
        "    time_to_wait_between_predictions = 0.5\n",
        "\n",
        "class OptimizerSearchSpace:\n",
        "    learning_rate = {'min': 0.00001, 'max': 0.1}\n",
        "    learning_rate_decay = {'min': 0.5, 'max': 0.99}\n",
        "    optimizer = ['momentum']   # ['momentum', 'adam', 'rmsprop', 'adagrad', 'adadelta']\n",
        "    optimizer_param = {'min': 0.5, 'max': 0.99}\n",
        "    keep_prob = {'min': 0.7, 'max': 0.99}\n",
        "\n",
        "def make_dir(folder):\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "\n",
        "DATASET = Dataset()\n",
        "NETWORK = Network()\n",
        "TRAINING = Training()\n",
        "HYPERPARAMS = Hyperparams()\n",
        "VIDEO_PREDICTOR = VideoPredictor()\n",
        "OPTIMIZER = OptimizerSearchSpace()\n",
        "\n",
        "make_dir(TRAINING.logs_dir)\n",
        "make_dir(TRAINING.checkpoint_dir)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdoqV48vd3qN"
      },
      "source": [
        "# data_loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DgoqgHqdiFa"
      },
      "source": [
        "def load_data(validation=False, test=False):\n",
        "    \n",
        "    data_dict = dict()\n",
        "    validation_dict = dict()\n",
        "    test_dict = dict()\n",
        "\n",
        "    if DATASET.name == \"Fer2013\":\n",
        "\n",
        "        # load train set\n",
        "        data_dict['X'] = np.load(DATASET.train_folder + '/images.npy')\n",
        "        data_dict['X'] = data_dict['X'].reshape([-1, NETWORK.input_size, NETWORK.input_size, 1])\n",
        "        if NETWORK.use_landmarks:\n",
        "            data_dict['X2'] = np.load(DATASET.train_folder + '/landmarks.npy')\n",
        "        if NETWORK.use_hog_and_landmarks:\n",
        "            data_dict['X2'] = np.load(DATASET.train_folder + '/landmarks.npy')\n",
        "            data_dict['X2'] = np.array([x.flatten() for x in data_dict['X2']])\n",
        "            data_dict['X2'] = np.concatenate((data_dict['X2'], np.load(DATASET.train_folder + '/hog_features.npy')), axis=1)\n",
        "        data_dict['Y'] = np.load(DATASET.train_folder + '/labels.npy')\n",
        "        if DATASET.trunc_trainset_to > 0:\n",
        "            data_dict['X'] = data_dict['X'][0:DATASET.trunc_trainset_to, :, :]\n",
        "            if NETWORK.use_landmarks and NETWORK.use_hog_and_landmarks:\n",
        "                data_dict['X2'] = data_dict['X2'][0:DATASET.trunc_trainset_to, :]\n",
        "            elif NETWORK.use_landmarks:\n",
        "                data_dict['X2'] = data_dict['X2'][0:DATASET.trunc_trainset_to, :, :]\n",
        "            data_dict['Y'] = data_dict['Y'][0:DATASET.trunc_trainset_to, :]\n",
        "\n",
        "        if validation:\n",
        "            # load validation set\n",
        "            validation_dict['X'] = np.load(DATASET.validation_folder + '/images.npy')\n",
        "            validation_dict['X'] = validation_dict['X'].reshape([-1, NETWORK.input_size, NETWORK.input_size, 1])\n",
        "            if NETWORK.use_landmarks:\n",
        "                validation_dict['X2'] = np.load(DATASET.validation_folder + '/landmarks.npy')\n",
        "            if NETWORK.use_hog_and_landmarks:\n",
        "                validation_dict['X2'] = np.load(DATASET.validation_folder + '/landmarks.npy')\n",
        "                validation_dict['X2'] = np.array([x.flatten() for x in validation_dict['X2']])\n",
        "                validation_dict['X2'] = np.concatenate((validation_dict['X2'], np.load(DATASET.validation_folder + '/hog_features.npy')), axis=1)\n",
        "            validation_dict['Y'] = np.load(DATASET.validation_folder + '/labels.npy')\n",
        "            if DATASET.trunc_validationset_to > 0:\n",
        "                validation_dict['X'] = validation_dict['X'][0:DATASET.trunc_validationset_to, :, :]\n",
        "                if NETWORK.use_landmarks and NETWORK.use_hog_and_landmarks:\n",
        "                    validation_dict['X2'] = validation_dict['X2'][0:DATASET.trunc_validationset_to, :]\n",
        "                elif NETWORK.use_landmarks:\n",
        "                    validation_dict['X2'] = validation_dict['X2'][0:DATASET.trunc_validationset_to, :, :]\n",
        "                validation_dict['Y'] = validation_dict['Y'][0:DATASET.trunc_validationset_to, :]\n",
        "        \n",
        "        if test:\n",
        "            # load test set\n",
        "            test_dict['X'] = np.load(DATASET.test_folder + '/images.npy')\n",
        "            test_dict['X'] = test_dict['X'].reshape([-1, NETWORK.input_size, NETWORK.input_size, 1])\n",
        "            if NETWORK.use_landmarks:\n",
        "                test_dict['X2'] = np.load(DATASET.test_folder + '/landmarks.npy')\n",
        "            if NETWORK.use_hog_and_landmarks:\n",
        "                test_dict['X2'] = np.load(DATASET.test_folder + '/landmarks.npy')\n",
        "                test_dict['X2'] = np.array([x.flatten() for x in test_dict['X2']])\n",
        "                test_dict['X2'] = np.concatenate((test_dict['X2'], np.load(DATASET.test_folder + '/hog_features.npy')), axis=1)\n",
        "            test_dict['Y'] = np.load(DATASET.test_folder + '/labels.npy')\n",
        "            if DATASET.trunc_testset_to > 0:\n",
        "                test_dict['X'] = test_dict['X'][0:DATASET.trunc_testset_to, :, :]\n",
        "                if NETWORK.use_landmarks and NETWORK.use_hog_and_landmarks:\n",
        "                    test_dict['X2'] = test_dict['X2'][0:DATASET.trunc_testset_to, :]\n",
        "                elif NETWORK.use_landmarks:\n",
        "                    test_dict['X2'] = test_dict['X2'][0:DATASET.trunc_testset_to, :, :]\n",
        "                test_dict['Y'] = test_dict['Y'][0:DATASET.trunc_testset_to, :]\n",
        "\n",
        "        if not validation and not test:\n",
        "            return data_dict\n",
        "        elif not test:\n",
        "            return data_dict, validation_dict\n",
        "        else: \n",
        "            return data_dict, validation_dict, test_dict\n",
        "    else:\n",
        "        print( \"Unknown dataset\")\n",
        "        exit()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jbq-NXJSeMXI"
      },
      "source": [
        "## model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdXJQ1j5eLCF"
      },
      "source": [
        "def build_model(optimizer=HYPERPARAMS.optimizer, optimizer_param=HYPERPARAMS.optimizer_param, \n",
        "    learning_rate=HYPERPARAMS.learning_rate, keep_prob=HYPERPARAMS.keep_prob,\n",
        "    learning_rate_decay=HYPERPARAMS.learning_rate_decay, decay_step=HYPERPARAMS.decay_step):\n",
        "\n",
        "    if NETWORK.model == 'A':\n",
        "        return build_modelA(optimizer, optimizer_param, learning_rate, keep_prob, learning_rate_decay, decay_step)\n",
        "    elif NETWORK.model == 'B':\n",
        "        return build_modelB(optimizer, optimizer_param, learning_rate, keep_prob, learning_rate_decay, decay_step)\n",
        "    else:\n",
        "        print( \"ERROR: no model \" + str(NETWORK.model))\n",
        "        exit()\n",
        "\n",
        "def build_modelB(optimizer=HYPERPARAMS.optimizer, optimizer_param=HYPERPARAMS.optimizer_param, \n",
        "    learning_rate=HYPERPARAMS.learning_rate, keep_prob=HYPERPARAMS.keep_prob,\n",
        "    learning_rate_decay=HYPERPARAMS.learning_rate_decay, decay_step=HYPERPARAMS.decay_step):\n",
        "\n",
        "    images_network = input_data(shape=[None, NETWORK.input_size, NETWORK.input_size, 1], name='input1')\n",
        "    images_network = conv_2d(images_network, 64, 3, activation=NETWORK.activation)\n",
        "    #images_network = local_response_normalization(images_network)\n",
        "    if NETWORK.use_batchnorm_after_conv_layers:\n",
        "        images_network = batch_normalization(images_network)\n",
        "    images_network = max_pool_2d(images_network, 3, strides = 2)\n",
        "    images_network = conv_2d(images_network, 128, 3, activation=NETWORK.activation)\n",
        "    if NETWORK.use_batchnorm_after_conv_layers:\n",
        "        images_network = batch_normalization(images_network)\n",
        "    images_network = max_pool_2d(images_network, 3, strides = 2)\n",
        "    images_network = conv_2d(images_network, 256, 3, activation=NETWORK.activation)\n",
        "    if NETWORK.use_batchnorm_after_conv_layers:\n",
        "        images_network = batch_normalization(images_network)\n",
        "    images_network = max_pool_2d(images_network, 3, strides = 2)\n",
        "    images_network = dropout(images_network, keep_prob=keep_prob)\n",
        "    images_network = fully_connected(images_network, 4096, activation=NETWORK.activation)\n",
        "    images_network = dropout(images_network, keep_prob=keep_prob)\n",
        "    images_network = fully_connected(images_network, 1024, activation=NETWORK.activation)\n",
        "    if NETWORK.use_batchnorm_after_fully_connected_layers:\n",
        "        images_network = batch_normalization(images_network)\n",
        "\n",
        "    if NETWORK.use_landmarks or NETWORK.use_hog_and_landmarks:\n",
        "        if NETWORK.use_hog_sliding_window_and_landmarks:\n",
        "            landmarks_network = input_data(shape=[None, 2728], name='input2')\n",
        "        elif NETWORK.use_hog_and_landmarks:\n",
        "            landmarks_network = input_data(shape=[None, 208], name='input2')\n",
        "        else:\n",
        "            landmarks_network = input_data(shape=[None, 68, 2], name='input2')\n",
        "        landmarks_network = fully_connected(landmarks_network, 1024, activation=NETWORK.activation)\n",
        "        if NETWORK.use_batchnorm_after_fully_connected_layers:\n",
        "            landmarks_network = batch_normalization(landmarks_network)\n",
        "        landmarks_network = fully_connected(landmarks_network, 128, activation=NETWORK.activation)\n",
        "        if NETWORK.use_batchnorm_after_fully_connected_layers:\n",
        "            landmarks_network = batch_normalization(landmarks_network)\n",
        "        images_network = fully_connected(images_network, 128, activation=NETWORK.activation)\n",
        "        network = merge([images_network, landmarks_network], 'concat', axis=1)\n",
        "    else:\n",
        "        network = images_network\n",
        "    network = fully_connected(network, NETWORK.output_size, activation='softmax')\n",
        "\n",
        "    if optimizer == 'momentum':\n",
        "        optimizer = Momentum(learning_rate=learning_rate, momentum=optimizer_param, \n",
        "                    lr_decay=learning_rate_decay, decay_step=decay_step)\n",
        "    elif optimizer == 'adam':\n",
        "        optimizer = Adam(learning_rate=learning_rate, beta1=optimizer_param, beta2=learning_rate_decay)\n",
        "    else:\n",
        "        print( \"Unknown optimizer: {}\".format(optimizer))\n",
        "    network = regression(network, optimizer=optimizer, loss=NETWORK.loss, learning_rate=learning_rate, name='output')\n",
        "\n",
        "    return network\n",
        "\n",
        "def build_modelA(optimizer=HYPERPARAMS.optimizer, optimizer_param=HYPERPARAMS.optimizer_param, \n",
        "    learning_rate=HYPERPARAMS.learning_rate, keep_prob=HYPERPARAMS.keep_prob,\n",
        "    learning_rate_decay=HYPERPARAMS.learning_rate_decay, decay_step=HYPERPARAMS.decay_step):\n",
        "\n",
        "    images_network = input_data(shape=[None, NETWORK.input_size, NETWORK.input_size, 1], name='input1')\n",
        "    images_network = conv_2d(images_network, 64, 5, activation=NETWORK.activation)\n",
        "    #images_network = local_response_normalization(images_network)\n",
        "    if NETWORK.use_batchnorm_after_conv_layers:\n",
        "        images_network = batch_normalization(images_network)\n",
        "    images_network = max_pool_2d(images_network, 3, strides = 2)\n",
        "    images_network = conv_2d(images_network, 64, 5, activation=NETWORK.activation)\n",
        "    if NETWORK.use_batchnorm_after_conv_layers:\n",
        "        images_network = batch_normalization(images_network)\n",
        "    images_network = max_pool_2d(images_network, 3, strides = 2)\n",
        "    images_network = conv_2d(images_network, 128, 4, activation=NETWORK.activation)\n",
        "    if NETWORK.use_batchnorm_after_conv_layers:\n",
        "        images_network = batch_normalization(images_network)\n",
        "    images_network = dropout(images_network, keep_prob=keep_prob)\n",
        "    images_network = fully_connected(images_network, 1024, activation=NETWORK.activation)\n",
        "    if NETWORK.use_batchnorm_after_fully_connected_layers:\n",
        "        images_network = batch_normalization(images_network)\n",
        "\n",
        "    if NETWORK.use_landmarks or NETWORK.use_hog_and_landmarks:\n",
        "        if NETWORK.use_hog_sliding_window_and_landmarks:\n",
        "            landmarks_network = input_data(shape=[None, 2728], name='input2')\n",
        "        elif NETWORK.use_hog_and_landmarks:\n",
        "            landmarks_network = input_data(shape=[None, 208], name='input2')\n",
        "        else:\n",
        "            landmarks_network = input_data(shape=[None, 68, 2], name='input2')\n",
        "        landmarks_network = fully_connected(landmarks_network, 1024, activation=NETWORK.activation)\n",
        "        if NETWORK.use_batchnorm_after_fully_connected_layers:\n",
        "            landmarks_network = batch_normalization(landmarks_network)\n",
        "        landmarks_network = fully_connected(landmarks_network, 40, activation=NETWORK.activation)\n",
        "        if NETWORK.use_batchnorm_after_fully_connected_layers:\n",
        "            landmarks_network = batch_normalization(landmarks_network)\n",
        "        images_network = fully_connected(images_network, 40, activation=NETWORK.activation)\n",
        "        network = merge([images_network, landmarks_network], 'concat', axis=1)\n",
        "    else:\n",
        "        network = images_network\n",
        "    network = fully_connected(network, NETWORK.output_size, activation='softmax')\n",
        "\n",
        "    if optimizer == 'momentum':\n",
        "        optimizer = Momentum(learning_rate=learning_rate, momentum=optimizer_param, \n",
        "                    lr_decay=learning_rate_decay, decay_step=decay_step)\n",
        "    elif optimizer == 'adam':\n",
        "        optimizer = Adam(learning_rate=learning_rate, beta1=optimizer_param, beta2=learning_rate_decay)\n",
        "    else:\n",
        "        print( \"Unknown optimizer: {}\".format(optimizer))\n",
        "    network = regression(network, optimizer=optimizer, loss=NETWORK.loss, learning_rate=learning_rate, name='output')\n",
        "\n",
        "    return network"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NC92MdsQmGF"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldNnX25bdFbK"
      },
      "source": [
        "def train(optimizer=HYPERPARAMS.optimizer, optimizer_param=HYPERPARAMS.optimizer_param, \n",
        "        learning_rate=HYPERPARAMS.learning_rate, keep_prob=HYPERPARAMS.keep_prob, \n",
        "        learning_rate_decay=HYPERPARAMS.learning_rate_decay, decay_step=HYPERPARAMS.decay_step,\n",
        "        train_model=True):\n",
        "\n",
        "        print( \"loading dataset \" + DATASET.name + \"...\")\n",
        "        if train_model:\n",
        "                data, validation = load_data(validation=True)\n",
        "        else:\n",
        "                data, validation, test = load_data(validation=True, test=True)\n",
        "\n",
        "        with tf.Graph().as_default():\n",
        "                print( \"building model...\")\n",
        "                network = build_model(optimizer, optimizer_param, learning_rate, \n",
        "                          keep_prob, learning_rate_decay, decay_step)\n",
        "                model = DNN(network, tensorboard_dir=TRAINING.logs_dir, \n",
        "                        tensorboard_verbose=0, checkpoint_path=TRAINING.checkpoint_dir,\n",
        "                        max_checkpoints=TRAINING.max_checkpoints)\n",
        "\n",
        "                #tflearn.config.init_graph(seed=None, log_device=False, num_cores=6)\n",
        "\n",
        "                if train_model:\n",
        "                        # Training phase\n",
        "                        print( \"start training...\")\n",
        "                        print( \"  - emotions = {}\".format(NETWORK.output_size))\n",
        "                        print( \"  - model = {}\".format(NETWORK.model))\n",
        "                        print( \"  - optimizer = '{}'\".format(optimizer))\n",
        "                        print( \"  - learning_rate = {}\".format(learning_rate))\n",
        "                        print( \"  - learning_rate_decay = {}\".format(learning_rate_decay))\n",
        "                        print( \"  - otimizer_param ({}) = {}\".format('beta1' if optimizer == 'adam' else 'momentum', optimizer_param))\n",
        "                        print( \"  - keep_prob = {}\".format(keep_prob))\n",
        "                        print( \"  - epochs = {}\".format(TRAINING.epochs))\n",
        "                        print( \"  - use landmarks = {}\".format(NETWORK.use_landmarks))\n",
        "                        print( \"  - use hog + landmarks = {}\".format(NETWORK.use_hog_and_landmarks))\n",
        "                        print( \"  - use hog sliding window + landmarks = {}\".format(NETWORK.use_hog_sliding_window_and_landmarks))\n",
        "                        print( \"  - use batchnorm after conv = {}\".format(NETWORK.use_batchnorm_after_conv_layers))\n",
        "                        print( \"  - use batchnorm after fc = {}\".format(NETWORK.use_batchnorm_after_fully_connected_layers))\n",
        "\n",
        "                        start_time = time.time()\n",
        "                        if NETWORK.use_landmarks:\n",
        "                                model.fit([data['X'], data['X2']], data['Y'],\n",
        "                                        validation_set=([validation['X'], validation['X2']], validation['Y']),\n",
        "                                        snapshot_step=TRAINING.snapshot_step,\n",
        "                                        show_metric=TRAINING.vizualize,\n",
        "                                        batch_size=TRAINING.batch_size,\n",
        "                                        n_epoch=TRAINING.epochs)\n",
        "                        else:\n",
        "                                model.fit(data['X'], data['Y'],\n",
        "                                        validation_set=(validation['X'], validation['Y']),\n",
        "                                        snapshot_step=TRAINING.snapshot_step,\n",
        "                                        show_metric=TRAINING.vizualize,\n",
        "                                        batch_size=TRAINING.batch_size,\n",
        "                                        n_epoch=TRAINING.epochs)\n",
        "                                validation['X2'] = None\n",
        "                        training_time = time.time() - start_time\n",
        "                        print( \"training time = {0:.1f} sec\".format(training_time))\n",
        "\n",
        "                        if TRAINING.save_model:\n",
        "                                print( \"saving model...\")\n",
        "                                model.save(TRAINING.save_model_path)\n",
        "                                if not(os.path.isfile(TRAINING.save_model_path)) and \\\n",
        "                                        os.path.isfile(TRAINING.save_model_path + \".meta\"):\n",
        "                                        os.rename(TRAINING.save_model_path + \".meta\", TRAINING.save_model_path)\n",
        "\n",
        "                        print( \"evaluating...\")\n",
        "                        validation_accuracy = evaluate(model, validation['X'], validation['X2'], validation['Y'])\n",
        "                        print( \"  - validation accuracy = {0:.1f}\".format(validation_accuracy*100))\n",
        "                        return validation_accuracy\n",
        "                else:\n",
        "                        # Testing phase : load saved model and evaluate on test dataset\n",
        "                        print( \"start evaluation...\")\n",
        "                        print( \"loading pretrained model...\")\n",
        "                        if os.path.isfile(TRAINING.save_model_path):\n",
        "                                model.load(TRAINING.save_model_path)\n",
        "                        else:\n",
        "                                print( \"Error: file '{}' not found\".format(TRAINING.save_model_path))\n",
        "                                exit()\n",
        "                        \n",
        "                        if not NETWORK.use_landmarks:\n",
        "                                validation['X2'] = None\n",
        "                                test['X2'] = None\n",
        "\n",
        "                        print( \"--\")\n",
        "                        print( \"Validation samples: {}\".format(len(validation['Y'])))\n",
        "                        print( \"Test samples: {}\".format(len(test['Y'])))\n",
        "                        print( \"--\")\n",
        "                        print( \"evaluating...\")\n",
        "                        start_time = time.time()\n",
        "                        validation_accuracy = evaluate(model, validation['X'], validation['X2'], validation['Y'])\n",
        "                        print( \"  - validation accuracy = {0:.1f}\".format(validation_accuracy*100))\n",
        "                        test_accuracy = evaluate(model, test['X'], test['X2'], test['Y'])\n",
        "                        print( \"  - test accuracy = {0:.1f}\".format(test_accuracy*100))\n",
        "                        print( \"  - evalution time = {0:.1f} sec\".format(time.time() - start_time))\n",
        "                        return test_accuracy\n",
        "\n",
        "def evaluate(model, X, X2, Y):\n",
        "        if NETWORK.use_landmarks:\n",
        "                accuracy = model.evaluate([X, X2], Y)\n",
        "        else:\n",
        "                accuracy = model.evaluate(X, Y)\n",
        "        return accuracy[0]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z19TVuzJgqLh",
        "outputId": "a1430d19-31a1-4126-d492-05c18c9e8868"
      },
      "source": [
        "# train\n",
        "train()\n",
        "# evaluate\n",
        "# train(train_model=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 296  | total loss: \u001b[1m\u001b[32m0.26815\u001b[0m\u001b[0m | time: 1.098s\n",
            "| Momentum | epoch: 011 | loss: 0.26815 - acc: 0.9336 -- iter: 3328/3436\n",
            "Training Step: 297  | total loss: \u001b[1m\u001b[32m0.26389\u001b[0m\u001b[0m | time: 2.142s\n",
            "| Momentum | epoch: 011 | loss: 0.26389 - acc: 0.9340 | val_loss: 1.90157 - val_acc: 0.6607 -- iter: 3436/3436\n",
            "--\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}