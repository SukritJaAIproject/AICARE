{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "สำเนาของ video_transformers_croped.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a83b3d096e624e93abcd22c58099f795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ee1a85d3da2e49618e1c19a2e3b994ea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6e1611c6dd524d92a14a180ad041d001",
              "IPY_MODEL_5b1b956b1e83469c8389b9098a1a74fe"
            ]
          }
        },
        "ee1a85d3da2e49618e1c19a2e3b994ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6e1611c6dd524d92a14a180ad041d001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_62f6045abe1b45d48377b167f54eab56",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6462b600804e4ec6b78f2b9fc45bcdcb"
          }
        },
        "5b1b956b1e83469c8389b9098a1a74fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5ffa3d8f2c3444e9b3ccfb8606de5902",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 673/? [5:33:27&lt;00:00, 22.19s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c620d053128a4f70982aef5e18fd697a"
          }
        },
        "62f6045abe1b45d48377b167f54eab56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6462b600804e4ec6b78f2b9fc45bcdcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ffa3d8f2c3444e9b3ccfb8606de5902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c620d053128a4f70982aef5e18fd697a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu1WM0x_zeYs"
      },
      "source": [
        "# Video Classification with Transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MD8N6NsDzeYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83aaf309-c2b5-49b4-b35e-2a4493ccf6b9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# !wget -q https://git.io/JGc31 -O ucf101_top5.tar.gz\n",
        "# !tar xf ucf101_top5.tar.gz\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "# !pip install -q py-feat\n",
        "from tensorflow_docs.vis import embed\n",
        "from tensorflow.keras import layers\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow import keras\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "# from feat import Detector\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import imageio\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# face_model = \"RetinaFace\"\n",
        "# landmark_model = \"MobileNet\"\n",
        "# au_model = \"svm\"\n",
        "# emotion_model = \"resmasknet\" #resmasknet,fer, svm, rf\n",
        "# detector = Detector(face_model = face_model, landmark_model = landmark_model, au_model = au_model, emotion_model = emotion_model)\n",
        "\n",
        "MAX_SEQ_LENGTH = 300\n",
        "NUM_FEATURES = 1024\n",
        "IMG_SIZE = 224\n",
        "EPOCHS = 100\n",
        "\n",
        "# test_df['tag'] = test_df['tag'].replace({'stress':'angry'})\n",
        "# from google.colab import files\n",
        "# test_df.to_csv('test_df_5class.csv') \n",
        "# files.download('test_df_5class.csv')\n",
        "# ls 'drive/MyDrive/AIHealthcare/AIcare_Phrase1/data/season2/file_v1/csv_frame/trainv1/test_df_5class.csv'"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLl7ED0F75aM"
      },
      "source": [
        "# train_df = pd.read_csv(\"drive/MyDrive/seqimg_youtube/unzip/labels.csv\")\n",
        "# train_df['tag'] = train_df['tag'].replace({'stress':'angry'})\n",
        "# pd.unique(train_df['tag'])\n",
        "# from google.colab import files\n",
        "# train_df.to_csv('labels.csv') \n",
        "# files.download('labels.csv')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62csZH3IzeY1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "535b5d0f-2948-4bf8-c2aa-27af93f16fcb"
      },
      "source": [
        "train_df = pd.read_csv(\"drive/MyDrive/seqimg_youtube/unzip/labels_5classes.csv\")\n",
        "# test_df = pd.read_csv(\"drive/MyDrive/AIHealthcare/AIcare_Phrase1/data/season2/file_v1/csv_frame/trainv1/test_df_5class.csv\")\n",
        "print(f\"Total videos for training: {len(train_df)}\")\n",
        "# print(f\"Total videos for testing: {len(test_df)}\")\n",
        "center_crop_layer = layers.experimental.preprocessing.CenterCrop(IMG_SIZE, IMG_SIZE)\n",
        "\n",
        "# def crop_center(frame):\n",
        "#     faceimg = detector.detect_faces(frame)\n",
        "#     try:\n",
        "#       pos = faceimg[0][:4]\n",
        "#       cropimg =frame[int(pos[1]):int(pos[3]),int(pos[0]):int(pos[2])] \n",
        "#       cropped = cv2.resize(cropimg, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
        "#     except:\n",
        "#       cropped = frame\n",
        "#       cropped = cv2.resize(cropped, (224, 224), interpolation = cv2.INTER_AREA)\n",
        "#       print('error')\n",
        "#     return cropped\n",
        "\n",
        "def load_video(path, max_frames=0):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            # frame = crop_center(frame)\n",
        "            frame = cv2.resize(frame, (224,224))\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            frames.append(frame)\n",
        "\n",
        "            if len(frames) == max_frames:\n",
        "                break\n",
        "    finally:\n",
        "        cap.release()\n",
        "    return np.array(frames)\n",
        "\n",
        "def build_feature_extractor():\n",
        "    feature_extractor = keras.applications.DenseNet121(weights=\"imagenet\",include_top=False,pooling=\"avg\",input_shape=(IMG_SIZE, IMG_SIZE, 3),)\n",
        "    preprocess_input = keras.applications.densenet.preprocess_input\n",
        "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "    preprocessed = preprocess_input(inputs)\n",
        "    outputs = feature_extractor(preprocessed)\n",
        "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
        "feature_extractor = build_feature_extractor()\n",
        "label_processor = keras.layers.experimental.preprocessing.StringLookup(num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"]), mask_token=None)\n",
        "print(label_processor.get_vocabulary())\n",
        "\n",
        "def prepare_all_videos(df, root_dir):\n",
        "    num_samples = len(df)\n",
        "    video_paths = df[\"video_name\"].tolist()\n",
        "    labels = df[\"tag\"]\n",
        "    labels = label_processor(labels[..., None]).numpy()\n",
        "    frame_features = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
        "\n",
        "    for idx, path in tqdm(enumerate(video_paths)):\n",
        "        frames = load_video(os.path.join(root_dir, path))\n",
        "        print('idx', idx, 'path', path)\n",
        "        if len(frames) < MAX_SEQ_LENGTH:\n",
        "            diff = MAX_SEQ_LENGTH - len(frames)\n",
        "            # print('frames', len(frames))\n",
        "            # print('diff=', diff)\n",
        "            padding = np.zeros((diff, IMG_SIZE, IMG_SIZE, 3))\n",
        "            # print('padding=', padding.shape)\n",
        "            # print('frames =', frames.shape)\n",
        "            frames = np.concatenate((frames, padding),axis=0)\n",
        "            # print('frames=', frames.shape)\n",
        "        frames = frames[None, ...]\n",
        "        temp_frame_featutes = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
        "        # print('frames', frames.shape)\n",
        "\n",
        "        for i, batch in enumerate(frames):\n",
        "            # print('batch', batch.shape)\n",
        "            video_length = batch.shape[0]\n",
        "            length = min(MAX_SEQ_LENGTH, video_length)\n",
        "            # print('video_length', video_length)\n",
        "            # print('###########')\n",
        "            for j in range(length):\n",
        "                if np.mean(batch[j, :]) > 0.0:\n",
        "                    temp_frame_featutes[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
        "                else:\n",
        "                    temp_frame_featutes[i, j, :] = 0.0\n",
        "\n",
        "        frame_features[idx,] = temp_frame_featutes.squeeze()\n",
        "        # np.save('drive/MyDrive/seqimg_youtube/video_transformers_croped/frame_features'+str(idx)+'.npy', frame_features)\n",
        "        # np.save('drive/MyDrive/seqimg_youtube/video_transformers_croped/labels'+str(idx)+'.npy', labels)\n",
        "    return frame_features, labels"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total videos for training: 1394\n",
            "['angry', 'happy', 'neutral', 'relax', 'sad']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EnRqeXKIvY0"
      },
      "source": [
        "# np.save('frame_start275.npy', frame_features)\n",
        "# np.save('frame_label275.npy', labels)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwtma2UtqUIu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a83b3d096e624e93abcd22c58099f795",
            "ee1a85d3da2e49618e1c19a2e3b994ea",
            "6e1611c6dd524d92a14a180ad041d001",
            "5b1b956b1e83469c8389b9098a1a74fe",
            "62f6045abe1b45d48377b167f54eab56",
            "6462b600804e4ec6b78f2b9fc45bcdcb",
            "5ffa3d8f2c3444e9b3ccfb8606de5902",
            "c620d053128a4f70982aef5e18fd697a"
          ]
        },
        "outputId": "5635c283-e44f-4b84-a402-935b7f42fe85"
      },
      "source": [
        "# !wget -q https://git.io/JZmf4 -O top5_data_prepared.tar.gz\n",
        "# !tar xf top5_data_prepared.tar.gz\n",
        "\n",
        "# A = np.load('drive/MyDrive/AIHealthcare/AIcare_Phrase1/data/season2/file_v1/csv_frame/trainv1/videos/video_transformers_croped/labels343.npy')\n",
        "# A[343]\n",
        "# ls 'drive/MyDrive/AIHealthcare/AIcare_Phrase1/data/season2/file_v1/csv_frame/trainv1/videos/video_transformers_croped/frame_features342.npy'\n",
        "# A = np.load('drive/MyDrive/AIHealthcare/AIcare_Phrase1/data/season2/file_v1/csv_frame/trainv1/videos/video_transformers_croped/frame_features342.npy')\n",
        "# A[343]\n",
        "# video_paths = train_df[\"video_name\"].values[343:].tolist()\n",
        "# for idx, path in tqdm(enumerate(video_paths)):\n",
        "#   print(idx)\n",
        "# for i in range(1194):\n",
        "#   A = np.load('drive/MyDrive/AIHealthcare/AIcare_Phrase1/data/season2/file_v1/csv_frame/trainv1/videos/video_transformers_croped/frame_features'+str(i)+'.npy')\n",
        "#   print('i=' , i, ' value = ' , A[i-1].sum())\n",
        "\n",
        "# np.save('drive/MyDrive/AIHealthcare/AIcare_Phrase1/data/season2/file_v1/csv_frame/trainv1/videos/video_transformers_croped/test_data.npy', frame_features)\n",
        "# np.save('drive/MyDrive/AIHealthcare/AIcare_Phrase1/data/season2/file_v1/csv_frame/trainv1/videos/video_transformers_croped/test_labels.npy', labels)\n",
        "frame_features, labels = prepare_all_videos(train_df, 'drive/MyDrive/seqimg_youtube/unzip/cropped_v1') #343 , 937   \n",
        "# ls 'drive/MyDrive/AIHealthcare/AIcare_Phrase1/data/season2/file_v1/csv_frame/trainv1/videos/video_transformers_croped/'\n",
        "# ls 'drive/MyDrive/AIHealthcare/AIcare_Phrase1/data/season2/file_v1/csv_frame/trainv1/videos/video_transformers_croped/labels_total.npy'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:53: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a83b3d096e624e93abcd22c58099f795",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "idx 0 path face2_01_0_59_3296_neutral.mp4\n",
            "idx 1 path face2_01_1_3356_4075_relax.mp4\n",
            "idx 2 path face2_01_2_4135_5034_neutral.mp4\n",
            "idx 3 path face2_01_3_5514_5754_stress.mp4\n",
            "idx 4 path face2_01_4_5814_6053_stress.mp4\n",
            "idx 5 path face2_01_5_6053_6233_happy.mp4\n",
            "idx 6 path face2_01_6_6293_7012_neutral.mp4\n",
            "idx 7 path face2_01_7_7072_7252_stress.mp4\n",
            "idx 8 path face2_01_8_7312_7672_neutral.mp4\n",
            "idx 9 path face2_01_9_7732_8031_stress.mp4\n",
            "idx 10 path face2_01_10_8091_8451_happy.mp4\n",
            "idx 11 path face2_01_11_8451_8871_happy.mp4\n",
            "idx 12 path face2_01_12_9050_9230_happy.mp4\n",
            "idx 13 path face2_01_13_9410_9650_happy.mp4\n",
            "idx 14 path face2_01_14_9710_10129_neutral.mp4\n",
            "idx 15 path face2_01_15_11448_11568_stress.mp4\n",
            "idx 16 path face2_01_16_11628_11928_neutral.mp4\n",
            "idx 17 path face2_01_17_10909_12647_stress.mp4\n",
            "idx 18 path face2_01_18_12707_12887_sad.mp4\n",
            "idx 19 path face2_01_19_12947_14565_sad.mp4\n",
            "idx 20 path face2_01_20_14625_14685_sad.mp4\n",
            "idx 21 path face2_01_21_14745_14925_angry.mp4\n",
            "idx 22 path face2_01_22_14445_14505_stress.mp4\n",
            "idx 23 path face2_01_23_15644_15884_neutral.mp4\n",
            "idx 24 path face2_01_24_15944_16003_happy.mp4\n",
            "idx 25 path face2_01_25_16063_16423_stress.mp4\n",
            "idx 26 path face2_01_26_17802_18221_neutral.mp4\n",
            "idx 27 path face2_01_27_18281_18341_happy.mp4\n",
            "idx 28 path face2_01_28_18401_18461_neutral.mp4\n",
            "idx 29 path face2_01_29_19000_19120_stress.mp4\n",
            "idx 30 path face2_01_30_18101_19360_happy.mp4\n",
            "idx 31 path face2_01_31_19420_19660_stress.mp4\n",
            "idx 32 path face2_01_32_20139_20439_neutral.mp4\n",
            "idx 33 path face2_01_33_20439_20559_stress.mp4\n",
            "idx 34 path face2_01_34_20859_21098_happy.mp4\n",
            "idx 35 path face2_01_35_21158_21218_happy.mp4\n",
            "idx 36 path face2_01_36_21278_21518_happy.mp4\n",
            "idx 37 path face2_01_37_22057_22117_happy.mp4\n",
            "idx 38 path face2_01_38_21638_22357_stress.mp4\n",
            "idx 39 path face2_01_39_22597_22657_happy.mp4\n",
            "idx 40 path face2_01_40_22897_23136_stress.mp4\n",
            "idx 41 path face2_01_41_23196_23616_relax.mp4\n",
            "idx 42 path face2_01_42_23676_23796_stress.mp4\n",
            "idx 43 path face2_01_43_23856_23916_relax.mp4\n",
            "idx 44 path face2_01_44_21818_24155_happy.mp4\n",
            "idx 45 path face2_01_45_24215_24335_stress.mp4\n",
            "idx 46 path face2_01_46_24815_24875_stress.mp4\n",
            "idx 47 path face2_01_47_24935_25054_relax.mp4\n",
            "idx 48 path face2_01_48_25114_25234_stress.mp4\n",
            "idx 49 path face2_01_49_26193_26793_stress.mp4\n",
            "idx 50 path face2_01_50_27932_28291_stress.mp4\n",
            "idx 51 path face2_01_51_28351_28831_neutral.mp4\n",
            "idx 52 path face2_01_52_29130_29430_relax.mp4\n",
            "idx 53 path face2_01_53_29490_29610_happy.mp4\n",
            "idx 54 path face2_01_54_29670_30629_stress.mp4\n",
            "idx 55 path face2_01_55_30629_30749_happy.mp4\n",
            "idx 56 path face2_01_56_30809_31468_relax.mp4\n",
            "idx 57 path face2_01_57_31528_31948_happy.mp4\n",
            "idx 58 path face2_01_58_32187_32427_happy.mp4\n",
            "idx 59 path face2_01_59_32667_33146_relax.mp4\n",
            "idx 60 path face2_01_60_33206_33446_stress.mp4\n",
            "idx 61 path face2_01_61_33746_34345_stress.mp4\n",
            "idx 62 path face2_01_62_34405_34525_stress.mp4\n",
            "idx 63 path face2_01_63_34585_34825_happy.mp4\n",
            "idx 64 path face2_01_64_35124_35244_happy.mp4\n",
            "idx 65 path face2_01_65_35304_35544_relax.mp4\n",
            "idx 66 path face2_01_66_35604_36323_stress.mp4\n",
            "idx 67 path face2_01_67_36383_36623_happy.mp4\n",
            "idx 68 path face2_01_68_36623_37222_relax.mp4\n",
            "idx 69 path face2_01_69_37282_37522_happy.mp4\n",
            "idx 70 path face2_01_70_37582_37822_relax.mp4\n",
            "idx 71 path face2_01_71_38121_39020_neutral.mp4\n",
            "idx 72 path face2_01_72_39020_39800_stress.mp4\n",
            "idx 73 path face2_01_73_40219_40279_stress.mp4\n",
            "idx 74 path face2_01_74_41058_41118_stress.mp4\n",
            "idx 75 path face2_01_75_41178_41538_stress.mp4\n",
            "idx 76 path face2_01_76_41598_43216_relax.mp4\n",
            "idx 77 path face2_01_77_43276_45014_relax.mp4\n",
            "idx 78 path face2_01_78_45314_45494_angry.mp4\n",
            "idx 79 path face2_01_79_46633_47232_neutral.mp4\n",
            "idx 80 path face2_01_80_47592_47652_stress.mp4\n",
            "idx 81 path face2_01_81_47712_48791_neutral.mp4\n",
            "idx 82 path face2_01_82_48851_48911_stress.mp4\n",
            "idx 83 path face2_01_83_48971_51068_stress.mp4\n",
            "idx 84 path face2_01_84_51368_51668_stress.mp4\n",
            "idx 85 path face2_01_85_51728_51848_neutral.mp4\n",
            "idx 86 path face2_01_86_50529_50589_neutral.mp4\n",
            "idx 87 path face2_01_87_52807_53286_stress.mp4\n",
            "idx 88 path face2_01_88_53886_54065_neutral.mp4\n",
            "idx 89 path face2_01_89_54125_54485_stress.mp4\n",
            "idx 90 path face2_01_90_54005_56103_neutral.mp4\n",
            "idx 91 path face2_01_91_56463_56643_stress.mp4\n",
            "idx 92 path face2_01_92_57902_58021_happy.mp4\n",
            "idx 93 path face2_01_93_58381_58501_relax.mp4\n",
            "idx 94 path face2_01_94_57662_59400_neutral.mp4\n",
            "idx 95 path face2_01_95_48671_59520_happy.mp4\n",
            "idx 96 path face2_01_96_59580_59880_neutral.mp4\n",
            "idx 97 path face2_01_97_57782_60119_relax.mp4\n",
            "idx 98 path face2_01_98_60179_60839_stress.mp4\n",
            "idx 99 path face2_01_99_60899_61138_happy.mp4\n",
            "idx 100 path face2_01_100_61618_62097_relax.mp4\n",
            "idx 101 path face2_01_101_62157_63056_relax.mp4\n",
            "idx 102 path face2_01_102_64255_64315_stress.mp4\n",
            "idx 103 path face2_01_103_64375_64795_neutral.mp4\n",
            "idx 104 path face2_01_104_64855_65214_sad.mp4\n",
            "idx 105 path face2_01_105_65274_65994_relax.mp4\n",
            "idx 106 path face2_01_106_65994_66353_neutral.mp4\n",
            "idx 107 path face2_01_107_66593_67192_neutral.mp4\n",
            "idx 108 path face2_01_108_67192_67432_stress.mp4\n",
            "idx 109 path face2_01_109_68511_69590_angry.mp4\n",
            "idx 110 path face2_01_110_68511_68811_happy.mp4\n",
            "idx 111 path face2_01_111_68991_69110_stress.mp4\n",
            "idx 112 path face2_01_112_69290_69950_neutral.mp4\n",
            "idx 113 path face2_01_113_70009_70189_happy.mp4\n",
            "idx 114 path face2_01_114_70189_70309_neutral.mp4\n",
            "idx 115 path face2_01_115_70789_70849_happy.mp4\n",
            "idx 116 path face2_01_116_70909_70969_sad.mp4\n",
            "idx 117 path face2_01_117_71028_71208_happy.mp4\n",
            "idx 118 path face2_01_118_71268_72107_relax.mp4\n",
            "idx 119 path face2_01_119_72167_72347_stress.mp4\n",
            "idx 120 path face2_01_120_72407_72587_happy.mp4\n",
            "idx 121 path face2_01_121_72587_72767_sad.mp4\n",
            "idx 122 path face2_01_122_72827_72947_neutral.mp4\n",
            "idx 123 path face2_01_123_73366_73906_neutral.mp4\n",
            "idx 124 path face2_01_124_73966_74145_neutral.mp4\n",
            "idx 125 path face2_01_125_74205_74625_stress.mp4\n",
            "idx 126 path face2_01_126_75044_75284_stress.mp4\n",
            "idx 127 path face2_01_127_75344_76003_neutral.mp4\n",
            "idx 128 path face2_01_128_76243_76783_neutral.mp4\n",
            "idx 129 path face2_01_129_77262_77562_stress.mp4\n",
            "idx 130 path face2_01_130_77622_78401_neutral.mp4\n",
            "idx 131 path face2_01_131_78461_78701_neutral.mp4\n",
            "idx 132 path face2_01_132_80499_81278_neutral.mp4\n",
            "idx 133 path face2_01_133_82057_82177_neutral.mp4\n",
            "idx 134 path face2_01_134_82177_82777_relax.mp4\n",
            "idx 135 path face2_01_135_83376_83436_stress.mp4\n",
            "idx 136 path face2_01_136_83496_83736_relax.mp4\n",
            "idx 137 path face2_01_137_83796_83976_relax.mp4\n",
            "idx 138 path face2_01_138_83976_84155_stress.mp4\n",
            "idx 139 path face2_01_139_85174_85414_stress.mp4\n",
            "idx 140 path face2_01_140_85894_86853_neutral.mp4\n",
            "idx 141 path face2_01_141_86373_87092_relax.mp4\n",
            "idx 142 path face2_01_142_87152_87632_relax.mp4\n",
            "idx 143 path face2_01_143_87692_88291_sad.mp4\n",
            "idx 144 path face2_01_144_88351_88471_relax.mp4\n",
            "idx 145 path face2_01_145_88531_88771_stress.mp4\n",
            "idx 146 path face2_01_146_88771_89010_stress.mp4\n",
            "idx 147 path face2_01_147_89430_89790_stress.mp4\n",
            "idx 148 path face2_01_148_90149_90209_stress.mp4\n",
            "idx 149 path face2_01_149_90449_90749_relax.mp4\n",
            "idx 150 path face2_01_150_90809_91168_neutral.mp4\n",
            "idx 151 path face2_01_151_92127_92367_happy.mp4\n",
            "idx 152 path face2_02_0_1300_1750_happy.mp4\n",
            "idx 153 path face2_02_1_1800_1900_relax.mp4\n",
            "idx 154 path face2_02_2_2150_2650_neutral.mp4\n",
            "idx 155 path face2_02_3_2700_2900_happy.mp4\n",
            "idx 156 path face2_02_4_2950_3150_happy.mp4\n",
            "idx 157 path face2_02_5_3950_4100_happy.mp4\n",
            "idx 158 path face2_02_6_4150_4550_stress.mp4\n",
            "idx 159 path face2_02_7_5200_5450_neutral.mp4\n",
            "idx 160 path face2_02_8_5950_6000_happy.mp4\n",
            "idx 161 path face2_02_9_6150_6400_relax.mp4\n",
            "idx 162 path face2_02_10_6700_6750_stress.mp4\n",
            "idx 163 path face2_02_11_6850_6900_happy.mp4\n",
            "idx 164 path face2_02_12_6950_7050_happy.mp4\n",
            "idx 165 path face2_02_13_7350_7800_relax.mp4\n",
            "idx 166 path face2_02_14_7950_8150_happy.mp4\n",
            "idx 167 path face2_02_15_8350_8550_neutral.mp4\n",
            "idx 168 path face2_02_16_8750_8950_neutral.mp4\n",
            "idx 169 path face2_02_17_9150_9350_happy.mp4\n",
            "idx 170 path face2_02_18_9700_10050_neutral.mp4\n",
            "idx 171 path face2_02_19_10200_10400_happy.mp4\n",
            "idx 172 path face2_02_20_10450_10750_stress.mp4\n",
            "idx 173 path face2_02_21_10800_11100_neutral.mp4\n",
            "idx 174 path face2_02_22_11300_11550_neutral.mp4\n",
            "idx 175 path face2_02_23_11550_11900_happy.mp4\n",
            "idx 176 path face2_02_24_11950_12000_stress.mp4\n",
            "idx 177 path face2_02_25_13150_13250_neutral.mp4\n",
            "idx 178 path face2_02_26_13450_13550_relax.mp4\n",
            "idx 179 path face2_02_27_13550_14150_stress.mp4\n",
            "idx 180 path face2_02_28_14800_15150_happy.mp4\n",
            "idx 181 path face2_02_29_15200_15700_neutral.mp4\n",
            "idx 182 path face2_02_30_15850_16350_relax.mp4\n",
            "idx 183 path face2_02_31_16550_17850_neutral.mp4\n",
            "idx 184 path face2_02_32_17900_18050_happy.mp4\n",
            "idx 185 path face2_02_33_18550_19100_happy.mp4\n",
            "idx 186 path face2_02_34_19150_20250_relax.mp4\n",
            "idx 187 path face2_02_35_20250_20450_happy.mp4\n",
            "idx 188 path face2_02_36_18250_20800_relax.mp4\n",
            "idx 189 path face2_02_37_20850_21050_relax.mp4\n",
            "idx 190 path face2_02_38_21100_21250_relax.mp4\n",
            "idx 191 path face2_02_39_21300_21750_neutral.mp4\n",
            "idx 192 path face2_02_40_21750_21850_happy.mp4\n",
            "idx 193 path face2_02_41_22100_22600_relax.mp4\n",
            "idx 194 path face2_02_42_22800_23200_happy.mp4\n",
            "idx 195 path face2_02_43_23200_23250_happy.mp4\n",
            "idx 196 path face2_02_44_23300_23900_happy.mp4\n",
            "idx 197 path face2_02_45_23950_24550_relax.mp4\n",
            "idx 198 path face2_02_46_24600_24650_happy.mp4\n",
            "idx 199 path face2_02_47_24700_25100_neutral.mp4\n",
            "idx 200 path face2_02_48_25150_25450_stress.mp4\n",
            "idx 201 path face2_02_49_24150_26050_stress.mp4\n",
            "idx 202 path face2_02_50_26200_26400_happy.mp4\n",
            "idx 203 path face2_02_51_26450_26650_neutral.mp4\n",
            "idx 204 path face2_02_52_27050_27150_happy.mp4\n",
            "idx 205 path face2_02_53_27200_28150_relax.mp4\n",
            "idx 206 path face2_02_54_27150_28700_happy.mp4\n",
            "idx 207 path face2_02_55_28750_28950_relax.mp4\n",
            "idx 208 path face2_02_56_27200_29100_happy.mp4\n",
            "idx 209 path face2_02_57_29650_29750_happy.mp4\n",
            "idx 210 path face2_02_58_30050_30200_neutral.mp4\n",
            "idx 211 path face2_02_59_30400_31050_neutral.mp4\n",
            "idx 212 path face2_02_60_31650_32050_happy.mp4\n",
            "idx 213 path face2_02_61_32400_32750_stress.mp4\n",
            "idx 214 path face2_02_62_32800_32850_happy.mp4\n",
            "idx 215 path face2_02_63_33300_33650_angry.mp4\n",
            "idx 216 path face2_02_64_33700_33750_happy.mp4\n",
            "idx 217 path face2_02_65_34050_34250_relax.mp4\n",
            "idx 218 path face2_02_66_34450_35050_relax.mp4\n",
            "idx 219 path face2_02_67_35050_35150_happy.mp4\n",
            "idx 220 path face2_02_68_35300_35750_neutral.mp4\n",
            "idx 221 path face2_02_69_35950_36400_happy.mp4\n",
            "idx 222 path face2_02_70_36450_36600_relax.mp4\n",
            "idx 223 path face2_02_71_37050_37200_happy.mp4\n",
            "idx 224 path face2_02_72_34550_35450_happy.mp4\n",
            "idx 225 path face2_02_73_33250_35600_neutral.mp4\n",
            "idx 226 path face5_01_0_50_750_happy.mp4\n",
            "idx 227 path face5_01_1_800_950_relax.mp4\n",
            "idx 228 path face5_01_2_100_1450_happy.mp4\n",
            "idx 229 path face5_01_3_150_2250_relax.mp4\n",
            "idx 230 path face5_01_4_2300_2400_relax.mp4\n",
            "idx 231 path face5_01_5_2450_4100_relax.mp4\n",
            "idx 232 path face5_01_6_4150_4300_relax.mp4\n",
            "idx 233 path face5_01_7_4350_4650_happy.mp4\n",
            "idx 234 path face5_01_8_4700_4900_relax.mp4\n",
            "idx 235 path face5_01_9_4950_5050_relax.mp4\n",
            "idx 236 path face5_01_10_5050_5200_happy.mp4\n",
            "idx 237 path face5_01_11_5250_5400_relax.mp4\n",
            "idx 238 path face5_01_12_5450_5800_stress.mp4\n",
            "idx 239 path face5_01_13_5850_5900_happy.mp4\n",
            "idx 240 path face5_01_14_6000_6150_stress.mp4\n",
            "idx 241 path face5_01_15_6200_6250_relax.mp4\n",
            "idx 242 path face5_01_16_6300_6350_relax.mp4\n",
            "idx 243 path face5_01_17_6400_6750_relax.mp4\n",
            "idx 244 path face5_01_18_6800_7200_stress.mp4\n",
            "idx 245 path face5_01_19_7250_7550_happy.mp4\n",
            "idx 246 path face5_01_20_7550_7800_relax.mp4\n",
            "idx 247 path face5_01_21_7850_8050_sad.mp4\n",
            "idx 248 path face5_01_22_8100_8300_neutral.mp4\n",
            "idx 249 path face5_01_23_8350_8450_stress.mp4\n",
            "idx 250 path face5_01_24_6250_8550_happy.mp4\n",
            "idx 251 path face5_01_25_8550_8950_sad.mp4\n",
            "idx 252 path face5_01_26_9000_9200_neutral.mp4\n",
            "idx 253 path face5_01_27_9450_9800_happy.mp4\n",
            "idx 254 path face5_01_28_9850_9900_neutral.mp4\n",
            "idx 255 path face5_01_29_9900_9950_happy.mp4\n",
            "idx 256 path face5_01_30_9100_10300_neutral.mp4\n",
            "idx 257 path face5_01_31_10350_10400_happy.mp4\n",
            "idx 258 path face5_01_32_10400_10750_sad.mp4\n",
            "idx 259 path face5_01_33_10800_11050_stress.mp4\n",
            "idx 260 path face5_01_34_11100_11250_stress.mp4\n",
            "idx 261 path face5_01_35_11300_11450_stress.mp4\n",
            "idx 262 path face5_01_36_11700_11950_relax.mp4\n",
            "idx 263 path face5_01_37_12000_12050_angry.mp4\n",
            "idx 264 path face5_01_38_12050_12650_stress.mp4\n",
            "idx 265 path face5_01_39_12700_13150_sad.mp4\n",
            "idx 266 path face5_01_40_13200_13250_stress.mp4\n",
            "idx 267 path face5_01_41_13250_13300_angry.mp4\n",
            "idx 268 path face5_01_42_13350_13450_stress.mp4\n",
            "idx 269 path face5_01_43_12150_13600_neutral.mp4\n",
            "idx 270 path face5_01_44_13650_13750_neutral.mp4\n",
            "idx 271 path face5_01_45_13800_14050_relax.mp4\n",
            "idx 272 path face5_01_46_14100_14350_neutral.mp4\n",
            "idx 273 path face5_01_47_14400_14550_happy.mp4\n",
            "idx 274 path face5_01_48_14600_14750_neutral.mp4\n",
            "idx 275 path face5_01_49_14800_14900_relax.mp4\n",
            "idx 276 path face5_01_50_14950_15100_neutral.mp4\n",
            "idx 277 path face5_01_51_15300_15350_neutral.mp4\n",
            "idx 278 path face5_01_52_15050_15550_stress.mp4\n",
            "idx 279 path face5_01_53_15550_15750_neutral.mp4\n",
            "idx 280 path face5_01_54_15800_15850_neutral.mp4\n",
            "idx 281 path face5_01_55_15850_15950_stress.mp4\n",
            "idx 282 path face5_01_56_15100_16300_stress.mp4\n",
            "idx 283 path face5_01_57_16350_16450_stress.mp4\n",
            "idx 284 path face5_01_58_16750_16800_stress.mp4\n",
            "idx 285 path face5_01_59_16800_16850_stress.mp4\n",
            "idx 286 path face5_01_60_16900_17050_stress.mp4\n",
            "idx 287 path face5_01_61_17050_17100_stress.mp4\n",
            "idx 288 path face5_01_62_17100_17450_stress.mp4\n",
            "idx 289 path face5_01_63_15250_18050_stress.mp4\n",
            "idx 290 path face5_01_64_18200_19600_angry.mp4\n",
            "idx 291 path face5_01_65_19650_19700_relax.mp4\n",
            "idx 292 path face5_01_66_19750_19800_angry.mp4\n",
            "idx 293 path face5_01_67_19800_20650_angry.mp4\n",
            "idx 294 path face5_01_68_20700_21600_happy.mp4\n",
            "idx 295 path face5_01_69_21650_22050_neutral.mp4\n",
            "idx 296 path face5_01_70_22750_22850_sad.mp4\n",
            "idx 297 path face5_01_71_22900_22950_stress.mp4\n",
            "idx 298 path face5_01_72_23050_23100_stress.mp4\n",
            "idx 299 path face5_01_73_23150_23250_relax.mp4\n",
            "idx 300 path face5_01_74_23700_23800_stress.mp4\n",
            "idx 301 path face5_01_75_23850_23900_neutral.mp4\n",
            "idx 302 path face5_01_76_23950_24000_neutral.mp4\n",
            "idx 303 path face5_01_77_24300_24450_neutral.mp4\n",
            "idx 304 path face5_01_78_24050_24550_neutral.mp4\n",
            "idx 305 path face5_01_79_24600_24950_neutral.mp4\n",
            "idx 306 path face5_01_80_24100_25150_stress.mp4\n",
            "idx 307 path face5_01_81_25200_25250_stress.mp4\n",
            "idx 308 path face5_01_82_25450_25600_stress.mp4\n",
            "idx 309 path face5_01_83_25800_25900_angry.mp4\n",
            "idx 310 path face5_01_84_25950_26100_neutral.mp4\n",
            "idx 311 path face5_01_85_26150_26200_stress.mp4\n",
            "idx 312 path face5_01_86_26250_26300_sad.mp4\n",
            "idx 313 path face5_01_87_26350_26550_stress.mp4\n",
            "idx 314 path face5_01_88_26600_26900_relax.mp4\n",
            "idx 315 path face5_01_89_26950_27050_stress.mp4\n",
            "idx 316 path face5_01_90_27100_27450_neutral.mp4\n",
            "idx 317 path face5_01_91_27050_27800_relax.mp4\n",
            "idx 318 path face5_01_92_27850_28550_stress.mp4\n",
            "idx 319 path face5_01_93_28600_28950_neutral.mp4\n",
            "idx 320 path face5_01_94_29100_29150_stress.mp4\n",
            "idx 321 path face5_01_95_29200_29400_stress.mp4\n",
            "idx 322 path face5_01_96_29450_29550_neutral.mp4\n",
            "idx 323 path face5_01_97_29600_29800_relax.mp4\n",
            "idx 324 path face5_01_98_29850_30350_stress.mp4\n",
            "idx 325 path face5_01_99_30400_30550_relax.mp4\n",
            "idx 326 path face5_01_100_30550_30650_stress.mp4\n",
            "idx 327 path face5_01_101_30700_31050_stress.mp4\n",
            "idx 328 path face5_01_102_31100_31150_stress.mp4\n",
            "idx 329 path face5_01_103_31200_31250_neutral.mp4\n",
            "idx 330 path face5_01_104_31250_31300_stress.mp4\n",
            "idx 331 path face5_01_105_31350_31400_stress.mp4\n",
            "idx 332 path face5_01_106_31450_32150_neutral.mp4\n",
            "idx 333 path face5_01_107_32200_32250_angry.mp4\n",
            "idx 334 path face5_01_108_32250_32400_neutral.mp4\n",
            "idx 335 path face5_01_109_30250_32600_stress.mp4\n",
            "idx 336 path face5_01_110_32650_32750_neutral.mp4\n",
            "idx 337 path face5_01_111_32800_32850_stress.mp4\n",
            "idx 338 path face5_01_112_32850_33050_neutral.mp4\n",
            "idx 339 path face5_01_113_33100_33650_happy.mp4\n",
            "idx 340 path face5_01_114_33700_34150_stress.mp4\n",
            "idx 341 path face5_01_115_34200_34800_happy.mp4\n",
            "idx 342 path face5_01_116_34900_34950_relax.mp4\n",
            "idx 343 path face5_01_117_33200_35200_neutral.mp4\n",
            "idx 344 path face5_01_118_35250_35300_relax.mp4\n",
            "idx 345 path face5_01_119_35350_35550_angry.mp4\n",
            "idx 346 path face5_01_120_35550_36000_neutral.mp4\n",
            "idx 347 path face5_01_121_36050_36550_happy.mp4\n",
            "idx 348 path face5_01_122_36550_36650_stress.mp4\n",
            "idx 349 path face5_01_123_36700_37700_neutral.mp4\n",
            "idx 350 path face5_01_124_37750_37800_neutral.mp4\n",
            "idx 351 path face5_01_125_37800_38550_stress.mp4\n",
            "idx 352 path face5_01_126_38550_38650_stress.mp4\n",
            "idx 353 path face5_01_127_38700_39000_stress.mp4\n",
            "idx 354 path face5_01_128_39050_39350_angry.mp4\n",
            "idx 355 path face5_01_129_39050_39700_angry.mp4\n",
            "idx 356 path face5_01_130_39900_39950_angry.mp4\n",
            "idx 357 path face5_01_131_39950_40550_neutral.mp4\n",
            "idx 358 path face5_01_132_40600_40750_angry.mp4\n",
            "idx 359 path face5_01_133_40800_40900_happy.mp4\n",
            "idx 360 path face5_01_134_40950_41350_angry.mp4\n",
            "idx 361 path face5_01_135_39250_42000_sad.mp4\n",
            "idx 362 path face5_01_136_42550_42750_sad.mp4\n",
            "idx 363 path face5_01_137_42800_42950_sad.mp4\n",
            "idx 364 path face5_01_138_42100_43250_angry.mp4\n",
            "idx 365 path face5_01_139_43300_43850_neutral.mp4\n",
            "idx 366 path face5_01_140_43900_43950_stress.mp4\n",
            "idx 367 path face5_01_141_42200_44050_neutral.mp4\n",
            "idx 368 path face5_01_142_44100_44300_angry.mp4\n",
            "idx 369 path face5_01_143_44350_44400_relax.mp4\n",
            "idx 370 path face5_01_144_44450_44650_happy.mp4\n",
            "idx 371 path face5_01_145_44700_44800_stress.mp4\n",
            "idx 372 path face5_01_146_44850_44900_happy.mp4\n",
            "idx 373 path face5_01_147_44950_45150_neutral.mp4\n",
            "idx 374 path face5_01_148_45200_45450_stress.mp4\n",
            "idx 375 path face5_01_149_45050_46200_relax.mp4\n",
            "idx 376 path face5_01_150_46250_46700_neutral.mp4\n",
            "idx 377 path face5_01_151_46750_46950_angry.mp4\n",
            "idx 378 path face5_01_152_45200_47050_relax.mp4\n",
            "idx 379 path face5_01_153_47100_47300_happy.mp4\n",
            "idx 380 path face5_02_0_66240_66360_neutral.mp4\n",
            "idx 381 path face5_02_1_66840_67020_happy.mp4\n",
            "idx 382 path face5_02_2_67620_68520_happy.mp4\n",
            "idx 383 path face5_02_3_68580_68880_neutral.mp4\n",
            "idx 384 path face5_02_4_68940_69120_stress.mp4\n",
            "idx 385 path face5_02_5_69180_69780_neutral.mp4\n",
            "idx 386 path face5_02_6_69960_70080_neutral.mp4\n",
            "idx 387 path face5_02_7_70140_70260_stress.mp4\n",
            "idx 388 path face5_02_8_70260_70560_stress.mp4\n",
            "idx 389 path face5_02_9_70620_70740_happy.mp4\n",
            "idx 390 path face5_02_10_72240_72720_happy.mp4\n",
            "idx 391 path face5_02_11_72840_73020_happy.mp4\n",
            "idx 392 path face5_02_12_73260_73620_happy.mp4\n",
            "idx 393 path face5_02_13_73680_73920_neutral.mp4\n",
            "idx 394 path face5_02_14_73980_74220_stress.mp4\n",
            "idx 395 path face5_02_15_74280_74460_neutral.mp4\n",
            "idx 396 path face5_02_16_74520_74820_stress.mp4\n",
            "idx 397 path face5_02_17_74880_75120_happy.mp4\n",
            "idx 398 path face5_02_18_75180_75360_happy.mp4\n",
            "idx 399 path face5_02_19_75480_76080_happy.mp4\n",
            "idx 400 path face5_02_20_76260_76320_happy.mp4\n",
            "idx 401 path face5_02_21_75900_79860_happy.mp4\n",
            "idx 402 path face5_02_22_79920_80100_happy.mp4\n",
            "idx 403 path face5_02_23_80760_81180_relax.mp4\n",
            "idx 404 path face5_02_24_81360_81660_happy.mp4\n",
            "idx 405 path face5_02_25_81780_81900_happy.mp4\n",
            "idx 406 path face5_02_26_82500_82560_happy.mp4\n",
            "idx 407 path face5_02_27_85500_85620_relax.mp4\n",
            "idx 408 path face5_02_28_85740_85860_relax.mp4\n",
            "idx 409 path face5_02_29_83100_85860_relax.mp4\n",
            "idx 410 path face5_02_30_85920_86280_happy.mp4\n",
            "idx 411 path face5_02_31_86460_86640_happy.mp4\n",
            "idx 412 path face5_02_32_86700_86820_neutral.mp4\n",
            "idx 413 path face5_02_33_86880_87240_neutral.mp4\n",
            "idx 414 path face5_02_34_87300_87420_relax.mp4\n",
            "idx 415 path face5_02_35_87840_88500_relax.mp4\n",
            "idx 416 path face5_02_36_88620_88920_stress.mp4\n",
            "idx 417 path face5_02_37_88980_89820_stress.mp4\n",
            "idx 418 path face5_02_38_91680_91980_stress.mp4\n",
            "idx 419 path face5_02_39_92160_92340_stress.mp4\n",
            "idx 420 path face5_02_40_92340_92820_relax.mp4\n",
            "idx 421 path face5_02_41_92880_92940_stress.mp4\n",
            "idx 422 path face5_02_42_90300_93120_happy.mp4\n",
            "idx 423 path face5_02_43_93180_93780_happy.mp4\n",
            "idx 424 path face5_02_44_94440_94860_angry.mp4\n",
            "idx 425 path face5_02_45_94920_95280_happy.mp4\n",
            "idx 426 path face5_02_46_95340_95820_happy.mp4\n",
            "idx 427 path face5_02_47_95880_96120_neutral.mp4\n",
            "idx 428 path face5_02_48_96180_96780_neutral.mp4\n",
            "idx 429 path face5_02_49_96840_97440_stress.mp4\n",
            "idx 430 path face5_02_50_97560_97620_happy.mp4\n",
            "idx 431 path face5_02_51_100080_100260_stress.mp4\n",
            "idx 432 path face5_02_52_102840_102900_relax.mp4\n",
            "idx 433 path face5_02_53_101040_103380_happy.mp4\n",
            "idx 434 path face5_02_54_104460_104520_neutral.mp4\n",
            "idx 435 path face5_02_55_104640_104700_neutral.mp4\n",
            "idx 436 path face5_02_56_104760_105720_neutral.mp4\n",
            "idx 437 path face5_02_57_106440_106500_neutral.mp4\n",
            "idx 438 path face5_02_58_106680_107040_relax.mp4\n",
            "idx 439 path face5_02_59_107160_107460_neutral.mp4\n",
            "idx 440 path face5_02_60_109080_109320_happy.mp4\n",
            "idx 441 path face5_02_61_109380_109500_happy.mp4\n",
            "idx 442 path face5_02_62_109560_110100_relax.mp4\n",
            "idx 443 path face5_02_63_110160_110760_happy.mp4\n",
            "idx 444 path face5_02_64_110820_110880_neutral.mp4\n",
            "idx 445 path face5_02_65_110940_111300_neutral.mp4\n",
            "idx 446 path face5_02_66_111300_111480_neutral.mp4\n",
            "idx 447 path face5_02_67_111600_111900_neutral.mp4\n",
            "idx 448 path face5_02_68_112080_112140_happy.mp4\n",
            "idx 449 path face5_02_69_111660_112500_happy.mp4\n",
            "idx 450 path face5_02_70_112560_112980_happy.mp4\n",
            "idx 451 path face5_02_71_113580_113640_stress.mp4\n",
            "idx 452 path face5_03_0_12475_12725_stress.mp4\n",
            "idx 453 path face5_03_1_12075_13100_sad.mp4\n",
            "idx 454 path face5_03_2_13425_13475_sad.mp4\n",
            "idx 455 path face5_03_3_13875_13900_stress.mp4\n",
            "idx 456 path face5_03_4_13900_13925_sad.mp4\n",
            "idx 457 path face6_01_0_100_1050_relax.mp4\n",
            "idx 458 path face6_01_1_1075_1100_happy.mp4\n",
            "idx 459 path face6_01_2_1125_1150_happy.mp4\n",
            "idx 460 path face6_01_3_1175_1225_neutral.mp4\n",
            "idx 461 path face6_01_4_125_1275_happy.mp4\n",
            "idx 462 path face6_01_5_1300_1325_happy.mp4\n",
            "idx 463 path face6_01_6_1350_1375_happy.mp4\n",
            "idx 464 path face6_01_7_1400_1425_happy.mp4\n",
            "idx 465 path face6_01_8_1425_1525_happy.mp4\n",
            "idx 466 path face6_01_9_1650_1675_happy.mp4\n",
            "idx 467 path face6_01_10_1700_1775_relax.mp4\n",
            "idx 468 path face6_01_11_1775_1800_neutral.mp4\n",
            "idx 469 path face6_01_12_1825_1850_stress.mp4\n",
            "idx 470 path face6_01_13_1875_1975_neutral.mp4\n",
            "idx 471 path face6_01_14_1550_2475_neutral.mp4\n",
            "idx 472 path face6_01_15_1600_2625_neutral.mp4\n",
            "idx 473 path face6_01_16_2650_2725_happy.mp4\n",
            "idx 474 path face6_01_17_2800_2825_happy.mp4\n",
            "idx 475 path face6_01_18_2850_3050_neutral.mp4\n",
            "idx 476 path face6_01_19_3025_3050_neutral.mp4\n",
            "idx 477 path face6_01_20_3075_3100_neutral.mp4\n",
            "idx 478 path face6_01_21_3125_3175_happy.mp4\n",
            "idx 479 path face6_01_22_3200_3450_stress.mp4\n",
            "idx 480 path face6_01_23_3450_3475_neutral.mp4\n",
            "idx 481 path face6_01_24_3525_3575_neutral.mp4\n",
            "idx 482 path face6_01_25_3600_3625_happy.mp4\n",
            "idx 483 path face6_01_26_3700_3775_happy.mp4\n",
            "idx 484 path face6_01_27_3775_3850_neutral.mp4\n",
            "idx 485 path face6_01_28_3875_4050_stress.mp4\n",
            "idx 486 path face6_01_29_4075_4275_neutral.mp4\n",
            "idx 487 path face6_01_30_4275_4325_stress.mp4\n",
            "idx 488 path face6_01_31_4350_4625_neutral.mp4\n",
            "idx 489 path face6_01_32_4650_4700_stress.mp4\n",
            "idx 490 path face6_01_33_4725_4875_neutral.mp4\n",
            "idx 491 path face6_01_34_4900_4975_relax.mp4\n",
            "idx 492 path face6_01_35_4550_5100_stress.mp4\n",
            "idx 493 path face6_01_36_5125_5150_neutral.mp4\n",
            "idx 494 path face6_01_37_5175_5200_happy.mp4\n",
            "idx 495 path face6_01_38_5275_5450_relax.mp4\n",
            "idx 496 path face6_01_39_5475_5575_sad.mp4\n",
            "idx 497 path face6_01_40_5600_5650_happy.mp4\n",
            "idx 498 path face6_01_41_5675_5700_relax.mp4\n",
            "idx 499 path face6_01_42_5725_5775_happy.mp4\n",
            "idx 500 path face6_01_43_5775_5800_neutral.mp4\n",
            "idx 501 path face6_01_44_5825_6100_relax.mp4\n",
            "idx 502 path face6_01_45_6125_6275_neutral.mp4\n",
            "idx 503 path face6_01_46_6275_6325_relax.mp4\n",
            "idx 504 path face6_01_47_6350_6400_relax.mp4\n",
            "idx 505 path face6_01_48_6425_6450_happy.mp4\n",
            "idx 506 path face6_01_49_6475_6525_neutral.mp4\n",
            "idx 507 path face6_01_50_6525_6550_happy.mp4\n",
            "idx 508 path face6_01_51_6575_6600_angry.mp4\n",
            "idx 509 path face6_01_52_6625_6675_happy.mp4\n",
            "idx 510 path face6_01_53_6775_6850_neutral.mp4\n",
            "idx 511 path face6_01_54_6950_7125_neutral.mp4\n",
            "idx 512 path face6_01_55_7200_7500_neutral.mp4\n",
            "idx 513 path face6_01_56_7525_7550_happy.mp4\n",
            "idx 514 path face6_01_57_7575_7675_stress.mp4\n",
            "idx 515 path face6_01_58_7700_7725_happy.mp4\n",
            "idx 516 path face6_01_59_7825_7900_happy.mp4\n",
            "idx 517 path face6_01_60_7925_8050_neutral.mp4\n",
            "idx 518 path face6_01_61_8075_8100_relax.mp4\n",
            "idx 519 path face6_01_62_8125_8175_angry.mp4\n",
            "idx 520 path face6_01_63_8200_8225_relax.mp4\n",
            "idx 521 path face6_01_64_8225_8275_angry.mp4\n",
            "idx 522 path face6_01_65_8275_8325_happy.mp4\n",
            "idx 523 path face6_01_66_8325_8400_neutral.mp4\n",
            "idx 524 path face6_01_67_8425_8525_stress.mp4\n",
            "idx 525 path face6_01_68_8525_8550_stress.mp4\n",
            "idx 526 path face6_01_69_8575_8600_stress.mp4\n",
            "idx 527 path face6_01_70_8625_8825_stress.mp4\n",
            "idx 528 path face6_01_71_8625_8650_stress.mp4\n",
            "idx 529 path face6_01_72_8900_9050_neutral.mp4\n",
            "idx 530 path face6_01_73_9075_9150_happy.mp4\n",
            "idx 531 path face6_01_74_9175_9300_neutral.mp4\n",
            "idx 532 path face6_01_75_9325_9375_stress.mp4\n",
            "idx 533 path face6_01_76_9400_9425_stress.mp4\n",
            "idx 534 path face6_01_77_9450_9525_stress.mp4\n",
            "idx 535 path face6_01_78_9525_9775_neutral.mp4\n",
            "idx 536 path face6_01_79_9775_9800_happy.mp4\n",
            "idx 537 path face6_01_80_10150_10200_stress.mp4\n",
            "idx 538 path face6_01_81_10225_10275_happy.mp4\n",
            "idx 539 path face6_01_82_10275_10300_relax.mp4\n",
            "idx 540 path face6_01_83_10325_10350_happy.mp4\n",
            "idx 541 path face6_01_84_10425_10450_happy.mp4\n",
            "idx 542 path face6_01_85_10475_10550_relax.mp4\n",
            "idx 543 path face6_01_86_10575_10600_neutral.mp4\n",
            "idx 544 path face6_01_87_10625_10725_happy.mp4\n",
            "idx 545 path face6_01_88_10525_10900_neutral.mp4\n",
            "idx 546 path face6_01_89_10925_11025_relax.mp4\n",
            "idx 547 path face6_01_90_11050_11600_neutral.mp4\n",
            "idx 548 path face6_01_91_11625_11775_relax.mp4\n",
            "idx 549 path face6_01_92_11775_11875_neutral.mp4\n",
            "idx 550 path face6_01_93_12025_12050_happy.mp4\n",
            "idx 551 path face6_01_94_12075_12175_stress.mp4\n",
            "idx 552 path face6_01_95_12200_12275_neutral.mp4\n",
            "idx 553 path face6_01_96_12425_12825_neutral.mp4\n",
            "idx 554 path face6_01_97_12850_12900_sad.mp4\n",
            "idx 555 path face6_01_98_12925_13025_happy.mp4\n",
            "idx 556 path face6_01_99_13050_13075_neutral.mp4\n",
            "idx 557 path face6_01_100_13100_13375_neutral.mp4\n",
            "idx 558 path face6_01_101_13400_13425_neutral.mp4\n",
            "idx 559 path face6_01_102_13450_13775_neutral.mp4\n",
            "idx 560 path face6_01_103_13800_14050_happy.mp4\n",
            "idx 561 path face6_01_104_14125_14150_relax.mp4\n",
            "idx 562 path face6_01_105_14175_14475_neutral.mp4\n",
            "idx 563 path face6_01_106_13600_14600_happy.mp4\n",
            "idx 564 path face6_01_107_14700_14725_happy.mp4\n",
            "idx 565 path face6_02_0_325_350_neutral.mp4\n",
            "idx 566 path face6_02_1_350_450_relax.mp4\n",
            "idx 567 path face6_02_2_475_575_happy.mp4\n",
            "idx 568 path face6_02_3_600_625_happy.mp4\n",
            "idx 569 path face6_02_4_650_675_relax.mp4\n",
            "idx 570 path face6_02_5_675_725_neutral.mp4\n",
            "idx 571 path face6_02_6_75_775_neutral.mp4\n",
            "idx 572 path face6_02_7_800_875_relax.mp4\n",
            "idx 573 path face6_02_8_900_1025_happy.mp4\n",
            "idx 574 path face6_02_9_1025_1075_happy.mp4\n",
            "idx 575 path face6_02_10_1100_1350_relax.mp4\n",
            "idx 576 path face6_02_11_1375_1475_happy.mp4\n",
            "idx 577 path face6_02_12_1500_1675_relax.mp4\n",
            "idx 578 path face6_02_13_1900_1950_happy.mp4\n",
            "idx 579 path face6_02_14_1975_2025_relax.mp4\n",
            "idx 580 path face6_02_15_2050_2075_relax.mp4\n",
            "idx 581 path face6_02_16_2100_2125_neutral.mp4\n",
            "idx 582 path face6_02_17_2150_2175_neutral.mp4\n",
            "idx 583 path face6_02_18_2175_2375_stress.mp4\n",
            "idx 584 path face6_02_19_2400_2425_stress.mp4\n",
            "idx 585 path face6_02_20_2450_2475_stress.mp4\n",
            "idx 586 path face6_02_21_1600_2525_neutral.mp4\n",
            "idx 587 path face6_02_22_2550_2575_happy.mp4\n",
            "idx 588 path face6_02_23_2575_2650_neutral.mp4\n",
            "idx 589 path face6_02_24_2675_2975_happy.mp4\n",
            "idx 590 path face6_02_25_3000_3200_happy.mp4\n",
            "idx 591 path face6_02_26_3200_3225_relax.mp4\n",
            "idx 592 path face6_02_27_3025_3475_neutral.mp4\n",
            "idx 593 path face6_02_28_3050_3625_stress.mp4\n",
            "idx 594 path face6_02_29_3650_3850_neutral.mp4\n",
            "idx 595 path face6_02_30_3875_4025_happy.mp4\n",
            "idx 596 path face6_02_31_4025_4175_stress.mp4\n",
            "idx 597 path face6_02_32_4200_4575_sad.mp4\n",
            "idx 598 path face6_02_33_4725_4850_neutral.mp4\n",
            "idx 599 path face6_02_34_4875_4900_neutral.mp4\n",
            "idx 600 path face6_02_35_4925_5025_relax.mp4\n",
            "idx 601 path face6_02_36_5025_5075_neutral.mp4\n",
            "idx 602 path face6_02_37_5100_5225_happy.mp4\n",
            "idx 603 path face6_02_38_4575_5275_neutral.mp4\n",
            "idx 604 path face6_02_39_5300_5375_stress.mp4\n",
            "idx 605 path face6_02_40_5400_5425_relax.mp4\n",
            "idx 606 path face6_02_41_5425_5475_neutral.mp4\n",
            "idx 607 path face6_02_42_4600_5675_relax.mp4\n",
            "idx 608 path face6_02_43_5700_5775_relax.mp4\n",
            "idx 609 path face6_02_44_5775_5875_sad.mp4\n",
            "idx 610 path face6_02_45_5950_6025_relax.mp4\n",
            "idx 611 path face6_02_46_6275_6400_happy.mp4\n",
            "idx 612 path face6_02_47_6450_6525_stress.mp4\n",
            "idx 613 path face6_02_48_6550_6600_angry.mp4\n",
            "idx 614 path face6_02_49_6625_6650_neutral.mp4\n",
            "idx 615 path face6_02_50_6650_6800_sad.mp4\n",
            "idx 616 path face6_02_51_6825_6850_happy.mp4\n",
            "idx 617 path face6_02_52_6850_6925_happy.mp4\n",
            "idx 618 path face6_02_53_6950_7075_happy.mp4\n",
            "idx 619 path face6_02_54_7100_7275_neutral.mp4\n",
            "idx 620 path face6_02_55_7300_7325_stress.mp4\n",
            "idx 621 path face6_02_56_7350_7375_stress.mp4\n",
            "idx 622 path face6_02_57_7400_7425_neutral.mp4\n",
            "idx 623 path face6_02_58_7425_7575_neutral.mp4\n",
            "idx 624 path face6_02_59_7600_7650_relax.mp4\n",
            "idx 625 path face6_02_60_7675_7800_stress.mp4\n",
            "idx 626 path face6_02_61_7825_8025_relax.mp4\n",
            "idx 627 path face6_02_62_8100_8150_neutral.mp4\n",
            "idx 628 path face6_02_63_8175_8275_happy.mp4\n",
            "idx 629 path face6_02_64_8300_8375_stress.mp4\n",
            "idx 630 path face6_02_65_8400_8450_neutral.mp4\n",
            "idx 631 path face6_02_66_8475_8550_stress.mp4\n",
            "idx 632 path face6_02_67_8575_8700_relax.mp4\n",
            "idx 633 path face6_02_68_8725_8800_stress.mp4\n",
            "idx 634 path face6_02_69_8825_8850_stress.mp4\n",
            "idx 635 path face6_02_70_8850_8875_neutral.mp4\n",
            "idx 636 path face6_02_71_8875_8950_relax.mp4\n",
            "idx 637 path face6_02_72_8975_9050_neutral.mp4\n",
            "idx 638 path face6_02_73_9075_9175_happy.mp4\n",
            "idx 639 path face6_02_74_9175_9200_happy.mp4\n",
            "idx 640 path face6_02_75_9350_9425_stress.mp4\n",
            "idx 641 path face6_02_76_9450_9700_sad.mp4\n",
            "idx 642 path face6_02_77_9725_9825_neutral.mp4\n",
            "idx 643 path face6_02_78_9850_10025_neutral.mp4\n",
            "idx 644 path face6_02_79_10050_10100_neutral.mp4\n",
            "idx 645 path face6_02_80_10125_10175_stress.mp4\n",
            "idx 646 path face6_02_81_10200_10275_happy.mp4\n",
            "idx 647 path face6_02_82_10275_10325_happy.mp4\n",
            "idx 648 path face6_02_83_10350_10400_happy.mp4\n",
            "idx 649 path face6_02_84_10425_10700_neutral.mp4\n",
            "idx 650 path face6_02_85_10725_10775_relax.mp4\n",
            "idx 651 path face6_02_86_10775_10875_relax.mp4\n",
            "idx 652 path face6_02_87_10900_10925_neutral.mp4\n",
            "idx 653 path face6_02_88_10950_10975_relax.mp4\n",
            "idx 654 path face6_02_89_10975_11025_happy.mp4\n",
            "idx 655 path face6_02_90_11025_11050_relax.mp4\n",
            "idx 656 path face6_02_91_11050_11075_relax.mp4\n",
            "idx 657 path face6_02_92_11100_11150_relax.mp4\n",
            "idx 658 path face6_02_93_11175_11275_neutral.mp4\n",
            "idx 659 path face6_02_94_11300_11325_relax.mp4\n",
            "idx 660 path face6_02_95_11350_11450_relax.mp4\n",
            "idx 661 path face6_02_96_11475_11550_happy.mp4\n",
            "idx 662 path face6_02_97_11575_11625_relax.mp4\n",
            "idx 663 path face6_02_98_11650_11700_neutral.mp4\n",
            "idx 664 path face6_02_99_11725_11775_relax.mp4\n",
            "idx 665 path face6_02_100_10625_11775_neutral.mp4\n",
            "idx 666 path face6_02_101_11775_11800_neutral.mp4\n",
            "idx 667 path face6_02_102_11825_11850_stress.mp4\n",
            "idx 668 path face6_02_103_11850_11950_happy.mp4\n",
            "idx 669 path face6_02_104_12075_12150_relax.mp4\n",
            "idx 670 path face6_02_105_12175_12525_relax.mp4\n",
            "idx 671 path face6_02_106_12550_12575_relax.mp4\n",
            "idx 672 path face6_02_107_12575_12725_neutral.mp4\n",
            "idx 673 path face6_02_108_12075_12900_neutral.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiuFJLbHIou0"
      },
      "source": [
        "np.save('drive/MyDrive/seqimg_youtube/frame_features.npy', frame_features)\n",
        "np.save('drive/MyDrive/seqimg_youtube/labels.npy', labels)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek9dhmsTUsF9"
      },
      "source": [
        "# A = np.load('drive/MyDrive/AIHealthcare/AIcare_Phrase1/data/season2/file_v1/csv_frame/trainv1/videos/video_transformers_croped/frame_features342.npy')\n",
        "# B = np.load('drive/MyDrive/AIHealthcare/AIcare_Phrase1/data/season2/file_v1/csv_frame/trainv1/videos/video_transformers_croped/frame_features936.npy')\n",
        "# C = np.load('drive/MyDrive/AIHealthcare/AIcare_Phrase1/data/season2/file_v1/csv_frame/trainv1/videos/video_transformers_croped/frame_features1193.npy')\n",
        "\n",
        "# X1_new = A[:343]\n",
        "# # print(A[342])\n",
        "# X2_new = B[343:937]\n",
        "# # print(B[936])\n",
        "# X3_new = C[937:1194]\n",
        "# # print(C[1193])\n",
        "\n",
        "# print('total', X1_new.shape[0]+X2_new.shape[0]+X3_new.shape[0])\n",
        "# print('X1_new', X1_new.shape)\n",
        "# print('X2_new', X2_new.shape)\n",
        "# print('X3_new', X3_new.shape)\n",
        "# Xtotal = np.concatenate((X1_new, X2_new, X3_new), axis=0)\n",
        "\n",
        "# labelss = np.load('drive/MyDrive/AIHealthcare/AIcare_Phrase1/data/season2/file_v1/csv_frame/trainv1/videos/video_transformers_croped/test_labels0.npy')\n",
        "# np.save('drive/MyDrive/AIHealthcare/AIcare_Phrase1/data/season2/file_v1/csv_frame/trainv1/videos/video_transformers_croped/labels_total.npy', labelss)\n",
        "# print('Xtotal', labelss.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyiaO1qEzeY3",
        "outputId": "c8cf6e67-6ef5-4d07-ae71-39f750ff650b"
      },
      "source": [
        "train_data  = np.load(\"drive/MyDrive/AIHealthcare/AIcare_Phrase1/data/season2/file_v1/csv_frame/trainv1/videos/video_transformers_croped/frame_features_Xtotal.npy\")\n",
        "train_labels = np.load(\"drive/MyDrive/AIHealthcare/AIcare_Phrase1/data/season2/file_v1/csv_frame/trainv1/videos/video_transformers_croped/labels_total.npy\")\n",
        "# test_data, test_labels = np.load('/content/test_data.npy'), np.load('/content/test_labels.npy')\n",
        "print(f\"Frame features in train set: {train_data.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frame features in train set: (1194, 20, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aC-eatUHzeY4"
      },
      "source": [
        "## Building the Transformer-based model\n",
        "\n",
        "We will be building on top of the code shared in\n",
        "[this book chapter](https://livebook.manning.com/book/deep-learning-with-python-second-edition/chapter-11) of\n",
        "[Deep Learning with Python (Second ed.)](https://www.manning.com/books/deep-learning-with-python)\n",
        "by François Chollet.\n",
        "\n",
        "First, self-attention layers that form the basic blocks of a Transformer are\n",
        "order-agnostic. Since videos are ordered sequences of frames, we need our\n",
        "Transformer model to take into account order information.\n",
        "We do this via **positional encoding**.\n",
        "We simply embed the positions of the frames present inside videos with an\n",
        "[`Embedding` layer](https://keras.io/api/layers/core_layers/embedding). We then\n",
        "add these positional embeddings to the precomputed CNN feature maps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNyViAI5zeY4"
      },
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # The inputs are of shape: `(batch_size, frames, num_features)`\n",
        "        length = tf.shape(inputs)[1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return inputs + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        mask = tf.reduce_any(tf.cast(inputs, \"bool\"), axis=-1)\n",
        "        return mask\n",
        "\n",
        "# Now, we can create a subclassed layer for the Transformer.\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim, dropout=0.3\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=tf.nn.gelu), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "\n",
        "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "## Utility functions for training\n",
        "def get_compiled_model():\n",
        "    sequence_length = MAX_SEQ_LENGTH\n",
        "    embed_dim = NUM_FEATURES\n",
        "    dense_dim = 4\n",
        "    num_heads = 1\n",
        "    classes = len(label_processor.get_vocabulary())\n",
        "    inputs = keras.Input(shape=(None, None))\n",
        "    x = PositionalEmbedding(sequence_length, embed_dim, name=\"frame_position_embedding\")(inputs)\n",
        "    x = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"transformer_layer\")(x)\n",
        "    x = layers.GlobalMaxPooling1D()(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(classes, activation=\"softmax\")(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "def run_experiment():\n",
        "    filepath = \"tmp1/video_classifier\"\n",
        "    checkpoint = keras.callbacks.ModelCheckpoint(filepath, save_weights_only=True, save_best_only=False, verbose=1)\n",
        "    model = get_compiled_model()\n",
        "    history = model.fit(train_data,train_labels,validation_split=0.15,epochs=30,callbacks=[checkpoint],)\n",
        "    model.load_weights(filepath)\n",
        "    _, accuracy = model.evaluate(test_data, test_labels)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rs6tBXFGzeY6"
      },
      "source": [
        "## Model training and inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKubruVtzeY6",
        "outputId": "94745e38-7fb9-4989-92c9-460857b675c0"
      },
      "source": [
        "# trained_model = run_experiment()\n",
        "\n",
        "num_folds = 10\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "fold_no = 1\n",
        "\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "for train, test in kfold.split(train_data, train_labels):\n",
        "    model = get_compiled_model()\n",
        "    history = model.fit(train_data[train], train_labels[train],epochs=100)\n",
        "    _, accuracy = model.evaluate(train_data[test], train_labels[test])\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    acc_per_fold.append(round(accuracy * 100, 2))\n",
        "    print(f'Training for fold {fold_no} ...')\n",
        "    fold_no = fold_no + 1\n",
        "\n",
        "print('mean = ', np.mean(acc_per_fold))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 5s 12ms/step - loss: 3.4228 - accuracy: 0.2458\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.1006 - accuracy: 0.2598\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.9251 - accuracy: 0.2663\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.8836 - accuracy: 0.2477\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.7703 - accuracy: 0.2747\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.6577 - accuracy: 0.2868\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.5825 - accuracy: 0.2924\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.4730 - accuracy: 0.3501\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.4241 - accuracy: 0.3641\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.4226 - accuracy: 0.4004\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.4345 - accuracy: 0.4022\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.3830 - accuracy: 0.4088\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.3392 - accuracy: 0.4292\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.2921 - accuracy: 0.4385\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.2616 - accuracy: 0.4655\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.2411 - accuracy: 0.4870\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.2515 - accuracy: 0.4842\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.2160 - accuracy: 0.5056\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.2616 - accuracy: 0.4721\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.1671 - accuracy: 0.5028\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.1526 - accuracy: 0.5335\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.1177 - accuracy: 0.5298\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0998 - accuracy: 0.5503\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.1474 - accuracy: 0.5298\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.0752 - accuracy: 0.5391\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0010 - accuracy: 0.5940\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0059 - accuracy: 0.5717\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0346 - accuracy: 0.5726\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9723 - accuracy: 0.5940\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9320 - accuracy: 0.6248\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8648 - accuracy: 0.6462\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.8821 - accuracy: 0.6490\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8288 - accuracy: 0.6723\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.7810 - accuracy: 0.6853\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.8111 - accuracy: 0.6788\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7531 - accuracy: 0.7160\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.7152 - accuracy: 0.7216\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7247 - accuracy: 0.7169\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.7290 - accuracy: 0.7253\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7160 - accuracy: 0.7309\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5894 - accuracy: 0.7728\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7353 - accuracy: 0.7104\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6384 - accuracy: 0.7523\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6687 - accuracy: 0.7337\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.5723 - accuracy: 0.7793\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5587 - accuracy: 0.7831\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.5425 - accuracy: 0.7942\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5672 - accuracy: 0.7775\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6699 - accuracy: 0.7505\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.6147 - accuracy: 0.7765\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6153 - accuracy: 0.7672\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.4642 - accuracy: 0.8240\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.4646 - accuracy: 0.8287\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4794 - accuracy: 0.8110\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.3624 - accuracy: 0.8641\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3883 - accuracy: 0.8631\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.4294 - accuracy: 0.8445\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.3536 - accuracy: 0.8799\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3795 - accuracy: 0.8575\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4445 - accuracy: 0.8408\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4494 - accuracy: 0.8343\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3545 - accuracy: 0.8706\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.3785 - accuracy: 0.8706\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5183 - accuracy: 0.8054\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.4929 - accuracy: 0.8203\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3050 - accuracy: 0.8939\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2735 - accuracy: 0.8985\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2453 - accuracy: 0.9153\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2843 - accuracy: 0.8920\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2608 - accuracy: 0.9097\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3289 - accuracy: 0.8827\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2871 - accuracy: 0.8920\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2802 - accuracy: 0.8966\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2832 - accuracy: 0.8957\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2654 - accuracy: 0.9069\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2795 - accuracy: 0.8901\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.3083 - accuracy: 0.8855\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2656 - accuracy: 0.9032\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2697 - accuracy: 0.9004\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.3127 - accuracy: 0.8939\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2352 - accuracy: 0.9199\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2715 - accuracy: 0.8966\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.3181 - accuracy: 0.8845\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2333 - accuracy: 0.9106\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2431 - accuracy: 0.9115\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2619 - accuracy: 0.9013\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1631 - accuracy: 0.9367\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1660 - accuracy: 0.9413\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1516 - accuracy: 0.9460\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1918 - accuracy: 0.9320\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2030 - accuracy: 0.9320\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2470 - accuracy: 0.9153\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1959 - accuracy: 0.9320\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1908 - accuracy: 0.9348\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1325 - accuracy: 0.9497\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2007 - accuracy: 0.9255\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1960 - accuracy: 0.9236\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1669 - accuracy: 0.9441\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1958 - accuracy: 0.9348\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2180 - accuracy: 0.9227\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 6.4389 - accuracy: 0.2583\n",
            "Test accuracy: 25.83%\n",
            "Training for fold 1 ...\n",
            "Epoch 1/100\n",
            "34/34 [==============================] - 2s 12ms/step - loss: 4.0349 - accuracy: 0.2328\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 2.1764 - accuracy: 0.2644\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.9854 - accuracy: 0.2765\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.8157 - accuracy: 0.2765\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.7839 - accuracy: 0.2644\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.6666 - accuracy: 0.2942\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.6069 - accuracy: 0.3119\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.6136 - accuracy: 0.2952\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.5474 - accuracy: 0.3212\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.5233 - accuracy: 0.3212\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.5213 - accuracy: 0.3231\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.4848 - accuracy: 0.3352\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.4599 - accuracy: 0.3538\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.4541 - accuracy: 0.3603\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.4497 - accuracy: 0.3566\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.4431 - accuracy: 0.3752\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.3828 - accuracy: 0.3864\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.3955 - accuracy: 0.3696\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.3526 - accuracy: 0.4041\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.3921 - accuracy: 0.3873\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.3162 - accuracy: 0.4292\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.2979 - accuracy: 0.4302\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.2540 - accuracy: 0.4646\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.2421 - accuracy: 0.4777\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.2220 - accuracy: 0.4795\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.2618 - accuracy: 0.4609\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.2181 - accuracy: 0.4637\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.1978 - accuracy: 0.4953\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.1639 - accuracy: 0.4795\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.1398 - accuracy: 0.5177\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0954 - accuracy: 0.5400\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.0991 - accuracy: 0.5493\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.1728 - accuracy: 0.4953\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.1888 - accuracy: 0.4888\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.2158 - accuracy: 0.4842\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.2079 - accuracy: 0.4758\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.1879 - accuracy: 0.4814\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.1593 - accuracy: 0.5270\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.1666 - accuracy: 0.4963\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.1594 - accuracy: 0.4907\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.1512 - accuracy: 0.5074\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.1006 - accuracy: 0.5289\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0907 - accuracy: 0.5233\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.0761 - accuracy: 0.5428\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0835 - accuracy: 0.5382\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.9965 - accuracy: 0.5875\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.1012 - accuracy: 0.5410\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0579 - accuracy: 0.5596\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.0122 - accuracy: 0.5838\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.9239 - accuracy: 0.6117\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.9922 - accuracy: 0.5754\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.9560 - accuracy: 0.5819\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9770 - accuracy: 0.5912\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0063 - accuracy: 0.5885\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9397 - accuracy: 0.6173\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.8866 - accuracy: 0.6257\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8691 - accuracy: 0.6434\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8310 - accuracy: 0.6480\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.8972 - accuracy: 0.6406\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7904 - accuracy: 0.6872\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.8170 - accuracy: 0.6853\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.8579 - accuracy: 0.6583\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.8189 - accuracy: 0.6629\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8105 - accuracy: 0.6657\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9293 - accuracy: 0.6257\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7890 - accuracy: 0.6788\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7458 - accuracy: 0.6881\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8306 - accuracy: 0.6536\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7437 - accuracy: 0.7002\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7797 - accuracy: 0.6778\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7868 - accuracy: 0.6639\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.7640 - accuracy: 0.6937\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7077 - accuracy: 0.7197\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6555 - accuracy: 0.7384\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6733 - accuracy: 0.7384\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.6858 - accuracy: 0.7132\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6290 - accuracy: 0.7505\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6859 - accuracy: 0.7272\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6926 - accuracy: 0.7272\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6660 - accuracy: 0.7346\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.7926 - accuracy: 0.6741\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.6217 - accuracy: 0.7570\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6129 - accuracy: 0.7598\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.5658 - accuracy: 0.7793\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6785 - accuracy: 0.7263\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.6078 - accuracy: 0.7505\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.6073 - accuracy: 0.7551\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5981 - accuracy: 0.7505\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5432 - accuracy: 0.7793\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5127 - accuracy: 0.7924\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5505 - accuracy: 0.7635\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5599 - accuracy: 0.7728\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.5621 - accuracy: 0.7616\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4874 - accuracy: 0.8101\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.5026 - accuracy: 0.8119\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5455 - accuracy: 0.7849\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.4953 - accuracy: 0.8147\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5729 - accuracy: 0.7747\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5526 - accuracy: 0.7896\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.4879 - accuracy: 0.8184\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 4.2401 - accuracy: 0.2833\n",
            "Test accuracy: 28.33%\n",
            "Training for fold 2 ...\n",
            "Epoch 1/100\n",
            "34/34 [==============================] - 2s 12ms/step - loss: 3.8014 - accuracy: 0.2346\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 2.1981 - accuracy: 0.2430\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.0171 - accuracy: 0.2533\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.9129 - accuracy: 0.2654\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.7241 - accuracy: 0.2970\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.6687 - accuracy: 0.3110\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.6396 - accuracy: 0.2812\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.5409 - accuracy: 0.3557\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.4863 - accuracy: 0.3417\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.5058 - accuracy: 0.3399\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.4479 - accuracy: 0.3706\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.4265 - accuracy: 0.3790\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.4226 - accuracy: 0.3911\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.3692 - accuracy: 0.4097\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.3890 - accuracy: 0.4106\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.4217 - accuracy: 0.3985\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.3432 - accuracy: 0.4283\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.3081 - accuracy: 0.4404\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.3066 - accuracy: 0.4264\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.2833 - accuracy: 0.4460\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.2557 - accuracy: 0.4600\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.2806 - accuracy: 0.4562\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.2609 - accuracy: 0.4795\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.2699 - accuracy: 0.4646\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.2606 - accuracy: 0.4516\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.1956 - accuracy: 0.4898\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.2063 - accuracy: 0.4749\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.1675 - accuracy: 0.5019\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.1885 - accuracy: 0.4823\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.1741 - accuracy: 0.5158\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.1325 - accuracy: 0.5335\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.1261 - accuracy: 0.5242\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.1337 - accuracy: 0.5251\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.1328 - accuracy: 0.5140\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.0934 - accuracy: 0.5503\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.1240 - accuracy: 0.5168\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0465 - accuracy: 0.5540\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0516 - accuracy: 0.5475\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0297 - accuracy: 0.5549\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0210 - accuracy: 0.5764\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0444 - accuracy: 0.5708\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0532 - accuracy: 0.5568\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0156 - accuracy: 0.5736\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9873 - accuracy: 0.5717\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9870 - accuracy: 0.5940\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0124 - accuracy: 0.5791\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9835 - accuracy: 0.5996\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9314 - accuracy: 0.6192\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9730 - accuracy: 0.6015\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9723 - accuracy: 0.5912\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0023 - accuracy: 0.6034\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9040 - accuracy: 0.6238\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9465 - accuracy: 0.6061\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9771 - accuracy: 0.5959\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0025 - accuracy: 0.5764\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.0183 - accuracy: 0.5652\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9987 - accuracy: 0.5838\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9666 - accuracy: 0.5875\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0000 - accuracy: 0.5801\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9609 - accuracy: 0.6155\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9877 - accuracy: 0.5885\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9648 - accuracy: 0.6108\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9784 - accuracy: 0.5931\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9416 - accuracy: 0.5996\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9097 - accuracy: 0.6266\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9372 - accuracy: 0.6182\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9049 - accuracy: 0.6145\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9381 - accuracy: 0.6182\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8816 - accuracy: 0.6397\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8758 - accuracy: 0.6415\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8635 - accuracy: 0.6257\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8768 - accuracy: 0.6322\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9333 - accuracy: 0.6155\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9377 - accuracy: 0.6061\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9324 - accuracy: 0.6080\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9016 - accuracy: 0.6378\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8760 - accuracy: 0.6620\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8822 - accuracy: 0.6406\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.8906 - accuracy: 0.6453\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8895 - accuracy: 0.6192\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9136 - accuracy: 0.6034\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9265 - accuracy: 0.6155\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9468 - accuracy: 0.6061\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8869 - accuracy: 0.6164\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.8711 - accuracy: 0.6397\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8861 - accuracy: 0.6369\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8967 - accuracy: 0.6276\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8964 - accuracy: 0.6201\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8542 - accuracy: 0.6322\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8311 - accuracy: 0.6704\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8982 - accuracy: 0.6117\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.8806 - accuracy: 0.6453\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8516 - accuracy: 0.6536\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9291 - accuracy: 0.6425\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8597 - accuracy: 0.6499\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7699 - accuracy: 0.6974\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7760 - accuracy: 0.6909\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7392 - accuracy: 0.6899\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7452 - accuracy: 0.6778\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7665 - accuracy: 0.6927\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.3055 - accuracy: 0.3000\n",
            "Test accuracy: 30.0%\n",
            "Training for fold 3 ...\n",
            "Epoch 1/100\n",
            "34/34 [==============================] - 2s 12ms/step - loss: 2.9527 - accuracy: 0.2533\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 2.0231 - accuracy: 0.2477\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.7820 - accuracy: 0.3017\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.7609 - accuracy: 0.2737\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.6843 - accuracy: 0.3045\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.6026 - accuracy: 0.3026\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.6047 - accuracy: 0.2877\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.5149 - accuracy: 0.3380\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.4425 - accuracy: 0.3743\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.4518 - accuracy: 0.3762\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.4205 - accuracy: 0.3911\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.3689 - accuracy: 0.4246\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.3100 - accuracy: 0.4562\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.3054 - accuracy: 0.4497\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.3069 - accuracy: 0.4320\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.2750 - accuracy: 0.4469\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.3201 - accuracy: 0.4367\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.2037 - accuracy: 0.5047\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.1978 - accuracy: 0.5196\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.1787 - accuracy: 0.4907\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.1916 - accuracy: 0.4981\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.1422 - accuracy: 0.5186\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0762 - accuracy: 0.5400\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.0592 - accuracy: 0.5559\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0419 - accuracy: 0.5596\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0054 - accuracy: 0.5782\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9627 - accuracy: 0.5885\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9594 - accuracy: 0.6201\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9128 - accuracy: 0.6220\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9039 - accuracy: 0.6145\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8024 - accuracy: 0.6443\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8751 - accuracy: 0.6378\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9191 - accuracy: 0.6285\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9878 - accuracy: 0.5847\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7901 - accuracy: 0.6834\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.7053 - accuracy: 0.7104\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7538 - accuracy: 0.7067\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7016 - accuracy: 0.7114\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7000 - accuracy: 0.7086\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7481 - accuracy: 0.6974\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6994 - accuracy: 0.7272\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6539 - accuracy: 0.7318\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.5658 - accuracy: 0.7849\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5959 - accuracy: 0.7654\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.6045 - accuracy: 0.7588\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.5350 - accuracy: 0.7924\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5602 - accuracy: 0.7998\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4950 - accuracy: 0.8259\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4321 - accuracy: 0.8399\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5150 - accuracy: 0.8007\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5119 - accuracy: 0.7905\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4910 - accuracy: 0.8091\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4856 - accuracy: 0.8110\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4349 - accuracy: 0.8250\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.4393 - accuracy: 0.8473\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3505 - accuracy: 0.8743\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3964 - accuracy: 0.8501\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3946 - accuracy: 0.8566\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3411 - accuracy: 0.8771\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3369 - accuracy: 0.8771\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3662 - accuracy: 0.8715\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3794 - accuracy: 0.8669\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3771 - accuracy: 0.8631\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4131 - accuracy: 0.8473\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4379 - accuracy: 0.8361\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3602 - accuracy: 0.8575\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3527 - accuracy: 0.8715\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2181 - accuracy: 0.9153\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2852 - accuracy: 0.9041\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3491 - accuracy: 0.8743\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4207 - accuracy: 0.8473\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3493 - accuracy: 0.8696\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3208 - accuracy: 0.8883\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3725 - accuracy: 0.8529\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2448 - accuracy: 0.9050\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3450 - accuracy: 0.8734\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2475 - accuracy: 0.9060\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2614 - accuracy: 0.9115\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2287 - accuracy: 0.9162\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2290 - accuracy: 0.9171\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1970 - accuracy: 0.9348\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2126 - accuracy: 0.9255\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3249 - accuracy: 0.8864\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3716 - accuracy: 0.8566\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3220 - accuracy: 0.8715\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2280 - accuracy: 0.9246\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3362 - accuracy: 0.8855\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2336 - accuracy: 0.9115\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2787 - accuracy: 0.8929\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2020 - accuracy: 0.9274\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2395 - accuracy: 0.9097\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2561 - accuracy: 0.9013\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1736 - accuracy: 0.9348\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1775 - accuracy: 0.9460\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1496 - accuracy: 0.9553\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3237 - accuracy: 0.8994\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2331 - accuracy: 0.9236\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2235 - accuracy: 0.9162\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2229 - accuracy: 0.9264\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3395 - accuracy: 0.8883\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.6006 - accuracy: 0.3667\n",
            "Test accuracy: 36.67%\n",
            "Training for fold 4 ...\n",
            "Epoch 1/100\n",
            "34/34 [==============================] - 2s 13ms/step - loss: 3.1926 - accuracy: 0.2549\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 2.0806 - accuracy: 0.2428\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.9526 - accuracy: 0.2605\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.8804 - accuracy: 0.2660\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.6818 - accuracy: 0.2837\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.6040 - accuracy: 0.2995\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.5254 - accuracy: 0.3163\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.4947 - accuracy: 0.3451\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.4729 - accuracy: 0.3553\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.3946 - accuracy: 0.3833\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.3438 - accuracy: 0.4149\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.3239 - accuracy: 0.4316\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.3311 - accuracy: 0.4316\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.2739 - accuracy: 0.4586\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.2788 - accuracy: 0.4744\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.2228 - accuracy: 0.4744\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.2769 - accuracy: 0.4549\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.2126 - accuracy: 0.4958\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.1642 - accuracy: 0.5274\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.1619 - accuracy: 0.5135\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.1067 - accuracy: 0.5498\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.0581 - accuracy: 0.5581\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.1515 - accuracy: 0.5172\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0162 - accuracy: 0.5702\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.0775 - accuracy: 0.5572\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0165 - accuracy: 0.5684\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.0289 - accuracy: 0.5860\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9434 - accuracy: 0.5972\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9628 - accuracy: 0.6056\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8883 - accuracy: 0.6260\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9353 - accuracy: 0.6102\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8888 - accuracy: 0.6353\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8298 - accuracy: 0.6642\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7803 - accuracy: 0.6726\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7979 - accuracy: 0.6828\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9486 - accuracy: 0.6223\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7907 - accuracy: 0.6921\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7440 - accuracy: 0.7042\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6746 - accuracy: 0.7358\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6959 - accuracy: 0.7228\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5723 - accuracy: 0.7758\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6542 - accuracy: 0.7358\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5795 - accuracy: 0.7740\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6164 - accuracy: 0.7674\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5886 - accuracy: 0.7749\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6717 - accuracy: 0.7581\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6383 - accuracy: 0.7572\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5087 - accuracy: 0.8009\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5774 - accuracy: 0.7740\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4795 - accuracy: 0.8177\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4614 - accuracy: 0.8260\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3772 - accuracy: 0.8530\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3900 - accuracy: 0.8549\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4773 - accuracy: 0.8140\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4393 - accuracy: 0.8428\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4945 - accuracy: 0.8195\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4750 - accuracy: 0.8177\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4124 - accuracy: 0.8381\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3921 - accuracy: 0.8521\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3684 - accuracy: 0.8623\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3998 - accuracy: 0.8549\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3449 - accuracy: 0.8623\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3028 - accuracy: 0.8893\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2679 - accuracy: 0.9005\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3497 - accuracy: 0.8670\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3468 - accuracy: 0.8726\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3123 - accuracy: 0.8800\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2663 - accuracy: 0.9023\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2628 - accuracy: 0.8967\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3152 - accuracy: 0.8716\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4185 - accuracy: 0.8474\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2733 - accuracy: 0.9042\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2463 - accuracy: 0.9163\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2034 - accuracy: 0.9274\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1675 - accuracy: 0.9423\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3292 - accuracy: 0.8791\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2116 - accuracy: 0.9256\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2315 - accuracy: 0.9153\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3198 - accuracy: 0.8819\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2813 - accuracy: 0.8865\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2792 - accuracy: 0.8884\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2809 - accuracy: 0.8995\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2489 - accuracy: 0.9023\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2957 - accuracy: 0.8781\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3196 - accuracy: 0.8828\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2457 - accuracy: 0.9126\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2228 - accuracy: 0.9228\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1753 - accuracy: 0.9414\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2354 - accuracy: 0.9107\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2326 - accuracy: 0.9191\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1667 - accuracy: 0.9367\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1961 - accuracy: 0.9274\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1675 - accuracy: 0.9377\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2038 - accuracy: 0.9265\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1560 - accuracy: 0.9442\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1745 - accuracy: 0.9423\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1845 - accuracy: 0.9414\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3041 - accuracy: 0.8967\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4081 - accuracy: 0.8502\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2701 - accuracy: 0.8967\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 5.5699 - accuracy: 0.3866\n",
            "Test accuracy: 38.66%\n",
            "Training for fold 5 ...\n",
            "Epoch 1/100\n",
            "34/34 [==============================] - 2s 12ms/step - loss: 3.2440 - accuracy: 0.2484\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 2.1038 - accuracy: 0.2474\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.9287 - accuracy: 0.2540\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.8142 - accuracy: 0.2893\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.6713 - accuracy: 0.2847\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.6319 - accuracy: 0.2940\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.6142 - accuracy: 0.3051\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.5554 - accuracy: 0.3126\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.4437 - accuracy: 0.3758\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.4200 - accuracy: 0.3935\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.4093 - accuracy: 0.3814\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.3562 - accuracy: 0.3963\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.3080 - accuracy: 0.4381\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.2843 - accuracy: 0.4698\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.2543 - accuracy: 0.4577\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.2492 - accuracy: 0.4577\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.2135 - accuracy: 0.4800\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.1942 - accuracy: 0.4949\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.2112 - accuracy: 0.4912\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.1084 - accuracy: 0.5312\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.0820 - accuracy: 0.5507\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0562 - accuracy: 0.5795\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0693 - accuracy: 0.5544\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9869 - accuracy: 0.5851\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9795 - accuracy: 0.5981\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.0362 - accuracy: 0.5805\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.9203 - accuracy: 0.6251\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9380 - accuracy: 0.6130\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8096 - accuracy: 0.6698\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9086 - accuracy: 0.6149\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8160 - accuracy: 0.6670\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.8162 - accuracy: 0.6800\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7572 - accuracy: 0.6921\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6968 - accuracy: 0.7172\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6777 - accuracy: 0.7340\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6656 - accuracy: 0.7349\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6510 - accuracy: 0.7442\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7012 - accuracy: 0.7153\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6248 - accuracy: 0.7665\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.7137 - accuracy: 0.7135\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6657 - accuracy: 0.7377\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5728 - accuracy: 0.7786\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5168 - accuracy: 0.8028\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5497 - accuracy: 0.7833\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4889 - accuracy: 0.8177\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4998 - accuracy: 0.8177\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5754 - accuracy: 0.7749\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4455 - accuracy: 0.8316\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5228 - accuracy: 0.8112\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4988 - accuracy: 0.8047\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5602 - accuracy: 0.7907\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4346 - accuracy: 0.8400\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3629 - accuracy: 0.8716\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4364 - accuracy: 0.8316\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3860 - accuracy: 0.8577\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3837 - accuracy: 0.8558\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3130 - accuracy: 0.8781\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2920 - accuracy: 0.8893\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3163 - accuracy: 0.8819\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3008 - accuracy: 0.8977\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3148 - accuracy: 0.8753\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3089 - accuracy: 0.8837\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2748 - accuracy: 0.9033\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2880 - accuracy: 0.9023\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4583 - accuracy: 0.8474\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2911 - accuracy: 0.8828\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2076 - accuracy: 0.9153\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3219 - accuracy: 0.8902\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2927 - accuracy: 0.8986\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3466 - accuracy: 0.8660\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2854 - accuracy: 0.8884\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2302 - accuracy: 0.9107\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2658 - accuracy: 0.9023\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2981 - accuracy: 0.8865\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2160 - accuracy: 0.9219\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1758 - accuracy: 0.9330\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2974 - accuracy: 0.8940\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2190 - accuracy: 0.9200\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2658 - accuracy: 0.9051\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3544 - accuracy: 0.8623\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2813 - accuracy: 0.9107\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1949 - accuracy: 0.9172\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2058 - accuracy: 0.9302\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1598 - accuracy: 0.9535\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1666 - accuracy: 0.9340\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2259 - accuracy: 0.9237\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1791 - accuracy: 0.9386\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1669 - accuracy: 0.9330\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1860 - accuracy: 0.9423\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1724 - accuracy: 0.9340\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1949 - accuracy: 0.9265\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1856 - accuracy: 0.9312\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1702 - accuracy: 0.9395\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2034 - accuracy: 0.9284\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2021 - accuracy: 0.9293\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2159 - accuracy: 0.9274\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2043 - accuracy: 0.9312\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1470 - accuracy: 0.9526\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1396 - accuracy: 0.9488\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2425 - accuracy: 0.9172\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 5.0690 - accuracy: 0.3277\n",
            "Test accuracy: 32.77%\n",
            "Training for fold 6 ...\n",
            "Epoch 1/100\n",
            "34/34 [==============================] - 2s 13ms/step - loss: 3.2057 - accuracy: 0.2447\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.9861 - accuracy: 0.2633\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.8412 - accuracy: 0.2884\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.7765 - accuracy: 0.2791\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.7531 - accuracy: 0.2670\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.6331 - accuracy: 0.3051\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.6118 - accuracy: 0.2940\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.5526 - accuracy: 0.3247\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.4810 - accuracy: 0.3581\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.4085 - accuracy: 0.4186\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.3756 - accuracy: 0.4019\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.3569 - accuracy: 0.4205\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.3477 - accuracy: 0.4214\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.2975 - accuracy: 0.4447\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.2261 - accuracy: 0.4819\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.2772 - accuracy: 0.4660\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.2078 - accuracy: 0.4902\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.2479 - accuracy: 0.4753\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.1866 - accuracy: 0.4958\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.1779 - accuracy: 0.5135\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.1248 - accuracy: 0.5274\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.1265 - accuracy: 0.5181\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.0906 - accuracy: 0.5395\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.9796 - accuracy: 0.5935\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.0451 - accuracy: 0.5767\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.0146 - accuracy: 0.5740\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.9874 - accuracy: 0.6047\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.0031 - accuracy: 0.5898\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.9717 - accuracy: 0.5907\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.9030 - accuracy: 0.6344\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.9141 - accuracy: 0.6093\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.8407 - accuracy: 0.6409\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.7463 - accuracy: 0.6986\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7135 - accuracy: 0.7135\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.7807 - accuracy: 0.6698\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7422 - accuracy: 0.7005\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.7767 - accuracy: 0.6837\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.7477 - accuracy: 0.6977\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6434 - accuracy: 0.7628\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5729 - accuracy: 0.7684\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5773 - accuracy: 0.7665\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6561 - accuracy: 0.7321\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5896 - accuracy: 0.7740\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5092 - accuracy: 0.7953\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6356 - accuracy: 0.7433\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6404 - accuracy: 0.7544\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4695 - accuracy: 0.8158\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5291 - accuracy: 0.7972\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5421 - accuracy: 0.7926\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4874 - accuracy: 0.8186\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5033 - accuracy: 0.8121\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3647 - accuracy: 0.8698\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3889 - accuracy: 0.8521\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4392 - accuracy: 0.8409\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3529 - accuracy: 0.8726\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3853 - accuracy: 0.8512\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3950 - accuracy: 0.8558\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3326 - accuracy: 0.8735\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3266 - accuracy: 0.8884\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3842 - accuracy: 0.8614\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3025 - accuracy: 0.8819\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3203 - accuracy: 0.8688\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3895 - accuracy: 0.8400\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3785 - accuracy: 0.8577\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2453 - accuracy: 0.9098\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2407 - accuracy: 0.9116\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3043 - accuracy: 0.8967\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3916 - accuracy: 0.8577\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3174 - accuracy: 0.8856\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4065 - accuracy: 0.8530\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2540 - accuracy: 0.9088\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3230 - accuracy: 0.8800\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4754 - accuracy: 0.8307\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2652 - accuracy: 0.9023\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2901 - accuracy: 0.8902\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2791 - accuracy: 0.8967\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2495 - accuracy: 0.9051\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3517 - accuracy: 0.8772\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2466 - accuracy: 0.9126\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1977 - accuracy: 0.9312\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2089 - accuracy: 0.9219\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2537 - accuracy: 0.9107\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3129 - accuracy: 0.8753\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2545 - accuracy: 0.9023\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2374 - accuracy: 0.9153\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2057 - accuracy: 0.9293\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1998 - accuracy: 0.9191\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2454 - accuracy: 0.9060\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.2401 - accuracy: 0.9163\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2011 - accuracy: 0.9312\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1783 - accuracy: 0.9423\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1274 - accuracy: 0.9498\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1891 - accuracy: 0.9312\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1613 - accuracy: 0.9442\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1186 - accuracy: 0.9535\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2494 - accuracy: 0.9135\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4945 - accuracy: 0.8242\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2327 - accuracy: 0.9181\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4034 - accuracy: 0.8642\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2719 - accuracy: 0.9033\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 7.1390 - accuracy: 0.3025\n",
            "Test accuracy: 30.25%\n",
            "Training for fold 7 ...\n",
            "Epoch 1/100\n",
            "34/34 [==============================] - 2s 13ms/step - loss: 3.2187 - accuracy: 0.2344\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 2.1900 - accuracy: 0.2447\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.9113 - accuracy: 0.2753\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.8346 - accuracy: 0.2605\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.6457 - accuracy: 0.3014\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.5971 - accuracy: 0.2958\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.5439 - accuracy: 0.2986\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.4898 - accuracy: 0.3488\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.4632 - accuracy: 0.3563\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.4453 - accuracy: 0.3758\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.3606 - accuracy: 0.4186\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.3663 - accuracy: 0.4251\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.2910 - accuracy: 0.4502\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 1.3357 - accuracy: 0.4288\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.2417 - accuracy: 0.4893\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.3359 - accuracy: 0.4344\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.2110 - accuracy: 0.4828\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.1726 - accuracy: 0.5005\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.2108 - accuracy: 0.4781\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.1037 - accuracy: 0.5209\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.0521 - accuracy: 0.5516\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.0851 - accuracy: 0.5405\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.0352 - accuracy: 0.5647\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.0281 - accuracy: 0.5740\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.0122 - accuracy: 0.5758\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9740 - accuracy: 0.5953\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.9363 - accuracy: 0.6177\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9070 - accuracy: 0.6307\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.8934 - accuracy: 0.6372\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.9067 - accuracy: 0.6233\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9699 - accuracy: 0.6000\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.9229 - accuracy: 0.6242\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.9571 - accuracy: 0.6140\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.7929 - accuracy: 0.6791\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7562 - accuracy: 0.6912\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7185 - accuracy: 0.7042\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.7432 - accuracy: 0.7033\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6835 - accuracy: 0.7209\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6156 - accuracy: 0.7619\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6359 - accuracy: 0.7423\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6764 - accuracy: 0.7284\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6205 - accuracy: 0.7553\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6818 - accuracy: 0.7405\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5481 - accuracy: 0.7944\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6021 - accuracy: 0.7591\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5331 - accuracy: 0.8047\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5282 - accuracy: 0.7851\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5107 - accuracy: 0.7916\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5264 - accuracy: 0.7981\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5574 - accuracy: 0.7656\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5568 - accuracy: 0.7888\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.3879 - accuracy: 0.8558\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5179 - accuracy: 0.7879\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4176 - accuracy: 0.8335\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5078 - accuracy: 0.8112\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6239 - accuracy: 0.7544\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3757 - accuracy: 0.8577\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3772 - accuracy: 0.8558\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4306 - accuracy: 0.8474\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4393 - accuracy: 0.8223\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4781 - accuracy: 0.8233\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3784 - accuracy: 0.8474\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3104 - accuracy: 0.8781\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3921 - accuracy: 0.8484\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2901 - accuracy: 0.8949\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3083 - accuracy: 0.8828\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3530 - accuracy: 0.8744\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4400 - accuracy: 0.8372\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3348 - accuracy: 0.8744\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4381 - accuracy: 0.8400\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3267 - accuracy: 0.8856\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2811 - accuracy: 0.8744\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2689 - accuracy: 0.9023\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3499 - accuracy: 0.8726\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2528 - accuracy: 0.9014\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2575 - accuracy: 0.9023\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2665 - accuracy: 0.8958\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2820 - accuracy: 0.8995\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3080 - accuracy: 0.8930\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3298 - accuracy: 0.8865\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2855 - accuracy: 0.8986\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2680 - accuracy: 0.9014\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3116 - accuracy: 0.8772\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2474 - accuracy: 0.9060\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3340 - accuracy: 0.8791\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3640 - accuracy: 0.8865\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2335 - accuracy: 0.9126\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2463 - accuracy: 0.9135\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3454 - accuracy: 0.8735\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2543 - accuracy: 0.9135\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2434 - accuracy: 0.9070\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2530 - accuracy: 0.8958\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2660 - accuracy: 0.8995\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2981 - accuracy: 0.8921\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.3015 - accuracy: 0.8828\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2164 - accuracy: 0.9219\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4536 - accuracy: 0.8456\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.2344 - accuracy: 0.9191\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2578 - accuracy: 0.9098\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2104 - accuracy: 0.9293\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.4247 - accuracy: 0.3193\n",
            "Test accuracy: 31.93%\n",
            "Training for fold 8 ...\n",
            "Epoch 1/100\n",
            "34/34 [==============================] - 2s 13ms/step - loss: 3.4062 - accuracy: 0.2484\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 2.0894 - accuracy: 0.2437\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.8724 - accuracy: 0.2642\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.8531 - accuracy: 0.2586\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.6633 - accuracy: 0.2995\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.6195 - accuracy: 0.3042\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.5557 - accuracy: 0.3200\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.5049 - accuracy: 0.3321\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.5192 - accuracy: 0.3228\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.3835 - accuracy: 0.3972\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.3922 - accuracy: 0.3991\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.3701 - accuracy: 0.4093\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.3186 - accuracy: 0.4381\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.3297 - accuracy: 0.4270\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.2900 - accuracy: 0.4586\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.2644 - accuracy: 0.4716\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.2097 - accuracy: 0.4874\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.2293 - accuracy: 0.4791\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.1440 - accuracy: 0.5209\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.1656 - accuracy: 0.5247\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.0962 - accuracy: 0.5414\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.0862 - accuracy: 0.5619\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.0803 - accuracy: 0.5507\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.1088 - accuracy: 0.5516\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.0427 - accuracy: 0.5684\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9438 - accuracy: 0.6149\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.9954 - accuracy: 0.5926\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9687 - accuracy: 0.6112\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.9285 - accuracy: 0.6177\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.8805 - accuracy: 0.6567\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.8498 - accuracy: 0.6660\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.8141 - accuracy: 0.6865\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.7862 - accuracy: 0.6967\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.8396 - accuracy: 0.6633\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.7801 - accuracy: 0.7014\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.7733 - accuracy: 0.7079\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.7393 - accuracy: 0.7088\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6765 - accuracy: 0.7367\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6862 - accuracy: 0.7256\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6991 - accuracy: 0.7219\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6235 - accuracy: 0.7591\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5664 - accuracy: 0.7777\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6208 - accuracy: 0.7665\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5005 - accuracy: 0.8242\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6481 - accuracy: 0.7358\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4858 - accuracy: 0.8214\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5089 - accuracy: 0.7963\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5019 - accuracy: 0.8093\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.5338 - accuracy: 0.7935\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5010 - accuracy: 0.8158\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4781 - accuracy: 0.8260\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4657 - accuracy: 0.8214\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4205 - accuracy: 0.8381\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4188 - accuracy: 0.8363\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4227 - accuracy: 0.8381\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3471 - accuracy: 0.8800\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3117 - accuracy: 0.8837\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2951 - accuracy: 0.8995\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3316 - accuracy: 0.8670\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3640 - accuracy: 0.8633\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3580 - accuracy: 0.8698\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2975 - accuracy: 0.8995\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2738 - accuracy: 0.8949\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2368 - accuracy: 0.9191\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3251 - accuracy: 0.8921\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3103 - accuracy: 0.8874\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3956 - accuracy: 0.8521\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2972 - accuracy: 0.8837\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3029 - accuracy: 0.8856\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3106 - accuracy: 0.8791\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3807 - accuracy: 0.8614\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3007 - accuracy: 0.8856\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3140 - accuracy: 0.8791\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2976 - accuracy: 0.8865\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.2902 - accuracy: 0.8967\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3259 - accuracy: 0.8791\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3652 - accuracy: 0.8716\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2817 - accuracy: 0.8967\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2195 - accuracy: 0.9135\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2127 - accuracy: 0.9256\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1826 - accuracy: 0.9358\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2688 - accuracy: 0.9060\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2764 - accuracy: 0.9042\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2646 - accuracy: 0.9088\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2665 - accuracy: 0.9005\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.2291 - accuracy: 0.9228\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2418 - accuracy: 0.9163\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1608 - accuracy: 0.9488\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2640 - accuracy: 0.9051\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1656 - accuracy: 0.9321\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2314 - accuracy: 0.9209\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2117 - accuracy: 0.9256\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1737 - accuracy: 0.9423\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1740 - accuracy: 0.9433\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1425 - accuracy: 0.9507\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2014 - accuracy: 0.9228\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1930 - accuracy: 0.9349\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1864 - accuracy: 0.9358\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2237 - accuracy: 0.9209\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.1978 - accuracy: 0.9293\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 6.8914 - accuracy: 0.2521\n",
            "Test accuracy: 25.21%\n",
            "Training for fold 9 ...\n",
            "Epoch 1/100\n",
            "34/34 [==============================] - 2s 13ms/step - loss: 3.3372 - accuracy: 0.2447\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 2.0674 - accuracy: 0.2447\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.8852 - accuracy: 0.2530\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 1.7835 - accuracy: 0.2800\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.6905 - accuracy: 0.2949\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.6715 - accuracy: 0.2707\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.5321 - accuracy: 0.2940\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.5133 - accuracy: 0.3367\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.4956 - accuracy: 0.3349\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 1.4511 - accuracy: 0.3758\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.3746 - accuracy: 0.4195\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.3103 - accuracy: 0.4502\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.4467 - accuracy: 0.3730\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.3236 - accuracy: 0.4000\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.2828 - accuracy: 0.4633\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.2193 - accuracy: 0.5042\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.2539 - accuracy: 0.4716\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 1.2299 - accuracy: 0.4800\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.2056 - accuracy: 0.4912\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.1467 - accuracy: 0.5107\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.1186 - accuracy: 0.5479\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.1017 - accuracy: 0.5377\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.1003 - accuracy: 0.5153\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.0655 - accuracy: 0.5544\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.0903 - accuracy: 0.5581\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0166 - accuracy: 0.5814\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.9372 - accuracy: 0.6214\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.9868 - accuracy: 0.6028\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.9759 - accuracy: 0.6084\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.9977 - accuracy: 0.5926\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.9537 - accuracy: 0.6112\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.8319 - accuracy: 0.6605\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.8104 - accuracy: 0.6623\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.8280 - accuracy: 0.6921\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.8835 - accuracy: 0.6400\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.7264 - accuracy: 0.7023\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.7064 - accuracy: 0.7265\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6995 - accuracy: 0.7126\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.7698 - accuracy: 0.6893\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.7329 - accuracy: 0.7051\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6507 - accuracy: 0.7498\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6357 - accuracy: 0.7451\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6555 - accuracy: 0.7293\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6484 - accuracy: 0.7460\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5987 - accuracy: 0.7712\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6393 - accuracy: 0.7544\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5389 - accuracy: 0.7851\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5935 - accuracy: 0.7693\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.5608 - accuracy: 0.7674\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5437 - accuracy: 0.7898\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5803 - accuracy: 0.7740\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5475 - accuracy: 0.7860\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5594 - accuracy: 0.7684\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4243 - accuracy: 0.8344\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4789 - accuracy: 0.8130\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4047 - accuracy: 0.8474\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5289 - accuracy: 0.7842\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4969 - accuracy: 0.8205\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3760 - accuracy: 0.8558\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4721 - accuracy: 0.8251\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.3557 - accuracy: 0.8726\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.3192 - accuracy: 0.8781\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3535 - accuracy: 0.8660\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3952 - accuracy: 0.8484\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4273 - accuracy: 0.8400\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3986 - accuracy: 0.8567\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3468 - accuracy: 0.8809\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3853 - accuracy: 0.8595\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.3328 - accuracy: 0.8763\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4201 - accuracy: 0.8512\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4003 - accuracy: 0.8633\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3173 - accuracy: 0.8847\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4026 - accuracy: 0.8465\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.2924 - accuracy: 0.8893\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2670 - accuracy: 0.9023\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3442 - accuracy: 0.8753\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3125 - accuracy: 0.8940\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2546 - accuracy: 0.9033\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3253 - accuracy: 0.8921\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3331 - accuracy: 0.8809\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2250 - accuracy: 0.9126\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2835 - accuracy: 0.8958\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2315 - accuracy: 0.9042\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2918 - accuracy: 0.8856\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2807 - accuracy: 0.9107\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3793 - accuracy: 0.8567\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3992 - accuracy: 0.8465\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1617 - accuracy: 0.9488\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2011 - accuracy: 0.9274\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1697 - accuracy: 0.9358\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1977 - accuracy: 0.9302\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2224 - accuracy: 0.9340\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2004 - accuracy: 0.9265\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1987 - accuracy: 0.9228\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1946 - accuracy: 0.9349\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.1613 - accuracy: 0.9460\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1867 - accuracy: 0.9358\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.2448 - accuracy: 0.9163\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2259 - accuracy: 0.9172\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2872 - accuracy: 0.9144\n",
            "4/4 [==============================] - 1s 11ms/step - loss: 5.1597 - accuracy: 0.2857\n",
            "Test accuracy: 28.57%\n",
            "Training for fold 10 ...\n",
            "mean =  30.821999999999996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AH9brGIkzeY6"
      },
      "source": [
        "def prepare_single_video(frames):\n",
        "    frame_featutes = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
        "    # Pad shorter videos.\n",
        "    if len(frames) < MAX_SEQ_LENGTH:\n",
        "        diff = MAX_SEQ_LENGTH - len(frames)\n",
        "        padding = np.zeros((diff, IMG_SIZE, IMG_SIZE, 3))\n",
        "        print(diff,padding )\n",
        "        frames = np.concatenate(frames, padding)\n",
        "    frames = frames[None, ...]\n",
        "\n",
        "    # Extract features from the frames of the current video.\n",
        "    for i, batch in enumerate(frames):\n",
        "        video_length = batch.shape[1]\n",
        "        length = min(MAX_SEQ_LENGTH, video_length)\n",
        "        for j in range(length):\n",
        "            if np.mean(batch[j, :]) > 0.0:\n",
        "                frame_featutes[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
        "            else:\n",
        "                frame_featutes[i, j, :] = 0.0\n",
        "    return frame_featutes\n",
        "\n",
        "\n",
        "def predict_action(path):\n",
        "    class_vocab = label_processor.get_vocabulary()\n",
        "    frames = load_video(os.path.join(\"drive/MyDrive/AIHealthcare/AIcare_Phrase1/data/season2/file_v1/csv_frame/trainv1/videos/test\", path))\n",
        "    print(os.path.join(\"drive/MyDrive/AIHealthcare/AIcare_Phrase1/data/season2/file_v1/csv_frame/trainv1/videos/test\", path))\n",
        "    frame_features = prepare_single_video(frames)\n",
        "    probabilities = trained_model.predict(frame_features)[0]\n",
        "    for i in np.argsort(probabilities)[::-1]:\n",
        "        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
        "    return frames\n",
        "\n",
        "def to_gif(images):\n",
        "    converted_images = images.astype(np.uint8)\n",
        "    imageio.mimsave(\"animation.gif\", converted_images, fps=10)\n",
        "    return embed.embed_file(\"animation.gif\")\n",
        "\n",
        "test_video = np.random.choice(test_df[\"video_name\"].values.tolist())\n",
        "print(f\"Test video path: {test_video}\")\n",
        "test_frames = predict_action(test_video)\n",
        "to_gif(test_frames[:MAX_SEQ_LENGTH])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}