{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "evaluate_model_FERG_DB_256.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8814db33b97c46f7be4cdb8fc274993e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_03dbda4e95644ca1a2ea2f2cffed8b29",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b9fe7e8d80e24dd6ae66e6d5b61be920",
              "IPY_MODEL_9741b4a1961748cab7e5fefbdc2c83ab"
            ]
          }
        },
        "03dbda4e95644ca1a2ea2f2cffed8b29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9fe7e8d80e24dd6ae66e6d5b61be920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cef5ae02e96e4e8491a8f45c53815768",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 152,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac55a23a7cbd4ff79b8cef506c2cdb7c"
          }
        },
        "9741b4a1961748cab7e5fefbdc2c83ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_299e389b8c134299959d158c09d36f75",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/152 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5396c94a2ad44017b8af84aa4d57e6dd"
          }
        },
        "cef5ae02e96e4e8491a8f45c53815768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac55a23a7cbd4ff79b8cef506c2cdb7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "299e389b8c134299959d158c09d36f75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5396c94a2ad44017b8af84aa4d57e6dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPFVCHjcQrEv",
        "outputId": "6ab38df9-0844-4caf-c66a-56be14df53e4"
      },
      "source": [
        "!pip install -q py-feat\n",
        "# !pip install -q facial-emotion-recognition\n",
        "# !pip install -q fer\n",
        "# !pip install -q deepface\n",
        "# !pip install -q mtcnn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 6.0MB 3.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 39.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 57.4MB 84kB/s \n",
            "\u001b[K     |████████████████████████████████| 4.9MB 49.9MB/s \n",
            "\u001b[?25h  Building wheel for py-feat (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kpu_xoUpRHxW",
        "outputId": "f69d088d-3441-47d4-869b-ec39ae015f22"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from feat import Detector\n",
        "import glob\n",
        "import math\n",
        "import dlib\n",
        "import joblib\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm\n",
        "from google.colab.patches import cv2_imshow\n",
        "from collections import Counter\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.applications.vgg19 import VGG19, preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.models import Model\n",
        "from keras import optimizers \n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
        "\n",
        "face_model = \"RetinaFace\"\n",
        "landmark_model = \"MobileNet\"\n",
        "au_model = \"svm\"\n",
        "emotion_model = \"resmasknet\" #resmasknet,fer, svm, rf\n",
        "detector = Detector(face_model = face_model, landmark_model = landmark_model, au_model = au_model, emotion_model = emotion_model)\n",
        "\n",
        "def my_mode(sample):\n",
        "  c = Counter(sample)\n",
        "  return [k for k, v in c.items() if v == c.most_common(1)[0][1]]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loading Face Detection model:  RetinaFace\n",
            "Using downloaded and verified file: /usr/local/lib/python3.7/dist-packages/feat/resources/mobilenet0.25_Final.pth\n",
            "Using downloaded and verified file: /usr/local/lib/python3.7/dist-packages/feat/resources/mobilenet_224_model_best_gdconv_external.pth.tar\n",
            "Using downloaded and verified file: /usr/local/lib/python3.7/dist-packages/feat/resources/hog_pca_all_emotio.joblib\n",
            "Using downloaded and verified file: /usr/local/lib/python3.7/dist-packages/feat/resources/hog_pca_all_emotio.joblib\n",
            "Using downloaded and verified file: /usr/local/lib/python3.7/dist-packages/feat/resources/hog_scalar_aus.joblib\n",
            "Using downloaded and verified file: /usr/local/lib/python3.7/dist-packages/feat/resources/svm_568.joblib\n",
            "Using downloaded and verified file: /usr/local/lib/python3.7/dist-packages/feat/resources/hog_pca_all_emotio.joblib\n",
            "Using downloaded and verified file: /usr/local/lib/python3.7/dist-packages/feat/resources/hog_scalar_aus.joblib\n",
            "Using downloaded and verified file: /usr/local/lib/python3.7/dist-packages/feat/resources/ResMaskNet_Z_resmasking_dropout1_rot30.pth\n",
            "Loading Face Landmark model:  MobileNet\n",
            "Loading au model:  svm\n",
            "Loading emotion model:  resmasknet\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator PCA from version 0.24.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearSVC from version 0.24.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUrNBJdNRUJ8"
      },
      "source": [
        "## ALL STEP IN ONE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhlYnFD5T2Vm",
        "outputId": "54f4fae1-6656-492d-8e89-cfe230c771a9"
      },
      "source": [
        "ls 'drive/MyDrive/file2/vdo/Isaree/01_karnmay.mp4'"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive/MyDrive/file2/vdo/Isaree/01_karnmay.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUZ5VZmZbFWi",
        "outputId": "9ad93b6e-061d-4757-bb59-7b8eac3dda1b"
      },
      "source": [
        "ls 'drive/MyDrive/file2/done/face2_01_KARNMAY_P1.csv'"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive/MyDrive/file2/done/face2_01_KARNMAY_P1.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFotJmV_esfP",
        "outputId": "2a91fe7f-d6a6-4b57-9e5c-d16ee1fa9a8b"
      },
      "source": [
        "ls 'drive/MyDrive/AIHealthcare/AIcare_Phrase1/data/model_FERG_DB_256'"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_4_1.h5    model_4_2_1.h5  model_4_2_3.h5  model_4.h5\n",
            "model_4_2_0.h5  model_4_2_2.h5  model_4_2_4.h5  model_FERG_DB_256.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knSi6HEAeUaC"
      },
      "source": [
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(4, activation='softmax')(x)\n",
        "\n",
        "# Create  model\n",
        "model_4 = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "base_model_layers = model_4.layers[:23]\n",
        "new_model_layers =  model_4.layers[23:]\n",
        "\n",
        "base_model_blocks = {\n",
        "    0: base_model_layers[1:3],\n",
        "    1: base_model_layers[4:6],\n",
        "    2: base_model_layers[7:11],\n",
        "    3: base_model_layers[12:16],\n",
        "    4: base_model_layers[17:21]\n",
        "}\n",
        "\n",
        "# Load the best model\n",
        "model_4_path = \"./drive/MyDrive/AIHealthcare/AIcare_Phrase1/data/model_FERG_DB_256/{}.h5\".format(\"model_4\")\n",
        "model_4.load_weights(model_4_path)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "8814db33b97c46f7be4cdb8fc274993e",
            "03dbda4e95644ca1a2ea2f2cffed8b29",
            "b9fe7e8d80e24dd6ae66e6d5b61be920",
            "9741b4a1961748cab7e5fefbdc2c83ab",
            "cef5ae02e96e4e8491a8f45c53815768",
            "ac55a23a7cbd4ff79b8cef506c2cdb7c",
            "299e389b8c134299959d158c09d36f75",
            "5396c94a2ad44017b8af84aa4d57e6dd"
          ]
        },
        "id": "Qxch2_rrRXwL",
        "outputId": "ad66c3bb-e263-43b8-f511-9a1c057a7e82"
      },
      "source": [
        "pred_emotion= []\n",
        "\n",
        "filepath = 'drive/MyDrive/file2/done/face2_01_KARNMAY_P1.csv'\n",
        "vdopath ='drive/MyDrive/file2/vdo/Isaree/01_karnmay.mp4'\n",
        "df = pd.read_csv(filepath)\n",
        "dim = (224, 224)\n",
        "rowimg = []\n",
        "label_img = []\n",
        "print('df', df.shape)\n",
        "\n",
        "for i in tqdm(range(df.shape[0])):\n",
        "  seqimg = []\n",
        "  for j in range(df['start_frame'][i], df['end_frame'][i]):\n",
        "    cap = cv2.VideoCapture(vdopath)\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, j)\n",
        "    success, image = cap.read()\n",
        "    faceimg = detector.detect_faces(image)\n",
        "    try:\n",
        "      pos = faceimg[0][:4]\n",
        "      cropimg =image[int(pos[1]):int(pos[3]),int(pos[0]):int(pos[2])] \n",
        "      resized = cv2.resize(cropimg, dim, interpolation=cv2.INTER_CUBIC)     \n",
        "      image = preprocess_input(resized)\n",
        "      image = np.expand_dims(image, axis=0)\n",
        "      preds = model_4.predict(image)\n",
        "      pred_class = np.argmax(preds)\n",
        "      seqimg.append(pred_class) \n",
        "    except:\n",
        "      print(\"Emotion Error  i = \",i, ' j =', j)\n",
        "\n",
        "  seq_label = my_mode(seqimg)\n",
        "  print('i =', i, 'seq_label =', seq_label)\n",
        "  pred_emotion.append(seq_label[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df (152, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8814db33b97c46f7be4cdb8fc274993e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=152.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1TQ1XKAUr_N"
      },
      "source": [
        "while True:pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGVa4i0rPLgf"
      },
      "source": [
        "dic_resmask =  {0:'anger',1:'disgust', 2:'fear', 3:'happiness',4:'sadness',\t5:'surprise',\t6:'neutral' }\n",
        "# dic_kagle =  {0:'anger',1:'disgust', 2:'fear', 3:'happiness',4:'sadness',\t5:'surprise',\t6:'neutral' }\n",
        "# dic_ckplus =  {1:'anger',3:'disgust', 4:'fear', 5:'happiness',6:'sadness',\t7:'surprise'}\n",
        "# dic_fer_svm_rf =  {0:'anger',1:'disgust', 2:'fear', 3:'happiness',4:'sadness',\t5:'surprise',\t6:'neutral' }\n",
        "# dic_fer_svm_rf =  {0:'anger',1:'disgust', 2:'fear', 3:'happiness',4:'sadness',\t5:'surprise',\t6:'neutral' }\n",
        "# dic_Deepfake =  {0:'anger',1:'fear', 2:'neutral', 3:'sad',4:'disgust',\t5:'happy',\t6:'surprise' }\n",
        "\n",
        "pred = pd.DataFrame({'Pred':pred_emotion})\n",
        "pred['emotion'] = pred['Pred'].replace(dic_resmask) \n",
        "result = pd.concat([df, pred], axis=1, join=\"inner\")\n",
        "\n",
        "from google.colab import files\n",
        "result.to_csv('05_pimrypie_tony_R1.csv') \n",
        "files.download('05_pimrypie_tony_R1.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}